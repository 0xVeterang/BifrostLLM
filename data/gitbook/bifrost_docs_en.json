[
  {
    "title": "Introduction",
    "content": "Introduction\nWhat is the Bifrost Network?\nThe Bifrost Network is a public blockchain built on the Substrate framework and fully compatible with the Ethereum API, providing developers with access to a wide range of libraries and development environments.\nThe Bifrost Network is designed with a \"multichain-first\" approach, which natively enables interaction and communication between different blockchains through a decentralized cross-chain channel. DApps on the Bifrost Network can utilize a range of promising cryptocurrencies from any supported blockchains through the Bifrost Network's cross-chain communication protocol. The core validators on the Bifrost Network also serve as relayers, transmitting cross-chain messages across multiple blockchains to facilitate this communication. This cross-chain readiness creates a multichain-oriented environment that offers developers huge opportunities to develop innovative and diverse applications.\nWhat makes developing and running applications on the Bifrost Network  enjoyable?\nCross-chain Interoperability\nThe Bifrost Network has its own Cross-Chain Communication Protocol (CCCP) that enables native support for cross-chain actions. Overcoming the inherent limitations of multichain (i.e., fragmented liquidity and market), DApps can offer their services to a broader range of users and provide more comprehensive services.\nBuilt-in token bridge interacting with DApps: CCCP is a key component of the Bifrost Network that enables the seamless transfer of tokens between different blockchain networks. Designated contracts on the Bifrost Network manage the cross-chain transfer of tokens at the smart contract level. By using CCCP, decentralized applications (DApps) can easily integrate cross-chain token transfer actions into their services.\nMultichain-ready resources (Token and Oracle): One of the main challenges faced by DApps operating across multiple blockchain networks is accessing and using primary resources, such as tokens and oracle data feeds, from different blockchain networks due to their inherent incompatibilities. This lack of clarity on handling multichain assets can hinder the development and adoption of DApps. The Bifrost Network supports representative forms of primary resource that is optimized for use with CCCP.\nExtending legacy single-chain DApps to support multichain: CCCP provides bridge integration methods (e.g., Bridge and BridgeAndCall) at smart contract level so that DApps can extend their actions for a single blockchain to interwork with DApps in the Bifrost Network. It allows developers to convert their regular DApps into multichain DApps by integrating them with the Bifrost Network.\nDApp-Friendly Environment\nThe Bifrost Network is a well-established and fully-equipped platform for DApps developers, built on the extensive experience of a long-time service provider of BiFi. It offers essential features and resources to support the development and operation of DApps.\nPrice oracle aggregation: The Bifrost Oracle is a reliable source for cryptocurrency prices, offering real-time data for decentralized finance (DeFi) services. By aggregating and verifying data from both on-chain and off-chain data sources, the Bifrost Oracle helps to prevent unexpected price spikes and manipulation attacks. In addition, the low gas fee of the Bifrost Network allows the Bifrost Oracle to update its price data more frequently than other oracle services, providing users with accurate, up-to-date information that closely reflects real-time market prices.\nEVM Compatibility\nThe Bifrost Network supports smart contracts on the Ethereum Virtual Machine (EVM). Developers may create DApp in Solidity and use the following well-known tools and resources to aid in the development process. \nSeamless migration of essential Solidity library. e.g., OpenZeppelin’s SafeMath, SafeERC20, SafeProxy.\nSeamless migration of essential Solidity library. e.g., OpenZeppelin’s SafeMath, SafeERC20, SafeProxy.\nCompatibility with client libraries. e.g., Web3, Ether.js, Web3.py.\nCompatibility with client libraries. e.g., Web3, Ether.js, Web3.py.\nDevelopment environments. e.g., HardHat, Brownie, Truffle, Metamask.\nDevelopment environments. e.g., HardHat, Brownie, Truffle, Metamask.\nSecurity analysis tools. e.g., Manticore, Mythril, Oyente, Solgraph.\nSecurity analysis tools. e.g., Manticore, Mythril, Oyente, Solgraph.\nEthereum asset standards. e.g., ERC-20, ERC-721.\nEthereum asset standards. e.g., ERC-20, ERC-721.\nLast updated 9 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network"
  },
  {
    "title": "Bifrost Network Architecture",
    "content": "Bifrost Network Architecture\nThe Bifrost Network is an EVM-compatible blockchain designed for multichain interoperability, allowing users and the DApp developers in the Bifrost Network ecosystem to interact with multiple blockchains through native cross-chain communication. The Bifrost Network initially supports timelock-secured token transfers and oracle aggregations across blockchains.\nA fully-functioning node in the Bifrost Network is composed of the base part and the inter-connection part, or \"relayer.\" The base part, built with Substrate and the Bifrost precompiles, is responsible for producing and finalizing blocks. At the same time, the relayer monitors multiple blockchains and securely executes cross-chain actions through in-blockchain consensus.\nCross-Chain Communication\nCross-Chain Communication (CCC) is a protocol that facilitates the delivery and verification of cross-chain actions in the Bifrost Network. It uses specialized smart contracts called \"socket contracts\" to coordinate relayers and cross-chain users on every supported blockchain. \nA user sends a request to the socket contracts to initiate a cross-chain action. If the socket contract can successfully validate the request, the relayers are notified and deliver the request to a socket contract on the other blockchain. CCC uses in-blockchain consensus to verify the request, including the current state of the cross-chain action and the signature of the relayer. The socket contract can only execute the cross-chain action when a quorum of authenticated relayers agree on the request and it is in a legitimate state.\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bifrost-network-architecture"
  },
  {
    "title": "Consensus",
    "content": "BIFROST NETWORK ARCHITECTURE\nConsensus\nDelegated Proof of Stake\nBifrost is based on a Delegated Proof of Stake (DPoS) system where nominators back validators with their own staked BFC as a show of faith in the good behavior of the validator. Anyone who has BFC staked in the DPoS-based Bifrost Network can participate in the network consensus process as a validator or a nominator (the exact amounts are TBD). \nThe Bifrost Network updates the current active validator set every round. A new active validator set is selected based on which validators have the highest voting power – the total voting power of an individual validator consists of the sum of their self-bonded stake and received nominations. Only the top n will be selected as the active validators authorized to participate in the consensus for the new round. At the end of each round, validators earn round rewards in return for maintaining the security and reliability of the Bifrost Network. Some of the validator’s round rewards will be proportionally distributed to each of their nominators. \nValidators that do not behave properly may be designated as a target for slashing and receive a penalty that deducts a percentage of their staked BFC. Validators are incentivized to maintain a high level of voting power within the network in order to remain in the active validator set and continue to earn rewards; or so that they can increase their chances of being selected as an active validator. Nominators are incentivized to vote for reliable validators to ensure that their stakes are maintained and rewarded. Over time, the voting power of each validator will be equivalent to the confidence that the total body of nominators has in that validator to support and secure the network. This set of consensus mechanisms and rewards is based on mutual trust and symbiotic relationships that improve both the stability and reliability of the network.\nBlock Production\nBifrost's block production engine is AuRA (Authority Ro(a)und). AuRa works by sequentially selecting the block producer for the current slot in a round-robin fashion. If the network is stable, all active validators will create the exact same number of blocks for each round.\nFinality Gadget\nBifrost's block finalization engine is GRANDPA (GHOST-based Recursive Ancestor Deriving Prefix Agreement). GRANDPA is a consensus approach based on deterministic finality. All active validators selected in each round must participate in the voting process to determine the finality of the block.\nThe voting process begins by selecting a primary node. The primary node then selects the highest block in the chain from that node's point of view and broadcasts its block data to the network. After when the rest of the nodes receive the block data, they vote on the block to achieve finality. If the block is affirmed by more than two-thirds of all active validators, all blocks below that block number will be finalized.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bifrost-network-architecture/consensus"
  },
  {
    "title": "Cross-Chain Communication Protocol (CCCP)",
    "content": "BIFROST NETWORK ARCHITECTURE\nCross-Chain Communication Protocol (CCCP)\nIntroduction\nBifrost's Cross-Chain Communication Protocol (CCCP) realizes cross-chain communication through interactions between socket contracts and relayers. The CCCP enables users on one blockchain to utilize DApps provided on other blockchains.\nA socket contract is a system contract installed on the Bifrost Network and all other external chains such as Ethereum. A socket contract emits a CCC-event when triggered by a CCC-request from another socket contract, and this CCC-event is delivered to another socket contract by a relayer. A user’s request goes around different socket contracts in the form of a CCC-event and terminates when all the necessary logic has been executed.\nIn particular, multiple relayers deliver the socket-events to ensure the protocol’s continuity even if a certain number of relayers fail or are compromised, and the “timeout rollback” function is in place to prevent the users’ assets from being locked in socket contracts even if the entire relayer group fails. Additionally, the total operational cost of the relayer group is significantly cut down by minimizing the number of transactions delivered to other blockchains that have relatively high costs.\nGlossary\nCCC Protocol (CCCP): Cross-Chain Communication Protocol \nCCC Protocol (CCCP): Cross-Chain Communication Protocol \nVS Protocol (VSP): Validator Synchronization Protocol \nVS Protocol (VSP): Validator Synchronization Protocol \nValidator: the consensus validation node of the Bifrost Network \nValidator: the consensus validation node of the Bifrost Network \nRelayer: the CCC protocol-worker node of the Bifrost Network\nRelayer: the CCC protocol-worker node of the Bifrost Network\nCCC-request: is requested by a user which calls an f(x) installed on other blockchains \nCCC-request: is requested by a user which calls an f(x) installed on other blockchains \nCCC-event: a CCCP message containing the CCC-request details (socket contract’s event) \nCCC-event: a CCCP message containing the CCC-request details (socket contract’s event) \nExternal chain: any blockchain other than the Bifrost Network (e.g. Ethereum, BNB chain, Polygon, etc.)\nExternal chain: any blockchain other than the Bifrost Network (e.g. Ethereum, BNB chain, Polygon, etc.)\nf(x): a pre-defined function to be executed in other blockchains. (smart contract) \nf(x): a pre-defined function to be executed in other blockchains. (smart contract) \nPositive status: the CCC-status indicating “success” (REQUESTED, EXECUTED, ACCEPTED, COMMITTED) \nPositive status: the CCC-status indicating “success” (REQUESTED, EXECUTED, ACCEPTED, COMMITTED) \nNegative status: the CCC-status indicating “failure”; the positive and negative statuses have been accordingly paired (FAILED, REVERTED, REJECTED, ROLLBACKED)\nNegative status: the CCC-status indicating “failure”; the positive and negative statuses have been accordingly paired (FAILED, REVERTED, REJECTED, ROLLBACKED)\nComponents\nA user sends a CCC-request to the socket contract, which calls a f(x) under another blockchain. As a f(x) requires cryptocurrency payment, the socket contract collects the user’s cryptocurrency.\nRelayers deliver the following data to the socket contract:\nLatest validator (relayer) list: relayers deliver the latest validator list to all external chains; all blockchains utilize the latest validator list for access control\nLatest validator (relayer) list: relayers deliver the latest validator list to all external chains; all blockchains utilize the latest validator list for access control\nOff-chain data: off-chain data such as certain assets’ prices or Bitcoin blockchain’s block hash are delivered to the Socket contract of the Bifrost Network; the oracle manager contract receives this data from the socket contract and provides oracle services\nOff-chain data: off-chain data such as certain assets’ prices or Bitcoin blockchain’s block hash are delivered to the Socket contract of the Bifrost Network; the oracle manager contract receives this data from the socket contract and provides oracle services\nCCC-events: a relayer detects CCC-events from all supported blockchain networks and relays the detected event to its corresponding socket contract; the corresponding socket contract information can be derived from the CCC-event\nCCC-events: a relayer detects CCC-events from all supported blockchain networks and relays the detected event to its corresponding socket contract; the corresponding socket contract information can be derived from the CCC-event\nSystem Contracts - The Bifrost Network supports the three system contracts:\nThe socket contract generates CCC-events which are to be treated by other socket contracts, or receives CCC-events emitted by other socket contracts and treats them. In particular, it executes request-indicated actions (e.g. mint, lending, leveraged investment) according to the protocol specifications.\nThe socket contract generates CCC-events which are to be treated by other socket contracts, or receives CCC-events emitted by other socket contracts and treats them. In particular, it executes request-indicated actions (e.g. mint, lending, leveraged investment) according to the protocol specifications.\nThe Built-in DeFi Suite - The DeFi Suite functions are abstracted and expressed as f(x).\nThe Built-in DeFi Suite - The DeFi Suite functions are abstracted and expressed as f(x).\nThe oracle manager contract collects the designated off-chain data and provides on-chain oracle services.\nThe oracle manager contract collects the designated off-chain data and provides on-chain oracle services.\nProtocol Design\nThe following design factors are applied to the CCCP to overcome the limitations of the smart contracts' execution environment.\nDesign Factors\nAs smart contracts do not provide sufficient data storage space, we only store the data’s hash instead of the entire data in smart contracts. If we need to reuse the data, we re-send it. We use this strategy because comparing the hash value is cheaper than initially storing the data. \nAs smart contracts do not provide sufficient data storage space, we only store the data’s hash instead of the entire data in smart contracts. If we need to reuse the data, we re-send it. We use this strategy because comparing the hash value is cheaper than initially storing the data. \nA transaction may fail due to its atomic property. In this case, another transaction indicating this “failure” must be re-transmitted to leave its failed status on the smart contract.\nA transaction may fail due to its atomic property. In this case, another transaction indicating this “failure” must be re-transmitted to leave its failed status on the smart contract.\nSmart contracts do not provide built-in functions such as sorting array or mapping keys/values return, and implementing such functions is inefficient transaction fee-wise. Thus, the transaction sender may have to send an already sorted array data so that the smart contract does not have to do the sorting.\nSmart contracts do not provide built-in functions such as sorting array or mapping keys/values return, and implementing such functions is inefficient transaction fee-wise. Thus, the transaction sender may have to send an already sorted array data so that the smart contract does not have to do the sorting.\nWe minimize the number of transactions directed to external chains which impose relatively high fees. When a relayer group relays a CCC-event to an external chain, the CCC-event is first submitted with a signature to the Bifrost Network. Then, the primary relayer aggregates all signatures and delivers them to the external chain at once.\nWe minimize the number of transactions directed to external chains which impose relatively high fees. When a relayer group relays a CCC-event to an external chain, the CCC-event is first submitted with a signature to the Bifrost Network. Then, the primary relayer aggregates all signatures and delivers them to the external chain at once.\nVSP is the sub-protocol of CCCP, which synchronizes the latest validator list of the Bifrost Network to all external chains. The validator list must stay up to date as the validators of the network can change periodically and socket contracts use information about validators for access control.\nAssumptions\nRelayers monitor every CCC-event. \nRelayers monitor every CCC-event. \nRelayers possess sufficient amounts of native coins (e.g. BFC, ETH, BNB) for transaction fees. \nRelayers possess sufficient amounts of native coins (e.g. BFC, ETH, BNB) for transaction fees. \nRelayers are penalized for request forgeries. (Relayers do not harm the protocol for minor gains.) \nRelayers are penalized for request forgeries. (Relayers do not harm the protocol for minor gains.) \nThe majority of relayers faithfully execute the protocol. (The number of relayers in shut down status or conducting request forgery attacks is always less than the majority.) \nThe majority of relayers faithfully execute the protocol. (The number of relayers in shut down status or conducting request forgery attacks is always less than the majority.) \nThe preceding CCC-event accumulation will not cause the failure of the following CCC-event production.\nThe preceding CCC-event accumulation will not cause the failure of the following CCC-event production.\nRelayers process all events generated during their delegated time, even if they are un-delegated for any reason. \nRelayers process all requests that occur during their term. \nThe Bifrost Network relays the next validator set. \nOtherwise, relayers are penalized.\nRelayers process all events generated during their delegated time, even if they are un-delegated for any reason. \nRelayers process all requests that occur during their term. \nRelayers process all requests that occur during their term. \nThe Bifrost Network relays the next validator set. \nThe Bifrost Network relays the next validator set. \nOtherwise, relayers are penalized.\nOtherwise, relayers are penalized.\nInbound CCCP\nThe inbound protocol indicates the delivery method of the CCC-request from an external chain to the Bifrost Network. The figure below represents the CCC-event flow of the inbound protocol. The “relay type” marked for each relay is further explained in the section \"Two-Types of Relay Vote\".\nEach user request delivered to the socket contract of an external chain sequentially goes through “REQUESTED”, “EXECUTED”, and “ACCEPTED” and finally ends in “COMMITTED” status. However, if the Phase 1 f(x) fails to execute, a request goes through “REQUESTED”, “REVERTED”, and “REJECTED” and ends in “ROLLBACKED” status. Requests completed as “ROLLBACKED” return the collected tokens during the user’s transaction.\nOutbound CCCP\nThe outbound protocol indicates the delivery method of the user request from the Bifrost Network to an external chain. The figure below represents the CCC-event flow of the outbound protocol. The “relay type” marked for each relay is further explained in the section \"Two-Types of Relay Vote\".\nEach user request delivered to the socket contract of an external chain sequentially goes through “REQUESTED”, “EXECUTED”, “ACCEPTED” and finally ends in “COMMITTED” status. However, if the Phase2 f(x) fails to execute, a request goes through “REQUESTED”, “REVERTED”, “REJECTED” and ends in “ROLLBACKED” status. Requests completed as “ROLLBACKED” return the collected tokens during the user’s transaction.'\nValidator Synchronization Protocol\nVSP delivers the updated information on the Bifrost Network’s validator(=relayer) set to all socket contracts on all supported external chains. Socket contracts update their access permission list with the delivered validator set.\nTwo Types of Relay Vote\nA CCC-request is delivered by several relayers for a low risk of data falsification. On the other hand, if a valid CCC-event is concurrently delivered to two different blockchains, user assets can increase or decrease on both sides. For example, when there are five relayers, the quorum is three. There can be a case where two relayers succeed and three fail in transmitting a CCC-event transaction that mints in Ethereum. In such a case, the “failed relayers” transmit a CCC-event transaction to the Bifrost Network, and the user is refunded in Ethereum. However, if one of the “failed relayers” re-sends the mint transaction and succeeds, the user’s asset in the Bifrost Network increases and results in “double payment.” This example shows how one malicious relayer can cause protocol failure.\nSituations like the above can occur as the socket contract did not clearly finalize the CCC-event process result before proceeding to the next phase. Thus, a CCC-request must be finalized as one status in each phase before emitting an event. The relayer must proceed to the next phase only when a CCC-event of the next status is detected.\nEach phase of the protocol delivers relay votes to the socket contract through one of the type methods described below. Moreover, for phases executing f(x) as a result of the relay vote, the “Self Transition Rule” additionally applies.\nSelf Transition Rule (if fails)\nFor phases in which f(x) is executed, such as Inbound Phase1 or Outbound Phase2, the transaction may fail due to the logic of f(x) even if the relayers deliver valid CCC-events. However, as a failed transaction due to its atomic property cannot affect the socket contract, an “execution failure” CCC-event cannot be emitted. Thus, relayers set the CCC-event status to negative and transfer it to the socket contract. When the socket contract receives negative CCC-events from a majority of relayers, it emits the “execution failure” CCC-event and forces the process onto the next phase. (A negative status can never be restored to positive status.)\nFurthermore, due to the transaction’s asynchronous property, we cannot know when the next status CCC-event is going to be emitted. There can be a situation where two out of five relayers emit a positive CCC-event, and the other two emit a negative CCC-event. If the remaining relayer does not act, this CCC-event can never be processed. This example shows how the protocol can fail due to one relayer.\nThus, relayers that have voted for positive status verify if the request has been finalized as a positive status after t seconds. If not finalized, the relayers change the original CCC-event to negative status and resend it. As a result, the CCC-event will always be processed in t seconds. (In the example case above, the status would ultimately be settled as negative.)\nFigure Description\nEach relayer delivers the event of the detected positive status to the next socket contract.\ntransaction success → set timer\ntransaction failure → change event to negative status and resend it\nEach relayer delivers the event of the detected positive status to the next socket contract.\ntransaction success → set timer\ntransaction success → set timer\ntransaction failure → change event to negative status and resend it\ntransaction failure → change event to negative status and resend it\ntimeout → change event to negative status and resend it\ntimeout → change event to negative status and resend it\nFor each status, the socket contract executes f(x) at the n-th relay vote transaction that reaches the majority and emits the next CCC-event.\nType 1: General Relay\nIn the case of a phase with no f(x) in its resulting logic, each relayer simply delivers the CCC-event through a transaction.\nFigure Description\nAll relayers deliver the detected event to the next socket contract.\nAll relayers deliver the detected event to the next socket contract.\nThe socket contract emits the next CCC-event at the n-th relay vote transaction that reaches the majority.\nType 1-1: General Relay with signature\nThe relayer additionally attaches its signature to execute “Type 1: General Relay”. The socket contract saves the attached signatures, which can later be inquired en bloc by the socket contract.\nType 2: Aggregated Relay\nInstead of having all the relayers deliver the CCC-event to an external chain with a relatively high fee, one primary relayer aggregates all relayers’ signatures and emits a CCC-event. (Once the primary relayer is designated, other relayers are automatically considered secondary relayers.)\nTo ensure that the failure of the primary relayer does not lead to the failure of the protocol, secondary relayers verify whether or not the CCC-event has been successfully emitted after t seconds. If not emitted, all secondary relayers take on the role of the primary relayer and emit the CCC-event.\nFigure Description\nCalculate the primary relayer index: (the height of the block containing the event) % (the total number of validators). The relayer with the calculated primary relayer index is designated as the primary relayer. (The rest become secondary relayers.)\nCalculate the primary relayer index: (the height of the block containing the event) % (the total number of validators). The relayer with the calculated primary relayer index is designated as the primary relayer. (The rest become secondary relayers.)\nPrimary relayer\nInquires the socket contract for the relayers’ signature values submitted in the preceding phase.\nAttaches the majority number of signatures and delivers it to the next socket contract.\nPrimary relayer\nInquires the socket contract for the relayers’ signature values submitted in the preceding phase.\nInquires the socket contract for the relayers’ signature values submitted in the preceding phase.\nAttaches the majority number of signatures and delivers it to the next socket contract.\nAttaches the majority number of signatures and delivers it to the next socket contract.\nSecondary relayers\nIf the primary relayer’s successful event delivery cannot be verified after t seconds, execute the primary relayer process instead.\nSecondary relayers\nIf the primary relayer’s successful event delivery cannot be verified after t seconds, execute the primary relayer process instead.\nIf the primary relayer’s successful event delivery cannot be verified after t seconds, execute the primary relayer process instead.\nThe socket contract emits the next CCC-event upon verifying the majority of the signatures received.\nApplications\nCCCP allows external chain users to use Bifrost Network DApp services. For example, let us say that f(x) is “Lending::Deposit” installed in the Bifrost Network. In this case, an Ethereum user can simply deposit tokens to the Ethereum socket contract, and this action will automatically deposit tokens to the lending service on the Bifrost Network. To give another example, let us say that f(x) is “Swap” in the Bifrost Network. In this case, a user can acquire some Bifrost Network’s token B by depositing some Ethereum’s token A through the inbound protocol, and then withdraw Avalanche’s token B through the outbound protocol. This implements a cross-chain swap.\nUltimately, the CCCP of the Bifrost Network allows users to enjoy DeFi services with relatively low fees and fast speed, and easily transfer assets between chains.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bifrost-network-architecture/cross-chain-communication-protocol-cccp"
  },
  {
    "title": "Oracle Service",
    "content": "BIFROST NETWORK ARCHITECTURE\nOracle Service\nOracle Service Architecture\nThe Bifrost Network uses relayers to gather external oracle reports, which are validated and provided to the Bifrost ecosystem by oracle manager contracts. The process of collecting and distributing data through the Bifrost oracle service is illustrated in Figure 1.\nData Collection\nRelayers on the Bifrost Network are responsible for collecting readings from various sources, both on-chain and off-chain, based on the configuration of the oracle. They then submit this data to the oracle manager contract for validation and distribution within the Bifrost ecosystem.\nTwo Types of Data\nThe Bifrost oracle service supports two types of data: exact data, such as the block hash of the latest Bitcoin block, and aggregatable data, such as token prices. For exact data, the oracle manager contract verifies that a quorum of relayers has submitted the same report. For aggregatable data, the oracle manager calculates the average of the submitted reports after eliminating outliers.\nData Feed\nAn oracle manager is a smart contract that serves as a data feed in the Bifrost Network. It verifies and processes data from multiple sources, then provides the final results along with metadata, such as the collection round number, to ensure the timeliness and reliability of the report.\nFeatures\nSource-specific Collection\nRelayers may be configured to follow different approaches in the data collection process, including the triggers for collection and post-processing procedures, depending on the specific data sources being utilized.\nToken prices are regularly collected from both centralized and decentralized exchanges, and outliers are removed through price deviation verification during post-processing. The collection of Bitcoin block hashes, on the other hand, is triggered by new block notifications. In the event of an unexpected chain reorganization in Bitcoin, relayers can correct obsolete block hashes during the post-processing step.\nPrice Aggregation and Correction\nRelayers combine prices from centralized and decentralized exchanges and adjust them to reflect market conditions more accurately. A volume-weighted average is calculated for prices from centralized exchanges, as the daily trading volume is known. Prices from decentralized exchanges are averaged without considering trading volume but are used to improve the volume-weighted average by taking the median between the two average values.\nReorg-aware Bitcoin Post-processing\nIn Bitcoin, there is a risk of unexpected large-scale block reorganization events occurring. To address this, we designed the committed value storage in the oracle manager contract to be adjustable when relayers resubmit the updated hash values of reorganized blocks.\nEasy DApp Integration\nChainlink is the most widely-used blockchain oracle service. To minimize the learning curve for using Bifrost's oracle service, it offers an interface compatible with that of Chainlink. As a result, DApp developers can utilize our oracle service without the need to acquire additional knowledge.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bifrost-network-architecture/oracle-service"
  },
  {
    "title": "Running a Node",
    "content": "Running a Node\nAnyone can become a validator or nominator by depositing BFC into the BIFROST Network. Validators generate new blocks and verify blocks generated by other validators in the set. Active validators receive rewards at the end of each round for performing these tasks correctly. In every round of block generation, validator candidates are ranked based on the sum of their self-bonded stake and delegated deposits from their nominators. The top n candidates in the ranking become active validators that can participate in the consensus process in the next round to earn rewards.\nTwo-tier Node Architecture\nNodes of the BIFROST Network are similar to typical Substrate-based nodes, but the interoperability nature of the network also requires some additional features. Thus, the BIFROST Network consists of two-tier nodes:\nBasic node of the first tier plays the role of block producing and acts as an archive node. Basic nodes are typical Substrate-based nodes.\nFull-node of the second tier has the features of the basic node and additionally plays the role of a relayer that interconnects blockchains. \nBasic node\n- Block production / Finalization (AURA / GRANPA)\n- Archive mode\nFull node\n- Block production / Finalization (AURA / GRANPA)\n- Archive mode\n- Cross-chain relaying\n- Price feed collection (on-chain / off-chain)\n\"Controller\" and \"Stash\" Keys\nTwo types of accounts are required to run a validator (both full node and basic node), as well as to become a nominator – \"Controller\" and \"Stash\" accounts. They are distinguished by their intended use, not by an underlying cryptographic difference.\nController Key\nThe controller key is a semi-online key that will be in the direct control of a user and used to submit manual extrinsics. For validators or nominators, this means that the controller key will be used to start or stop validating or nominating. Controller keys should hold some BFC to pay for fees, but they should not be used to hold huge amounts or life savings. Since they will be exposed to the internet with relative frequency, they should be treated carefully and occasionally replaced with new ones.\nStash Key\nThe stash key is a key that will, in most cases, be a cold wallet, existing on a piece of paper in a safe or protected by layers of hardware security. It should rarely, if ever, be exposed to the internet or used to submit extrinsics. The stash key is intended to hold large amounts of funds. It should be thought of as a savings account at a bank, which is ideally only ever touched in urgent conditions. Or, perhaps a more apt metaphor is to think of it as buried treasure, hidden on some random island and only known by the pirate who originally hid it.\nSince the stash key is kept offline, it must be set to have its funds bonded to a particular controller. For non-spending actions, the controller has the funds of the stash behind it. For example, in nominating, staking, or voting, the controller can indicate its preference with the weight of the stash. It will never be able to actually move or claim the funds in the stash key. However, if someone does obtain your controller key, they could use it for slashable behavior, so you should still protect it and change it regularly.\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node"
  },
  {
    "title": "Basic-Node Requirements",
    "content": "RUNNING A NODE\nBasic-Node Requirements\nBasic node operators stake BFC to verify and create blocks. Validators should expect staking rewards if they stake in the network for at least three months. The longer the staking period, the higher the rewards. The rewards consist of:\nSelf-staking rewards which accrue in proportion to the number of staked tokens\nSelf-staking rewards which accrue in proportion to the number of staked tokens\nTransaction fees\nTransaction fees\nA portion of nominators' staking rewards (optional)\nA portion of nominators' staking rewards (optional)\nTechnical Requirements\nCPU\n- x86-64 compatible\n- Intel Ice Lake, or newer (Xeon or Core series); AMD Zen3, or newer (EPYC)\n- Simultaneous multithreading disabled (Hyper-Threading on Intel, SMT on AMD)\n- Prefer single-threaded performance over a higher cores count\nStorage\nAn NVMe SSD of 1 TB (As it should be reasonably sized to deal with blockchain growth)\nRAM\n16GB DDR4\nOperating system requirements (Ubuntu 18.04 ~ 22.04 Recommended)\nLinux Kernel 5.16 or later\nLinux Kernel 5.16 or later\nAmazon Linux 2: 5.10.130-118.517.amzn2.x86_64 or later\nAmazon Linux 2: 5.10.130-118.517.amzn2.x86_64 or later\nBonding Requirements\nMinimum self-bond\n50,000 BFC\nMinimum voting power (self-bond + total nominated BFC)\n50,000 BFC\nOperating Requirements\nAccount Management\nValidators should securely manage two accounts, Stash and Controller accounts, for self-bonding deposit and consensus participation, respectively.\nStash account: An EVM account for the self-bonding deposit.\nStash account: An EVM account for the self-bonding deposit.\nController account: An EVM account for consensus participation. It should have enough balance for transaction fees used in certain operations.\nController account: An EVM account for consensus participation. It should have enough balance for transaction fees used in certain operations.\nRequired Credentials\nValidators require three types of keys as follows:\nAURA key for block production\nAURA key for block production\nGRANDPA key for block finalization\nGRANDPA key for block finalization\n“Imonline” key to check the node availability\n“Imonline” key to check the node availability\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/basic-node-requirements"
  },
  {
    "title": "Full-Node Requirements",
    "content": "RUNNING A NODE\nFull-Node Requirements\nFull nodes share all the features of the basic nodes and additionally facilitate Cross-Chain Communication. To do that, they must keep access to external blockchains and off-chain data feed for price oracles. Full node rewards consist of:\nSelf-staking rewards which accrue in proportion to the number of staked tokens\nSelf-staking rewards which accrue in proportion to the number of staked tokens\nTransaction fees\nTransaction fees\nFees from cross-chain transactions\nFees from cross-chain transactions\nA portion of nominators' staking rewards (optional)\nA portion of nominators' staking rewards (optional)\nTechnical Requirements\nCPU\n- x86-64 compatible\n- Intel Ice Lake, or newer (Xeon or Core series); AMD Zen3, or newer (EPYC)\n- Simultaneous multithreading disabled (Hyper-Threading on Intel, SMT on AMD)\n- Prefer single-threaded performance over a higher cores count\nStorage\nAn NVMe SSD of 1 TB (As it should be reasonably sized to deal with blockchain growth)\nRAM\n32GB DDR4\nOperating system requirements (Ubuntu 18.04 ~ 22.04 Recommended)\nLinux Kernel 5.16 or later\nLinux Kernel 5.16 or later\nAmazon Linux 2: 5.10.130-118.517.amzn2.x86_64 or later\nAmazon Linux 2: 5.10.130-118.517.amzn2.x86_64 or later\nBonding Requirements\nMinimum self-bond\n100,000 BFC\nMinimum voting power (self-bond + total nominated BFC)\n100,000 BFC\nOperating Requirements\nAccount Management\nValidators should securely manage three accounts, Stash, Controller, and Relayer accounts, for self-bonding deposit and consensus participation, respectively.\nStash account: An EVM account for the self-bonding deposit.\nStash account: An EVM account for the self-bonding deposit.\nController account: An EVM account for consensus participation. It should have enough balance for transaction fees used in operations.\nController account: An EVM account for consensus participation. It should have enough balance for transaction fees used in operations.\nRelayer account: An EVM account for cross-chain action participation. It should have enough balance for transaction fees used in operations.\nRelayer account: An EVM account for cross-chain action participation. It should have enough balance for transaction fees used in operations.\nRequired Credentials\nValidators require three types of keys as follows:\nAURA key for block production\nAURA key for block production\nGRANDPA key for block finalization\nGRANDPA key for block finalization\n“Imonline” key to check the node availability\n“Imonline” key to check the node availability\nExternal Source Access\nFull nodes should set up Web3 providers to all the external blockchains supported by the Bifrost Network via reusing their blockchain RPC nodes or employing external services (e.g. Infura or NodeReal).\nPrice Feed\nThe full-node validators collect on-chain and off-chain data for price oracles.\nOn-chain price feed: ChainLink\nOn-chain price feed: ChainLink\nOff-chain API: CoinGecko, Upbit, Binance, Gate.io, Kucoin\nOff-chain API: CoinGecko, Upbit, Binance, Gate.io, Kucoin\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/full-node-requirements"
  },
  {
    "title": "Validator Account Management",
    "content": "RUNNING A NODE\nValidator Account Management\nTime-related parameters\nIn the Bifrost Network, there are several parameters related to time with which node operators need to be familiar. You must familiarize yourself with these parameters prior to account management.\nRound duration\n6 hours\nSession duration\n15 minutes\nBond less delay\n2 rounds (Approx. 12 hours)\nLeave candidates delay\n2 rounds (Approx. 12 hours)\nPolkadot.js account setup\nValidator node operators must deposit self-bonds through their stash accounts to operate the nodes. In some cases, the deposited BFC may be withdrawn, and additional deposits may need to be made. To perform these actions, node operators must utilize the administrator page provided by Polkadot which can be accessed via the following link.\npolkadot.js/apps\npolkadot.js/apps\nUpon accessing the link, a page similar to the image below will show up.\nUpon successful access, you must register your stash and controller account that is currently being used for your validator node activities on the page. First, click on the \"Add account\" button located near the center of the page.\nIf the \"Add account\" button does not show up or as disabled, then access the \"Settings\" tab and set the \"in-browser account creation\" option to \"Allow local in-browser account storage\". This option will allow to store your accounts to your local web browser.\nClick on the button to switch to the next page. Then, enter the secret key or mnemonic seed of the account in the input box, check the check box at the bottom, and click on the \"Next\" button to continue.\nOn the next page, you must enter the name and password of the account you wish to register. As the name of the account does not affect the system in any way and is visible only in your local environment, set it to a name that is easily recognizable. Also, as the password must be entered once for verification before transaction transmission through the polkadot.js app page, make sure to store it safely. Once you have entered all the information, click on the \"Next\" button to proceed to the next step.\nOn the next page, you can create a backup file for the account you wish to register. The backup file is in JSON format, and with this, you can restore your account if necessary by clicking on the \"Restore JSON\" button located in the center of the \"Accounts\" page. Clicking on the \"Next\" button closes the window and the backup file will be downloaded. Once all processes have been completed, you will be able to check that the registered account has been added to the \"accounts\" list.\nAll processes specified above must be performed once each for the stash account and controller account.\nSelf-Bond Management\nValidator node operators can access and manage their own self-bonds. This means that if you completely own the stash and controller accounts in use, you can make additional deposits or withdrawals.\nBond More\nIn order to proceed with the additional deposit, your stash account must be registered on the polkadot.js app page in advance, and the account must hold enough BFC for the additional deposit you wish to make.\nFirst, click on the \"Developer\" tab at the top and access the \"Extrinsic\" page.\nWhen you move to the link, you will see the following page. Proceed with the following steps in order.\nSelect your own stash account.\nSelect your own stash account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"candidateBondMore\" extrinsic.\nSelect the \"candidateBondMore\" extrinsic.\nEnter the amount of BFC you want to deposit in Wei units. If you want to deposit 100 BFC, you must add 18 zeros to 100.\nEnter the amount of BFC you want to deposit in Wei units. If you want to deposit 100 BFC, you must add 18 zeros to 100.\nClick on the \"Submit Transaction\" button.\nClick on the \"Submit Transaction\" button.\nIf you enter the account password and click on the \"Sign and Submit\" button at the bottom, the transaction will be sent and the additional deposit result will be immediately reflected.\nThe reflected result can be found on the next page.\nBond Less\nTo proceed with partial withdrawal, both your stash account and controller account must be registered on the polkadot.js app page in advance. The entire withdrawal process consists of two stages. First, you must perform the \"Schedule Withdrawal\" process with the controller account. At this time, even if the request is successfully processed, the withdrawal cannot be executed immediately. You must wait for a certain number of rounds. (\"Bond less delay\") If you have finished waiting, you must finally execute the \"Execute withdrawal\" process with your stash account to complete the actual withdrawal. All actions are performed on the \"Extrinsic\" page under the \"Developer\" tab.\nSchedule Bond Less\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"scheduleCandidateBondLess\" extrinsic.\nSelect the \"scheduleCandidateBondLess\" extrinsic.\nEnter the amount of BFC to be partially withdrawn in Wei units. If you want to withdraw 100 BFCs, you must add 18 zeros to 100.\nEnter the amount of BFC to be partially withdrawn in Wei units. If you want to withdraw 100 BFCs, you must add 18 zeros to 100.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nCancel Schedule Bond Less\nYou can also cancel the withdrawal request made in advance. In the case of cancellation, calls can be made regardless of delays.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"cancelCandidateBondLess\" extrinsic.\nSelect the \"cancelCandidateBondLess\" extrinsic.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nExecute Bond Less\nSelect your own stash account.\nSelect your own stash account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"executeCandidateBondLess\" extrinsic.\nSelect the \"executeCandidateBondLess\" extrinsic.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nLeave Validators\nIf you wish to quit your validator activity and leave, your stash account and controller account must be registered on the polkadot.js app page in advance. If you choose to leave, all deposited self-bond will be returned to your stash account, and all nominations will also be returned to the nominators.\nThe entire process of exit consists of two steps, as with partial withdrawal. You must first perform the \"Schedule Leave\" process with the controller account. At this time, even if the request is successfully processed, exit cannot be immediately executed. You must wait for a certain number of rounds. (\"Leave candidates delay\") If you have finished waiting, you must finally perform the \"Execute Leave\" process with your stash account to complete the actual exit.\nIf a validator node operation is terminated without proceeding to exit, a penalty may be applied and some of your assets may be deducted. Therefore, be aware of this process to exit and guard your assets safely.\nSchedule Leave\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"scheduleLeaveCandidates\" extrinsic.\nSelect the \"scheduleLeaveCandidates\" extrinsic.\nEnter the current number of validators. If the value is greater than or equal to the current number of validators, it will operate normally.\nEnter the current number of validators. If the value is greater than or equal to the current number of validators, it will operate normally.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nCancel Schedule Leave\nYou can also cancel the request for leave in advance. In the case of cancellation, calls can be made regardless of the delay.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"cancelLeaveCandidates\" extrinsic.\nSelect the \"cancelLeaveCandidates\" extrinsic.\nEnter the current number of validators. If the value is greater than or equal to the current number of validators, it will operate normally.\nEnter the current number of validators. If the value is greater than or equal to the current number of validators, it will operate normally.\nClick on the \"Submit Transaction\" button and send the transaction through password entry and signature.\nClick on the \"Submit Transaction\" button and send the transaction through password entry and signature.\nExecute Leave\nSelect your own stash account.\nSelect your own stash account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"executeLeaveCandidates\" extrinsic.\nSelect the \"executeLeaveCandidates\" extrinsic.\nEnter the number of nominators nominated for yourself. If the value is greater than or equal to the current number of nominators, it operates normally.\nEnter the number of nominators nominated for yourself. If the value is greater than or equal to the current number of nominators, it operates normally.\nClick on the \"Submit Transaction\" button and send the transaction through password entry and signature.\nClick on the \"Submit Transaction\" button and send the transaction through password entry and signature.\nIf you have finished executing the exit, you may completely shut down the validator node that was in operation.\nSet Auto-Compound Destination\nThe Bifrost Network provides Auto-Compounding functionality. This optional feature allows both validators and nominators to decide whether to receive their round rewards in their wallets (\"Account\") or to immediately add them to their stakes (\"Staked\").\nThe “Account” option receives round rewards paid in each round to the wallet you deposited. In this case, there is no change in one's self-bond, and the token paid can be used immediately in the wallet without a special lock.\nThe “Staked” option automatically makes an additional deposit immediately to your self-bond for the round reward you receive for each round. It is set to the default value of all network participants (validators + nominators).\nProceed with the following steps in order.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"setCandidateRewardDst\" extrinsic.\nSelect the \"setCandidateRewardDst\" extrinsic.\nSelect the \"Staked\" or \"Account\" option.\nSelect the \"Staked\" or \"Account\" option.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nSet Commission Rate\nAll validators are able to set a commission rate according to their tier.\nFull Node\n0% ~ 100% (default: 50%)\nBasic Node\n0% ~ 20% (default: 10%)\nProceed with the following steps in order.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"setValidatorCommission\" extrinsic.\nSelect the \"setValidatorCommission\" extrinsic.\nEnter the rate you want to change. For example, if you wish to change it to 60%, you must add 7 zeros to 60.\nEnter the rate you want to change. For example, if you wish to change it to 60%, you must add 7 zeros to 60.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nIf you wish to pause your validator activity for a certain period of time without unbonding your self-bonds, you can change your node status to offline. When switching to offline status, you should be familiar with the following.\nSelf-bonds and nominations are not withdrawn and will remain.\nSelf-bonds and nominations are not withdrawn and will remain.\nAdditional deposits and partial withdrawals of your self-bond, and nominations will be possible.\nAdditional deposits and partial withdrawals of your self-bond, and nominations will be possible.\nYou can leave the validator set only after switching back to online status.\nYou can leave the validator set only after switching back to online status.\nYou cannot be selected as an active validator during the round update.\nYou cannot be selected as an active validator during the round update.\nWhen you change your status to offline while operating as an active validator, you will still be paid for your active share.\nWhen you change your status to offline while operating as an active validator, you will still be paid for your active share.\nAs the offline request is reflected after one session, at least one session must be kept online to prevent any penalties.\nAs the offline request is reflected after one session, at least one session must be kept online to prevent any penalties.\nProceed with the following steps in order.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"goOffline()\" extrinsic.\nSelect the \"goOffline()\" extrinsic.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nSet Validator Online\nIf a node in operation has switched to offline status, or has been removed from the round due to continuous inactivity without an offline request, the node must be switched back to online status to proceed with normal validator activity. If not, the validator will not be selected as an active validator.\nProceed with the following steps in order.\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"goOnline()\" extrinsic.\nSelect the \"goOnline()\" extrinsic.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nSet Validator Tier\nIt is possible to change the tier of the node in operation. When changing from the basic node to the full node, the following conditions must be satisfied.\nAdditional deposits must be made if the minimum required amount of self-bonds is not met.\nAdditional deposits must be made if the minimum required amount of self-bonds is not met.\nA new Ethereum account is required for relayer operation.\nA new Ethereum account is required for relayer operation.\nA relayer must be operated after changing the tier.\nA relayer must be operated after changing the tier.\nProceed with the following steps in order.\nSelect your own stash account.\nSelect your own stash account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"setValidatorTier()\" extrinsic.\nSelect the \"setValidatorTier()\" extrinsic.\nIf an additional deposit of self-bonds is required, enter the BFC amount in wei units in the more parameter. Otherwise, enter 0.\nIf an additional deposit of self-bonds is required, enter the BFC amount in wei units in the more parameter. Otherwise, enter 0.\nSelect the tier of the node to which you wish to change. (Select Full or Basic)\nSelect the tier of the node to which you wish to change. (Select Full or Basic)\nSelect the relayer account when changing to a full node. If not, toggle the \"include option\" button located on the right to disabled.\nSelect the relayer account when changing to a full node. If not, toggle the \"include option\" button located on the right to disabled.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nIf the modification has successfully been processed, your tier will be updated as the one you have selected. But your node will still be operating as the previous tier until the current round ends.\n(Re-)Set Controller Account\nSince controller accounts for each validator is public to the network due to validator activities, there could be a chance that an attacker exploits or takeover your account. Although, since validator accounts are divided to multiple accounts, the attacker won't be able to withdraw your self-bonds. But for future safety we suggest to let exposed controller accounts to be replaced. To do so, the following conditions must be satisfied.\nA new controller account must be prepared contained with some funds for transaction payments. This new account will later be replaced from your previous account.\nA new controller account must be prepared contained with some funds for transaction payments. This new account will later be replaced from your previous account.\nDouble check if your previous account has any leftover funds. If so transfer to any other safe account.\nDouble check if your previous account has any leftover funds. If so transfer to any other safe account.\nNow to (re-)set your controller account, proceed with the following steps in order.\nFirst, access to your tools directory that was used to setup your validator node.\nFirst, access to your tools directory that was used to setup your validator node.\nExecute the set_session_keys CLI command to register a new set of on-chain session keys. At this point, the controllerPrivate option must be your new accounts private key.\nExecute the set_session_keys CLI command to register a new set of on-chain session keys. At this point, the controllerPrivate option must be your new accounts private key.\nNow, access the polkadot.js web page and move on to the extrinsics tab. In prior, your new account must be registered to polkadot.js\nNow, access the polkadot.js web page and move on to the extrinsics tab. In prior, your new account must be registered to polkadot.js\nSelect your own stash account.\nSelect your own stash account.\nSelect the \"bfcStaking\" pallet.\nSelect the \"bfcStaking\" pallet.\nSelect the \"setController()\" extrinsic.\nSelect the \"setController()\" extrinsic.\nSet the new parameter to your new account.\nSet the new parameter to your new account.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nAfter the transaction has been successfully executed, the actual account replacement (state change) will be applied at the beginning of the next round.\n(Re-)Set Relayer Account\nIn case of full node operators, your relayer account can be replaced. To do so, the following conditions must be satisfied.\nA new relayer account must be prepared contained with enough funds for cross-chain actions. This new account will later be replaced from your previous account.\nA new relayer account must be prepared contained with enough funds for cross-chain actions. This new account will later be replaced from your previous account.\nDouble check if your previous account has any leftover funds. If so transfer to any other safe account.\nDouble check if your previous account has any leftover funds. If so transfer to any other safe account.\nNow to (re-)set your relayer account, proceed with the following steps in order.\nFirst, access the polkadot.js web page and move on to the extrinsics tab. In prior, your new account must be registered to polkadot.js\nFirst, access the polkadot.js web page and move on to the extrinsics tab. In prior, your new account must be registered to polkadot.js\nSelect your own controller account.\nSelect your own controller account.\nSelect the \"relayManager\" pallet.\nSelect the \"relayManager\" pallet.\nSelect the \"setRelayer()\" extrinsic.\nSelect the \"setRelayer()\" extrinsic.\nSet the new parameter to your new account.\nSet the new parameter to your new account.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nClick on the \"Submit Transaction\" button and send the transaction by entering your password and signing.\nAfter the transaction has been successfully executed, the actual account replacement (state change) will be immediately applied. Due to the replacement, your running relayer program's account setup must be modified as well.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/validator-account-management"
  },
  {
    "title": "Guide for Operators",
    "content": "RUNNING A NODE\nGuide for Operators\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators"
  },
  {
    "title": "Setting up an Endpoint Node",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSetting up an Endpoint Node\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-an-endpoint-node"
  },
  {
    "title": "Using Docker",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP AN ENDPOINT NODE\nUsing Docker\nIntroduction\nThe endpoint node is a node that provides a JSON-RPC interface for interacting with the Bifrost Network. Through the provided RPC methods, users or many projects can easily interact with the blockchain data. In addition to the Ethereum standard RPC interface, Geth's debug and txpool APIs and OpenEthereum's trace APIs are also selectively enabled, providing a non-standard RPC interface for bringing more detailed information about transaction processing.\nThe endpoint node consists of two modes. The first mode is the archive mode which stores status information on all blocks from the genesis block to the present. This mode can be used when you need to request historical data. The second mode is the non-archive mode which, unlike the archive mode, stores chain information only by the specified number of blocks. Therefore, it is not possible to request chain information outside of the set range.\nAs endpoint nodes do not participate in the consensus algorithm, there is no need to deposit BFC's and separate account settings, and unlike validator nodes do not lead to any special rewards.\nInstall Requirements\nFirst, create a local directory to store the chain data of the Bifrost Network. This directory stores all block information collected from the genesis block to the present.\nYou must set the ownership and permissions for the directory you created. If you wish to set it to a specific user, you can run the command written in “case 1” and change DOCKER_USER to the actual user name to run Docker later. If you wish to set it as the currently connected user, you can run the command written in \"case 2\".\nRun the Node Container\nTo run an endpoint node with the archive mode enabled, you can run the following command.\nConversely, to run an endpoint node with the non-archive mode enabled, you can run the following command. In this case, it is necessary to determine the maximum number of past blocks to be indexed, and the number of blocks may be specified after the --state-pruning option.\nCheck Logs\nTo check your running bifrost-node container logs, execute the command below.\nIf the Docker image is successfully pulled, and the validator node is executed, the chain information will be shown as the following.\nSince chain data needs to be synced starting from the genesis block, the information that it is currently syncing will be shown as the following output. You can proceed to the next steps only when the sync is complete, and it may take up to several days at most.\nTo quickly synchronize your chain data, follow this link.\nWhen all the chain data sync is complete, newly generated blocks are synchronized one by one at every block time as follows.\nUpdate Node Client\nAs Bifrost Network development continues, it will sometimes be necessary to upgrade your node client. Node operators will be notified on our Discord channel or by personal contacts when upgrades are available and whether they are necessary (some client upgrades are optional). \nBefore upgrading your node client, please keep a backup file of your chain data to prevent any further data, keys, or credential losses.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-an-endpoint-node/using-docker"
  },
  {
    "title": "Using Systemd",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP AN ENDPOINT NODE\nUsing Systemd\nInstall Requirements\nIn addition to using the Docker image, there are ways to run nodes with the Linux system daemon as a Systemd service. The service will work on most Linux operating systems. However, Debian/Ubuntu is the only environment in which all tests have been completed, and the manual has been written based on this environment.\nFirst, create a service account to run the node service.\nNext, create a local directory to store the chain data of the Bifrost Network. This directory contains the node binary and block information collected from the genesis block to the present.\nAfter you download the latest node execution binary and move it to the directory you created earlier, you must set permissions of the binary and ownership of the directory. You can check the latest releases by going to our GitHub repository under the releases page.\nRun the Node Service\nNext, you need to create a Systemd configuration file. In the example below, change YOUR_NODE_NAME to the desired name of your node service, and save the file in the following directory.\nConversely, to run an endpoint node with non-archive mode enabled, it is necessary to determine the maximum number of past blocks to be indexed, and the number of blocks may be specified after the --state-pruning option.\nNow, with the two lines of the command below, the node service will run in the background.\nCheck Logs\nTo check your running bifrost-node service logs, execute the command below.\nIf the node service has successfully been executed, the chain information will be shown as the following.\nSince chain data needs to be synced starting from the genesis block, the information that it is currently syncing will be shown as the following output. You can proceed to the next steps only when the sync is complete, and it may take up to several days at most.\nTo quickly synchronize your chain data, follow this link.\nWhen the chain data is completely synchronized, newly generated blocks will start to synchronize one by one at every block time as follows.\nUpdate Node Client\nAs Bifrost Network development continues, it will sometimes be necessary to upgrade your node client. Node operators will be notified on our Discord channel or by personal contacts when upgrades are available and whether they are necessary (some client upgrades are optional). \nBefore upgrading your node client, please keep a backup file of your chain data to prevent any further data, keys, or credential losses.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-an-endpoint-node/using-systemd"
  },
  {
    "title": "Setting up a Validator Node",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSetting up a Validator Node\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-validator-node"
  },
  {
    "title": "Using Docker",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP A VALIDATOR NODE\nUsing Docker\nInstall Requirements\nAll types of Bifrost Network nodes can be executed easily through Docker. Docker must be pre-installed in the environment you wish to run the node. Once installed, you can proceed with the following process.\nFirst, create a local directory to store the chain data of the Bifrost Network. This directory stores all block information collected from the genesis block to the present and additional session keys of the corresponding validator node.\nYou must set the ownership and permissions for the directory you created. If you wish to set it to a specific user, you can run the command written in “case 1” and change DOCKER_USER to the actual user name to run Docker later. If you want to set it as the currently connected user, you can run the command written in \"case 2\".\nRun the Node Container\nTo run the validator node, you can simply run the following command. In this case, YOUR_NODE_NAME is a parameter indicating the name of the node to be executed and should be modified to the desired name.\nCheck Logs\nTo check your running bifrost-node container logs, execute the command below.\nIf the Docker image is successfully pulled, and the validator node is executed, the chain information will be shown as the following.\nSince chain data needs to be synced starting from the genesis block, the information that it is currently syncing will be shown as the following output. You can proceed to the next steps only when the sync is complete, and it may take up to several days at most.\nTo quickly synchronize your chain data, follow this link.\nWhen the chain data is completely synchronized, newly generated blocks will start to synchronize one by one at every block time as follows.\nKey Setup and Bonding\nWe now proceed with the key setting that is required to allow the validator node to perform the process of block generation and finalization. From this step, the chain data synchronization of the running node must be completed.\nFirst, validator nodes essentially require two Ethereum-style accounts, the controller and stash accounts, and in the case of full nodes, an additional relayer account is required.\nA stash account is an account that holds a certain amount of self-bond that must be deposited in the system so that the delegated account can act as a validator. The role of a stash account is to deposit self-bonds and delegate one account (controller) to perform validator activities publicly on its behalf.\nThe controller account is the delegated target from the stash account and is the prime account that acts as a validator. The role of the controller is an account that is dedicated to all activities such as session key registration, block generation, finalization, etc., and requires minimal assets to pay transaction fees.\nIf you need to create a new account, you can run the following commands.\nAfter executing the command, the available new validator accounts will be printed as follows. You must send enough BFC to each account that meets the requirements to proceed to the next process.\nNext, the validator node must issue and register session keys to be used in the consensus algorithm. The process can be performed by executing the following command. Make sure that you are in the tools directory.\nThis command will generate three session keys for your node. Each key has their own purpose. Aura is for block creation, grandpa is for block finalization, and ImOnline is for node liveness. The generated keys will be stored in your chain data directory. The directory path will look like this: /var/lib/bifrost-data/chains/{testnet|mainnet}/keystore.\nFinally, it is necessary to deposit the self-bonds of the validator node to form the initial voting power. The process can be performed by executing the following command.\nIf you have successfully completed every process mentioned above, the amount of BFC deposited from the stash account will be deducted from the wallet, and your controller account will participate in the active validator update process in the next round. You can check whether or not you successfully joined the validator pool on the following page.\nIf the tier of the validator node to be operated is a full node, it must be operated together with the relayer. The manual for relayer setup can be found in the \"Setting up a Relayer\" section.\nUpdate Node Client\nAs Bifrost Network development continues, it will sometimes be necessary to upgrade your node client. Node operators will be notified on our Discord channel or by personal contacts when upgrades are available and whether they are necessary (some client upgrades are optional). \nBefore upgrading your node client, please keep a backup file of your chain data to prevent any further data, keys, or credential losses.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-validator-node/using-docker"
  },
  {
    "title": "Using Systemd",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP A VALIDATOR NODE\nUsing Systemd\nInstall Requirements\nIn addition to using the Docker image, there are ways to run nodes with the Linux system daemon as a Systemd service. The service will work on most Linux operating systems. However, Debian/Ubuntu is the only environment in which all tests have been completed, and the manual has been written based on this environment.\nFirst, create a service account to run the node service.\nNext, create a local directory to store the chain data of the Bifrost Network. This directory will contain the node binary and all block information collected from the genesis block to the present and additional session keys of the corresponding validator node.\nAfter you download the latest node execution binary and move it to the directory you created earlier, you must set permissions of the binary and ownership of the directory. You can check the latest releases by going to our GitHub repository under the releases page.\nRun the Node Service\nNext, you need to create a Systemd configuration file. In the example below, change YOUR_NODE_NAME to the desired name of your node service, and save the file in the following directory.\nNow, with the two lines of the command below, the node service will run in the background.\nCheck Logs\nTo check your running bifrost-node service logs, execute the command below.\nIf the node service has successfully been executed, the chain information will be shown as the following.\nSince chain data needs to be synced starting from the genesis block, the information that it is currently syncing will be shown as the following output. You can proceed to the next steps only when the sync is complete, and it may take up to several days at most.\nTo quickly synchronize your chain data, follow this link.\nWhen the chain data is completely synchronized, newly generated blocks will start to synchronize one by one at every block time as follows.\nKey Setup and Bonding\nThe scripts that we provide to proceed with the remaining detailed setup processes are written in Node.js. Install the required packages and execute the following commands to receive the script.\nWe now proceed with the key setting required to allow the validator node to perform the process of block generation and finalization. From this step onwards, the chain data synchronization of the running node must be completed.\nFirst, validator nodes essentially require two Ethereum-style accounts, the controller and stash accounts, and in the case of the full nodes, an additional relayer account is required. The stash account must have enough BFC to deposit as much as the initial self-bond, and the controller account only needs enough balance to pay for some transactions. If you need to create a new account, you can run the following commands. Make sure that you are in the tools directory.\nAfter executing the command, the available new validator accounts will be printed as follows. You must send enough BFC to each account that meets the requirements to proceed to the next process.\nNext, the validator node must issue and register session keys to be used in the consensus algorithm. The process can be performed by executing the following command. \nThis command will generate three session keys for your node. Each key has their own purpose. Aura is for block creation, grandpa is for block finalization, and ImOnline is for node liveness. The generated keys will be stored in your chain data directory. The directory path will look like this: /var/lib/bifrost-data/chains/{testnet|mainnet}/keystore.\nFinally, it is necessary to deposit the self-bonds of the validator node to form the initial voting power. The process can be performed by executing the following command.\nIf all of the above processes have been successfully completed, the amount of BFC deposited from the stash account will be deducted from the wallet, and your controller account will participate in the active validator update process at the next round. You can check whether or not you successfully joined the validator pool on the following page.\nIf the tier of the validator node to be operated is a full node, it must be operated with the relayer. The manual for relayer setup can be found in the \"Setting up a Relayer\" section below.\nUpdate Node Client\nAs Bifrost Network development continues, it will sometimes be necessary to upgrade your node client. Node operators will be notified on our Discord channel or by personal contacts when upgrades are available and whether they are necessary (some client upgrades are optional). \nBefore upgrading your node client, please keep a backup file of your chain data to prevent any further data, keys, or credential losses.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-validator-node/using-systemd"
  },
  {
    "title": "Setting up a Relayer",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSetting up a Relayer\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-relayer"
  },
  {
    "title": "bifrost-relayer.rs",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP A RELAYER\nbifrost-relayer.rs\nWhat is bifrost-relayer.rs?\nWe recently introduced a Rust implementation of the CCCP-Relayer for the Bifrost Network. The new relayer has been reengineered to enhance overall performance and robustness across multiple blockchains. It retains the same functions as the Python version, processing cross-chain transactions and facilitating data transfers (e.g., feeding price information) from one blockchain to another.\nThe following section will guide you through the setup process about the Rust implementation of the Bifrost network's relayer.\nInstall Requirements\nTo initiate the bifrost-relayer, certain dependencies must be manually installed. Both the executable binary file and the configuration YAML file are essential for all environments and operators.\nFirst, install the latest bifrost-relayer release binary. You can check the latest releases by going to our GitHub repository under the releases page.\nIn order to execute the binary, the permission of the file has to be updated.\nThen, install the configuration YAML file. This file serves as an example for a quick start. Given the minor differences between Testnet and Mainnet environments, it's crucial to use the appropriate file for the corresponding network.\nConfiguration Setup\nNext, the configuration YAML file contains certain parameters that the operator has to set. For instance, variables such as your relayer private key and each EVM provider's RPC endpoints depends to the operator itself, thus these values should be manually set.\nYou should prepare RPC endpoints for the following blockchain networks. There are two options for this: 1) operating your own blockchains nodes, or 2) utilizing services that offers RPC endpoints. You can find node providers on the links below. It’s crucial that each node must be archive-mode enabled.\nBifrost (Must be priorly self-operating and fully synced)\nBifrost (Must be priorly self-operating and fully synced)\nEthereum\nEthereum\nBinance Smart Chain\nBinance Smart Chain\nPolygon\nPolygon\nBase\nBase\nArbitrum\nArbitrum\nBitcoin\nBitcoin\nConfiguration Templates\nConfiguration Parameters\nThe following table presents customizable parameters for the relayer. You can change each parameter according to your environment. However, we highly recommend to use the default values specified in the template except for fields that are not checked in the \"Template Provided\" column. Furthermore, \"Template Provided\" merely serves as an example, thus you must change the correct values for certain parameters (e.g., your private key).\nGenerally, for safety and to prevent unexpected system malfunctions, you should refrain from altering parameters that are included in the YAML file but not explicitly specified. If the network's self-monitoring mechanism detects a malfunction stemming from altered parameters, the offending relayer may be subject to slashing.\nUsing Systemd\nFor operators who prefer on using Systemd, you should make a configuration file for the Systemd execution environment. First, create a configuration file in the following directory.\nAn example of the configuration is provided below. The following parameters should be set regarding to your setup environment.\n<DIRECTORY_WHERE_BIFROST_RELAYER_LOCATES> : The absolute path to the directory where the installed bifrost-relayer binary file locates.\n<DIRECTORY_WHERE_BIFROST_RELAYER_LOCATES> : The absolute path to the directory where the installed bifrost-relayer binary file locates.\n<PATH_TO_BIFROST_RELAYER> : The absolute path to the installed bifrost-relayer binary file.\n<PATH_TO_BIFROST_RELAYER> : The absolute path to the installed bifrost-relayer binary file.\n<PATH_TO_CONFIG_FILE> : The absolute path to the installed config.testnet.yaml or config.mainnet.yaml. This parameter will be the the value for the CLI option, --chain.\n<PATH_TO_CONFIG_FILE> : The absolute path to the installed config.testnet.yaml or config.mainnet.yaml. This parameter will be the the value for the CLI option, --chain.\nRun the Relayer Service\nNow, the service can be started by executing the following commands. First, enable the service that will let it start automatically at every next system restart.\nThen, start the Systemd service, executing instructions in the service’s configuration file, use the start command as mentioned below.\nAnd lastly, verify the service has successfully executed.\nCheck Logs\nTo check your running bifrost-relayer service logs, execute the command below.\nOnce the service has successfully started, the initial logs will show up similar as below.\nIf the bootstrap configuration is enabled, it will then start to bootstrap historical events as below.\nAfter the initial launch and the bootstrap process ends, the system will wait until each chain has reached the block confirmations specified in your configuration YAML file. It will then import every new block on every interval as below.\nIf your relayer has met every system logs mentioned above, this means that it has successfully been launched and has started to operate in a healthy state.\nUpgrade Service\nAs the bifrost-relayer is under continuous development, there will be instances when it becomes necessary to upgrade your relayer service. When such upgrades become available, relayer operators will be notified either through our community channels or via direct communication. Please note that some upgrades may be optional rather than mandatory.\nFirst, remove or backup the previous bifrost-relayer binary file.\nThen, install the latest version of bifrost-relayer into the same directory and update permissions. (In case of directory changes, the Systemd configuration file should be modified as well)\nAt last, restart the Systemd service.\nUsing Docker\nFor operators who prefer on using Docker, it must be pre-installed in your operating system. Once installed, you can proceed to the following steps.\nTo run the relayer as a Docker container, use the command as mentioned below.\n<DIRECTORY_WHERE_CONFIG_FILE_LOCATES> : The absolute path of the directory where the installed config.testnet.yaml or config.mainnet.yaml locates.\n<DIRECTORY_WHERE_CONFIG_FILE_LOCATES> : The absolute path of the directory where the installed config.testnet.yaml or config.mainnet.yaml locates.\n<YOUR_CONFIG_FILE_NAME> : The file name of the installed configuration YAML file.\n<YOUR_CONFIG_FILE_NAME> : The file name of the installed configuration YAML file.\n<YOUR_CONTAINER_NAME> : Please set an explicit name for your relayer container.\n<YOUR_CONTAINER_NAME> : Please set an explicit name for your relayer container.\nCheck Logs\nTo check your running bifrost-relayer container logs, execute the command below.\nUpgrade Docker Image\nAs the bifrost-relayer is under continuous development, there will be instances when it becomes necessary to upgrade your relayer service. When such upgrades become available, relayer operators will be notified either through our community channels or via direct communication. Please note that some upgrades may be optional rather than mandatory.\nFirst stop and remove your running relayer container.\nThen, pull the latest bifrost-relayer Docker image.\nAt last execute the following command below to start a new container.\nParameter Descriptions\nsystem\nSystem related parameters of the relayer.\n-\n-\nsystem.private_key\nThe private key of the relayer.\n\"0x5fb92d6e98884f76de468fa3f6278f8807c48bebc13595d45af5bdc4da702133\"\n-\nsystem.debug_mode\nThe flag that represents if the debug mode is enabled. If enabled, debug-level logs and sentry alerts will be enabled.\ntrue / false\nfalse\nbtc_provider\nThe parameters related to the Bitcoin chain provider.\n-\n-\nbtc_provider.id\nThe unique ID of the Bitcoin chain.\n10000 (For Mainnet)\n10000 (For Mainnet)\n10001 (For Testnet)\n10001 (For Testnet)\n-\nbtc_provider.chain\nThe name of the Bitcoin chain.\n\"main\" (For Mainnet)\n\"main\" (For Mainnet)\n\"test\" (For Testnet)\n\"test\" (For Testnet)\n-\nbtc_provider.provider\nThe RPC endpoint of the Bitcoin chain.\n-\n-\nbtc_provider.call_interval\nThe block synchronization interval in milliseconds. At every new interval, the system will synchronize every new block mined on the target chain.\n10000\n-\nbtc_provider.block_confirmations\nThe number of block confirmations required to synchronize a new block.\n3\n3\nevm_providers\nThe parameters related to EVM chain providers.\n-\n-\nevm_providers.id\nThe unique ID of the chain.\n3068\n-\nevm_providers.name\nThe name of the chain.\n\"bifrost\"\n-\nevm_providers.provider\nThe RPC endpoint of the node. If the node is running, or is expected to be operated on the same server with the relayer, then set this value to the provided example.\n\"http://127.0.0.1:9933\"\n-\nevm_providers.call_interval\nThe block synchronization interval in milliseconds. At every new interval, the system will synchronize every new block mined on the target chain.\n1500\n-\nevm_providers.block_confirmations\nThe number of block confirmations required to synchronize a new block.\n5\n-\nevm_providers.is_relay_target\nThe flag which represents whether the system will participate in external-chain CCCP actions. If this value is set to true, the system will try to execute transactions on the target chain, so sufficient balances are required. This value must be set to true if it is the Bifrost Network.\ntrue / false\n-\nevm_providers.eip1559\nThe flag which represents whether the system will execute EIP-1559 transactions. If set to false, transactions will be executed by legacy types.\ntrue / false\nfalse\nevm_providers.min_gas_price\nThe minimum gas price (in WEI) that the system will setup when executing legacy transactions. If the value is null, it will be dynamically set. This field only has effect when the eip1559 parameter is disabled.\n30000000000\n0\nevm_providers.min_priority_fee\nThe minimum priority fee (in WEI) that the system will setup when executing EIP-1559 transactions. If the value is null, it will be dynamically set. This field only has effect when the eip1559 parameter is enabled.\n30000000000\n0\nevm_providers.escalate_percentage\nThe percentage that will be used on gas price escalation to replace a transaction that is stuck in the mempool. This option will only have effect for legacy transactions.\n15.0\n15.0\nevm_providers.is_initially_escalated\nThe flag whether if the gas price will be initially escalated. The escalate_percentage will be used on escalation. This option will only have effect for legacy transactions.\ntrue / false\nfalse\nevm_providers.get_logs_batch_size\nThe batch size (=block range) used when requesting eth_getLogs(). If increased the RPC request ration will be reduced, however event processing will be delayed regarded to the configured value. Default size is set  to 1, which means it will be requested on every new block.\n5\n1\nsentry_config\nSentry related parameters. If this section does not exist in your configuration file, Sentry will be disabled.\n-\nNone\nsentry_config.is_enabled\nThe flag which represents whether Sentry is enabled.\n-\n-\nsentry_config.environment\nThe identifier for the Sentry client. This value will be used to distinguish triggered alarms.\n\"mainnet\"\n\"\"\nsentry_config.dsn\nThe Sentry DSN. If the value has been set, error and warning alerts will be notified. If the value is empty, Sentry will be disabled.\n-\n-\nprometheus_config\nPrometheus related parameters. It this section does not exist in your configuration file, Prometheus will be disabled.\n-\nNone\nprometheus_config.is_enabled\nThe flag which represents whether Prometheus metric collection is enabled.\ntrue / false\n-\nprometheus_config.is_external\nThe flag which represents whether the Prometheus server is exposed on all interfaces.\ntrue / false\nfalse\nprometheus_config.port\nThe Prometheus exporter TCP port.\n8000\n8000\nbootstrap_config\nBootstrap related parameters. Bootstrap is a process that will be executed whenever the relayer (re-)starts. It will collect historical CCCP events and let the relayer re-handle the event to prevent missed actions.\n-\nNone\nbootstrap_config.is_enabled\nThe flag which represents whether bootstrap is enabled\ntrue / false\n-\nbootstrap_config.round_offset\nThe amount of rounds to search for missed events.\n3\n3\nLast updated 2 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-relayer/bifrost-relayer.rs"
  },
  {
    "title": "bifrost-relayer.py (Legacy)",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nSETTING UP A RELAYER\nbifrost-relayer.py (Legacy)\nWhat is bifrost-relayer.py?\nbifrost-relayer.py is the Python implementation of the Bifrost network's relayer and represents the initial implementation of the CCCP-Relayer. Recently, we have introduced a Rust implementation of the CCCP-Relayer. However, this doesn't imply the end of the legacy relayer, which will continue to be maintained and supported.\nInstall Requirements\nFirst, you need to get the code to prepare for the relayer execution.\nThe common configurations for the bifrost-relayer is provided through the configs/entity.relayer.json file, but the individual settings for each relayer must be set through the configs/entity.relayer.private.json file. (For testnet relayers, use the configs-testnet directory)\nUsing Systemd\nPython version 3.10 is required to run the relayer as a system daemon.\nThe required Python packages must be priorly installed. It is recommended to use a virtual environment, and this manual assumes the use of a virtual environment.\nNext, you need to create a Systemd configuration file. Create the file in the following directory.\n<DIRECTORY_WHERE_BIFROST_RELAYER_LOCATES> : The absolute path to the directory where the installed bifrost-relayer locates.\n<DIRECTORY_WHERE_BIFROST_RELAYER_LOCATES> : The absolute path to the directory where the installed bifrost-relayer locates.\n<PATH_TO_BIFROST_RELAYER> : The absolute path to the installed bifrost-relayer.\n<PATH_TO_BIFROST_RELAYER> : The absolute path to the installed bifrost-relayer.\nNow, with the two lines of the command below, the relayer will be executed in the background.\nTo check your running bifrost-relayer service logs, execute the command below.\nUsing Docker\nMove to the project root path and build the Docker image.\nRun the built image.\nTo check your running bifrost-relayer container logs, execute the command below.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/setting-up-a-relayer/bifrost-relayer.py-legacy"
  },
  {
    "title": "Chain Data Snapshots",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nChain Data Snapshots\nChain Data Synchronization Using Snapshots\nBifrost Network provides snapshots of the chain data. Snapshots are updated at regular intervals.\nThis allows node operators to spend less time on data synchronization and reduce the load on the network.\nFollow the link, and complete the snapshot download&export process.\nFollow the link, and complete the snapshot download&export process.\nReturn to the process in the operation manual once complete.\nReturn to the process in the operation manual once complete.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/chain-data-snapshots"
  },
  {
    "title": "Trouble Shooting",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nTrouble Shooting\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/trouble-shooting"
  },
  {
    "title": "Testnet \bChain Sync Issue",
    "content": "RUNNING A NODE\nGUIDE FOR OPERATORS\nTROUBLE SHOOTING\nTestnet \bChain Sync Issue\nThis guide will walk you through how to resolve the issue when your Testnet node has stopped to sync chain data at block #336,000.\n1. Synchronization Using Snapshot (Recommended)\nCurrently if your node is running in full-mode (non-archive mode), instead of this step you should follow to section 2. Synchronization from the Genesis Block\nThe Bifrost Network provides snapshots of the chain data. Snapshots are updated at regular intervals. This allows node operators to spend less time on data synchronization and reduce the load on the network.\nFollow the link, and complete the snapshot download & export process.\nFollow the link, and complete the snapshot download & export process.\nReturn to the process in the operation manual once complete.\nReturn to the process in the operation manual once complete.\n2. Synchronization from the Genesis Block\nThis method does not require downloading snapshots. This section works for both archive and full modes.\n1. Block 0 to 336115\nFor initial synchronization, utilize bifrost-node 1.0.2 up to at least block 336115.\nAfter start running your node, it will start to synchronize chain data from the genesis block as below. (In some cases, error logs might be displayed, but for now, those are fine to ignore)\n2. Block 336115 onwards\nOnce synchronization reaches block 336115, utilize the latest version of bifrost-node.\nAfter restarting your node, in some cases, error logs might be displayed as before, however it is fine to ignore.\n3. Complete synchronization\nSynchronization is complete once “Syncing” does not appear in the log. Return to the process on the operation manual.\nLast updated 3 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/guide-for-operators/trouble-shooting/testnet-chain-sync-issue"
  },
  {
    "title": "System Monitoring",
    "content": "RUNNING A NODE\nSystem Monitoring\nThis section outlines how to monitor the status of the Bifrost Node and Relayer. It will be useful for debugging, adjusting, and understanding what actually happens in the Bifrost Node and Relayer.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/system-monitoring"
  },
  {
    "title": "Prometheus and Grafana",
    "content": "RUNNING A NODE\nSYSTEM MONITORING\nPrometheus and Grafana\nThe Bifrost node and relayer also supports system metric monitoring. This guide will walk you through how to setup Prometheus and Grafana to monitor your node and relayer.\nEnable Prometheus\nIn order to let your Bifrost node and relayer to collect Prometheus metrics, it must be manually enabled. To enable the Prometheus server of your node, the following CLI flags has to be provided and then restarted.\n--prometheus-external : This exposes the Prometheus exporter on all interfaces.\n--prometheus-external : This exposes the Prometheus exporter on all interfaces.\n--prometheus-port <PORT> : The default port will be set to 9615. However, if port changes are required, then this flag must be provided.\n--prometheus-port <PORT> : The default port will be set to 9615. However, if port changes are required, then this flag must be provided.\nIn case that you're operating a full-node, to enable the Prometheus server of your relayer, the following parameters of your configuration YAML file has to be updated as below and restarted.\nIf it has been successfully restarted, in both of your services the following log will be printed at the initial launch.\nUsing Systemd\nThis section contains how to install and setup Prometheus and Grafana by using Systemd.\nInstalling Prometheus\nFirst, create the directories required to store the configuration and executable files.\nThen, update your OS and install the latest Prometheus. You can check the latest releases by going to their GitHub repository under the releases page.\nCopy the executable files to the /usr/local/bin/ directory.\nCopy the console files to the /etc/prometheus directory.\nOnce everything is done, remove the prometheus directory.\nInstalling NodeExporter\nNow, install the NodeExporter. You can check the latest releases by going to their Github repository under the releases page.\nInstalling AlertManager\nFirst, create the directories required to store the configuration and executable files.\nNext, install the AlertManager. You can check the latest releases by going to their Github repository under the releases page.\nInstall the AlertManager plugins required for Grafana.\nConfigure Alert Rules\nCreate the rules.yml file that will give the rules for the AlertManager.\nWe are going to create 2 basic rules that will trigger an alert in case the instance is down or the CPU usage crosses 80%. Add the following lines and save the file.\nThe alertmanager.yml file is used to set the external service that will be called when an alert is triggered. Here, we are going to use the Gmail notification.\nFor Gmail notification, you will need to generate an app password. We recommend you to use a dedicated email address for your alerts. In order to set-up follow this link.\nCreate the file in the following path.\nAnd add the Gmail configuration to it and save the file as below.\nConfigure Prometheus\nIn order to start Prometheus, it needs some configuration. Create a configuration yaml file in the following directory.\nThe configuration file should look as below.\nStarting Prometheus\nNext, the Systemd configuration should be set for Prometheus. Create a configuration file in the following directory.\nThe configuration file should look as below.\nNow, enable and start the service.\nTo test out if it all successfully worked, access YOUR_SERVER_IP_ADDRESS:9090. If the Prometheus dashboard appears, it is good to go.\nStarting NodeExporter\nThe Systemd configuration should be set for the NodeExporter. Crate a configuration file in the following directory.\nThe configuration file should look as below.\nNow, enable and start the service.\nStarting AlertManager\nThe Systemd configuration should be set for the AlertManager. Crate a configuration file in the following directory.\nThe configuration file should look as below.\nNow, enable and start the service.\nInstalling Grafana\nTo visualize your Prometheus metrics, you should install Grafana, which queries the Prometheus server. The latest releases can be checked on their download page. Execute the following commands to install the necessary dependencies.\nStarting Grafana\nThen enable and start the service with default configurations.\nYou can now access it by going to YOUR_SERVER_IP_ADDRESS:3000/login. The default user and password is admin/admin.\nUsing Docker\nThis section contains how to install and setup Prometheus and Grafana by using Docker.\nRequirements\nFirst, Docker and Docker Compose should be installed in your server. Then you can download the docker-compose.yml file that is provided in Bifrost node's Github repository. Download the file by using the command below. The file will be located in the maintenance directory.\nConfigure AlertManager\nThe alert rules are pre-defined in the maintenance/prometheus/rules.yml file. It contains 2 basic rules that will trigger an alert in case the instance is down or the CPU usage crosses 80%. The file will be provided as below.\nThe alertmanager.yml file is used to set the external service that will be called when an alert is triggered. Here, we are going to use the Gmail notification.\nFor Gmail notification, you will need to generate an app password. We recommend you to use a dedicated email address for your alerts. In order to set-up follow this link.\nThe file locates in the maintenance/alertmanager/alertmanager.yml directory. Then, add the Gmail configuration to it and save the file as below.\nConfigure Prometheus\nIn order to start Prometheus, it needs some configuration. The configuration file locates at maintenance/prometheus/prometheus.yml. For Full-Node operators who runs the node and relayer both, should manually uncomment the below \"relayer\" job.\nRun Docker Containers\nIf you have followed every processes above, return to the maintenance directory and execute the following command.\nYou can now access it by going to YOUR_SERVER_IP_ADDRESS:3000/login. The default user and password is admin/admin.\nDatasource Configuration\nIf it is all set, create a new Prometheus datasource and input the URL as http://localhost:9090 and then click “Save & Test” as below.\nFor Docker users, the URL should be set to http://prometheus:9090.\nThen, create a new Prometheus AlertManager datasource and input the URL as http://localhost:9093 and then click \"Save & Test\" as below.\nFor Docker users, the URL should be set to http://alertmanager:9093.\nNext, the dashboard has to be imported. Access the \"Dashboards\" tab and click on \"New\" to import the dashboard as below.\nNow, in the \"Import via grafana.com\" section, input the dashboard ID as 19207 and then click \"Load\" to continue.\nIf it has been successfully loaded, set the correct datasources that you have just created before. The Prometheus and the AlertManager has to be set correctly. Then click \"Import\" to continue.\nIn the meantime, if your node and relayer is running in the background, the collected metrics will be visualized as below.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/system-monitoring/prometheus-and-grafana"
  },
  {
    "title": "Sentry",
    "content": "RUNNING A NODE\nSYSTEM MONITORING\nSentry\nThis guide will walk you through how to setup Sentry to track errors and issues of your Bifrost relayer.\nSentry Setup\nTo setup Sentry, you should first create an account and login to https://sentry.io. Then, you will be redirected to your Sentry dashboard. You will now have to create a new project for your Bifrost relayer. Access the “Projects” tab and then create a new project as below. You should set the platform to \"RUST\". However the alert frequency and project name is freely available to be customized.\nYou will now see your created project in the “Projects” tab. Access to your new project and go to the settings tab. Then on the left-hand side, you will see “Client Keys (DSN)” tab. On the page, you will see your project’s DSN key. Copy and paste your DSN key to sentry_config.dsn in your relayer’s configuration YAML file, and then restart the service.\nSentry is now ready to go. Whenever any new issue occurs, the error information will be displayed in your project’s dashboard and alerts will be notified to your target destination (Slack, Email, etc).\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/running-a-node/system-monitoring/sentry"
  },
  {
    "title": "Nominators",
    "content": "Nominators\nNominators are one type of participant in the staking subsystem of Polkadot. They are responsible for appointing their stake to the validators who are the second type of participant. By appointing their stake, they are able to elect the active set of validators and share in the rewards that are paid out.\nWhile the validators are active participants in the network that engage in the block production and finality mechanisms, nominators take a slightly more passive role. Being a nominator does not require running a node of your own or worrying about online uptime. However, a good nominator performs due diligence on the validators that they elect. When looking for validators to nominate, a nominator should pay attention to their own reward percentage for nominating a specific validator.\nNominators are recommended to set up separate stash and controller accounts.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/nominators"
  },
  {
    "title": "Developer Documentations",
    "content": "Developer Documentations\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations"
  },
  {
    "title": "Ethereum API",
    "content": "DEVELOPER DOCUMENTATIONS\nEthereum API\nThe Bifrost Network has an Ethereum-like API that is fully compatible with Ethereum-style JSON RPC invocations. Therefore, developers constructing DApps on the Bifrost Network can utilize any development tool compatible with Ethereum.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/ethereum-api"
  },
  {
    "title": "Ethereum Precompiled Contracts",
    "content": "DEVELOPER DOCUMENTATIONS\nETHEREUM API\nEthereum Precompiled Contracts\nThe Bifrost Network supports the standard precompiled contract installed on the Ethereum mainnet. The following is the table of addresses of the implemented precompiled contracts.\nECRECOVER\nIt returns the signer address of the ecdsa signature (v, r, s) if the signature is valid. It can be called directly in Solidity code.\nSHA256\nIt returns the keccak-hash value of the data. It can be called directly in Solidity code.\nRIPEMD160\nIt returns the ripemd160-hash value of the data. It can be called directly in Solidity code.\nIdentity\nAlso known as datacopy, this function serves as a cost-efficient way to copy data in memory. Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nModular Exponentiation\nThis function calculates the remainder when an integer b(base) is raised to the e-th power(the exponent) and is divided by a positive integer m(the modulus). Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nBN128Add\nThe BN128Add precompiled contract implements a native elliptic curve point addition. It returns an elliptic curve point representing (ax, ay) + (bx, by) such that (ax, ay) and (bx, by) are valid points on the curve BN256. Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nBN128Mul\nThe BN128Mul precompiled contract implements a native elliptic curve multiplication with a scalar value. It returns an elliptic curve point representing scalar * (x, y) such that (x, y) is a valid curve point on the curve BN256. Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nBN128Pairing\nThe BN128Pairing precompile implements elliptic curve paring operation to perform zkSNARK verification. For more information, check out the EIP-197 standard. Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nBlake2F\nThis EIP will enable the BLAKE2b hash function and other higher-round 64-bit BLAKE2 variants to run cost-effectively on the EVM, allowing easier interoperability between Ethereum and Zcash or any other Equihash-based PoW coin. For more information, check out the EIP-152 standard. Since the Solidity compiler does not support this function, this function must be called by assembly as follows.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/ethereum-api/ethereum-precompiled-contracts"
  },
  {
    "title": "Libraries",
    "content": "DEVELOPER DOCUMENTATIONS\nETHEREUM API\nLibraries\nDevelopers who want to construct DApps on the Bifrost Network can utilize any library that supports Ethereum. The following is a list of some of the supported libraries.\nEther.js\nThe ethers.js library aims to be a complete and compact library for interacting with the Ethereum blockchain and its ecosystem. You can find more information in their documentation.\nWeb3.js/Web3.py\nWeb3.js has a longer history and more maintainers than Ether.js and it provides a single instantiated web3 object with methods for interacting with the blockchain.\nYou can find more information in their documentation.\nOpenZeppelin\nOpenZeppelin is well known in the Ethereum developer community as their set of audited smart contracts and libraries has become a standard in the industry. For example, most of the tutorials that show developers how to deploy an ERC-20 token use OpenZeppelin contracts.\nYou can find more information in their documentation.\nPolkadot.js\nFor exceptional developers who require Substrate runtime, pallets, or client interactions for their DApp development, polkadot.js will be an optimal choice. You can find more information in their documentation.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/ethereum-api/libraries"
  },
  {
    "title": "Developer Environments",
    "content": "DEVELOPER DOCUMENTATIONS\nETHEREUM API\nDeveloper Environments\nDevelopers who want to construct DApps on the Bifrost Network can select any development tool that supports Ethereum. The following is a list of some of the supported development environments.\nRemix\nRemix is a rich toolset that can be used throughout the entire development process by users at any knowledge level, and is a great learning lab for teaching and experimenting with Ethereum.\nYou can find more information in their documentation.\nTruffle\nTruffle supports developers throughout the full lifecycle of their projects, whether they are looking to build on Ethereum, Hyperledger, Quorum, or any other supported platform from an ever-growing list. Paired with Ganache, a personal blockchain, and Drizzle, a front-end DApp development kit, the full Truffle suite of tools promises to be an end-to-end DApp development platform.\nYou can find more information in their documentation.\nBrownie\nBrownie is a Python-based development and testing framework for smart contracts targeting the Ethereum Virtual Machine. It has powerful debugging tools and a built-in console.\nYou can find more information in their documentation.\nHardhat\nHardhat is a development environment for Ethereum software. It consists of different components for editing, compiling, debugging, and deploying smart contracts and DApps, all of which work together to create a complete development environment.\nYou can find more information in their documentation.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/ethereum-api/developer-environments"
  },
  {
    "title": "Bifrost Precompiled Contracts",
    "content": "DEVELOPER DOCUMENTATIONS\nBifrost Precompiled Contracts\nThe Bifrost Network provides several useful sets of precompiled contracts. These contracts are implemented in the network itself as a native implementation. The addresses from 0x01 through 0x09 are identical to the standard Ethereum precompiled contracts. The Bifrost Network additionally supports several custom precompiled contracts for technical features.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/bifrost-precompiled-contracts"
  },
  {
    "title": "Staking",
    "content": "DEVELOPER DOCUMENTATIONS\nBIFROST PRECOMPILED CONTRACTS\nStaking\nAny network participant who desires to become a validator, should first join the candidate pool by bonding the required amount of BFC to the network. Users can also delegate their power (BFC) to nominate their desired candidate. Finally, at each new round, only the top n candidates will be selected as validators to produce blocks.\nCandidates and nominators can perform all actions related to validator elections through the following BfcStaking contract.\nBfcStaking contract\naddress: 0x0000000000000000000000000000000000000400\naddress: 0x0000000000000000000000000000000000000400\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/bifrost-precompiled-contracts/staking"
  },
  {
    "title": "Governance",
    "content": "DEVELOPER DOCUMENTATIONS\nBIFROST PRECOMPILED CONTRACTS\nGovernance\nThe Bifrost Network is a decentralized network managed by BFC holders. At the heart of the Bifrost Network's governance protocol, BFC holders reflect changes to the network by voting on the community's proposed referenda through a stake-weighted voting system based on their stakes.\nAll actions related to governance can be performed through the following Governance contract.\nGovernance contract\naddress: 0x0000000000000000000000000000000000000800\naddress: 0x0000000000000000000000000000000000000800\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/bifrost-precompiled-contracts/governance"
  },
  {
    "title": "RelayManager",
    "content": "DEVELOPER DOCUMENTATIONS\nBIFROST PRECOMPILED CONTRACTS\nRelayManager\nA relayer that is part of a full validator has its own account that is different from the controller address of the validator. Therefore, a function to check the selected relayers in a specific round is separately required.\nAll actions related to verifying the authority of the relayer are performed through the following RelayerManager contract.\nRelayManager contract\naddress: 0x0000000000000000000000000000000000002000\naddress: 0x0000000000000000000000000000000000002000\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nSince the Solidity compiler does not support this function, it is recommended to call a method through the interface below.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/bifrost-precompiled-contracts/relaymanager"
  },
  {
    "title": "Pallet Interfaces",
    "content": "DEVELOPER DOCUMENTATIONS\nPallet Interfaces\nThe Bifrost Network is built by the Substrate framework and has multiple implemented FRAME pallets. The Bifrost Network also has multiple custom pallets for its core functionality. This section outlines the definitions of the implemented custom pallets.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/pallet-interfaces"
  },
  {
    "title": "BfcStaking",
    "content": "DEVELOPER DOCUMENTATIONS\nPALLET INTERFACES\nBfcStaking\nDescription\nThe core DPoS consensus mechanism of the Bifrost Node is defined in pallet_bfc_staking. The pallet_bfc_staking is a custom pallet that defines the concepts of validators and nominators and also manages their self-bonds and nominations. In addition, it defines the concept of rounds as well as the logic within the rounds.\nExtrinsics\nset_staking_expectations(expectations: Range<BalanceOf>)\ninterface: api.tx.bfcStaking.setStakingExpectations\ninterface: api.tx.bfcStaking.setStakingExpectations\nsummary: Sets the expectations for total staked. These expectations determine the issuance of the round. The origin should be the root.\nsummary: Sets the expectations for total staked. These expectations determine the issuance of the round. The origin should be the root.\nset_inflation(schedule: Range<Perbill>)\ninterface: api.tx.bfcStaking.setInflation\ninterface: api.tx.bfcStaking.setInflation\nsummary: Sets the annual inflation rate to derive per-round inflation. The origin should be the root.\nsummary: Sets the annual inflation rate to derive per-round inflation. The origin should be the root.\nset_max_full_selected(new: u32)\ninterface: api.tx.bfcStaking.setMaxFullSelected\ninterface: api.tx.bfcStaking.setMaxFullSelected\nsummary: Sets the maximum number of full validator candidates selected per round. The origin should be the root.\nsummary: Sets the maximum number of full validator candidates selected per round. The origin should be the root.\nset_basic_full_selected(new: u32)\ninterface: api.tx.bfcStaking.setMaxBasicSelected\ninterface: api.tx.bfcStaking.setMaxBasicSelected\nsummary: Sets the maximum number of basic validator candidates selected per round. The origin should be the root.\nsummary: Sets the maximum number of basic validator candidates selected per round. The origin should be the root.\nset_min_total_selected(new: u32)\ninterface: api.tx.bfcStaking.setMinTotalSelected\ninterface: api.tx.bfcStaking.setMinTotalSelected\nsummary: Sets the minimum number of validator candidates selected per round. The origin should be the root.\nsummary: Sets the minimum number of validator candidates selected per round. The origin should be the root.\nset_default_validator_commission(new: Perbill, tier: TierType)\ninterface: api.tx.bfcStaking.setDefaultValidatorCommission\ninterface: api.tx.bfcStaking.setDefaultValidatorCommission\nsummary: Sets the default commission rate for all validators of the given tier. The origin should be the root.\nsummary: Sets the default commission rate for all validators of the given tier. The origin should be the root.\nset_max_validator_commission(new: Perbill, tier: TierType)\ninterface: api.tx.bfcStaking.setMaxValidatorCommission\ninterface: api.tx.bfcStaking.setMaxValidatorCommission\nsummary: Sets the maximum commission rate for all validators of the given tier. The origin should be the root.\nsummary: Sets the maximum commission rate for all validators of the given tier. The origin should be the root.\nset_validator_commission(new: Perbill)\ninterface: api.tx.bfcStaking.setValidatorCommission\ninterface: api.tx.bfcStaking.setValidatorCommission\nsummary: Sets the commission rate of the given validator. The origin should be the controller account.\nsummary: Sets the commission rate of the given validator. The origin should be the controller account.\nset_validator_tier(more: BalanceOf, new: TierType, relayer?: AccountId)\ninterface: api.tx.bfcStaking.setValidatorTier\ninterface: api.tx.bfcStaking.setValidatorTier\nsummary: Modifies validator candidate tier. The actual state reflection will apply at the next round. The origin should be the stash account.\nsummary: Modifies validator candidate tier. The actual state reflection will apply at the next round. The origin should be the stash account.\nset_blocks_per_round(new: u32)\ninterface: api.tx.bfcStaking.setBlocksPerRound\ninterface: api.tx.bfcStaking.setBlocksPerRound\nsummary: Sets blocks per round. The new round length will be updated immediately in the next block. This also updates the per-round inflation config. The origin should be the root.\nsummary: Sets blocks per round. The new round length will be updated immediately in the next block. This also updates the per-round inflation config. The origin should be the root.\nset_storage_cache_lifetime(new: u32)\ninterface: api.tx.bfcStaking.setStorageCacheLifetime\ninterface: api.tx.bfcStaking.setStorageCacheLifetime\nsummary: Sets the StorageCacheLifetime round length. The origin should be the root.\nsummary: Sets the StorageCacheLifetime round length. The origin should be the root.\njoin_candidates(controller: AccountId, relayer?: AccountId, bond: BalanceOf, candidate_count: u32)\ninterface: api.tx.bfcStaking.joinCandidates\ninterface: api.tx.bfcStaking.joinCandidates\nsummary: Join the set of validator candidates. The origin should be the stash account.\nsummary: Join the set of validator candidates. The origin should be the stash account.\nschedule_leave_candidates(candidate_count: u32)\ninterface: api.tx.bfcStaking.scheduleLeaveCandidates\ninterface: api.tx.bfcStaking.scheduleLeaveCandidates\nsummary: Requests to leave the set of candidates. If successful, the account is immediately removed from the candidate pool to prevent selection as a validator. The origin should be the controller account.\nsummary: Requests to leave the set of candidates. If successful, the account is immediately removed from the candidate pool to prevent selection as a validator. The origin should be the controller account.\nexecute_leave_candidates(candidate_nomination_count: u32)\ninterface: api.tx.bfcStaking.executeLeaveCandidates\ninterface: api.tx.bfcStaking.executeLeaveCandidates\nsummary: Executes leave candidates request. The origin should be the stash account.\nsummary: Executes leave candidates request. The origin should be the stash account.\ncancel_leave_candidates(candidate_count: u32)\ninterface: api.tx.bfcStaking.cancelLeaveCandidates\ninterface: api.tx.bfcStaking.cancelLeaveCandidates\nsummary: Cancels open request to leave candidates. The origin should be the controller account.\nsummary: Cancels open request to leave candidates. The origin should be the controller account.\nset_controller(new: AccountId)\ninterface: api.tx.bfcStaking.setController\ninterface: api.tx.bfcStaking.setController\nsummary: (Re-)sets the bonded controller account. The origin must be the bonded stash account. The actual change will apply on the next round update. The origin should be the stash account.\nsummary: (Re-)sets the bonded controller account. The origin must be the bonded stash account. The actual change will apply on the next round update. The origin should be the stash account.\nset_candidate_reward_dst(new_reward_dst: RewardDestination)\ninterface: api.tx.bfcStaking.setCandidateRewardDst\ninterface: api.tx.bfcStaking.setCandidateRewardDst\nsummary: Sets the validator candidate reward destination. The origin should be the controller account.\nsummary: Sets the validator candidate reward destination. The origin should be the controller account.\nset_nominator_reward_dst(new_reward_dst: RewardDestination)\ninterface: api.tx.bfcStaking.setNominatorRewardDst\ninterface: api.tx.bfcStaking.setNominatorRewardDst\nsummary: Sets the nominator reward destination.\nsummary: Sets the nominator reward destination.\ngo_offline()\ninterface: api.tx.bfcStaking.goOffline\ninterface: api.tx.bfcStaking.goOffline\nsummary: Temporarily leaves the set of validator candidates without unbonding. The origin should be the controller account.\nsummary: Temporarily leaves the set of validator candidates without unbonding. The origin should be the controller account.\ngo_online()\ninterface: api.tx.bfcStaking.goOnline\ninterface: api.tx.bfcStaking.goOnline\nsummary: Rejoins the set of validator candidates if previously been kicked out or went offline. The origin should be the controller account.\nsummary: Rejoins the set of validator candidates if previously been kicked out or went offline. The origin should be the controller account.\ncandidate_bond_more(more: BalanceOf)\ninterface: api.tx.bfcStaking.candidateBondMore\ninterface: api.tx.bfcStaking.candidateBondMore\nsummary: Increases validator candidate self-bond by more. The origin should be the stash account.\nsummary: Increases validator candidate self-bond by more. The origin should be the stash account.\nschedule_candidate_bond_less(less: BalanceOf)\ninterface: api.tx.bfcStaking.scheduleCandidateBondLess\ninterface: api.tx.bfcStaking.scheduleCandidateBondLess\nsummary: Requests by validator candidate to decrease self-bond by less. The origin should be the controller account.\nsummary: Requests by validator candidate to decrease self-bond by less. The origin should be the controller account.\nexecute_candidate_bond_less()\ninterface: api.tx.bfcStaking.executeCandidateBondLess\ninterface: api.tx.bfcStaking.executeCandidateBondLess\nsummary: Executes pending request to adjust the validator candidate self-bond. The origin should be the stash account.\nsummary: Executes pending request to adjust the validator candidate self-bond. The origin should be the stash account.\ncancel_candidate_bond_less()\ninterface: api.tx.bfcStaking.cancelCandidateBondLess\ninterface: api.tx.bfcStaking.cancelCandidateBondLess\nsummary: Cancels pending request to adjust the validator candidate self bond. The origin should be the controller account.\nsummary: Cancels pending request to adjust the validator candidate self bond. The origin should be the controller account.\nnominate(candidate: AccountId, amount: BalanceOf, candidate_nomination_count: u32, nomination_count: u32)\ninterface: api.tx.bfcStaking.nominate\ninterface: api.tx.bfcStaking.nominate\nsummary: Nominates the given candidate.\nsummary: Nominates the given candidate.\nschedule_leave_nominators()\ninterface: api.tx.bfcStaking.scheduleLeaveNominators\ninterface: api.tx.bfcStaking.scheduleLeaveNominators\nsummary: Requests to leave the set of nominators.\nsummary: Requests to leave the set of nominators.\nexecute_leave_nominators(nomination_count: u32)\ninterface: api.tx.bfcStaking.executeLeaveNominators\ninterface: api.tx.bfcStaking.executeLeaveNominators\nsummary: Executes the right to exit the set of nominators and revoke all ongoing nominations.\nsummary: Executes the right to exit the set of nominators and revoke all ongoing nominations.\ncancel_leave_nominators()\ninterface: api.tx.bfcStaking.cancelLeaveNominators\ninterface: api.tx.bfcStaking.cancelLeaveNominators\nsummary: Cancels a pending request to exit the set of nominators.\nsummary: Cancels a pending request to exit the set of nominators.\nschedule_revoke_nomination(validator: AccountId)\ninterface: api.tx.bfcStaking.scheduleRevokeNomination\ninterface: api.tx.bfcStaking.scheduleRevokeNomination\nsummary: Requests to revoke an existing nomination.\nsummary: Requests to revoke an existing nomination.\nnominator_bond_more(candidate: AccountId, more: BalanceOf)\ninterface: api.tx.bfcStaking.nominatorBondMore\ninterface: api.tx.bfcStaking.nominatorBondMore\nsummary: Bonds more for a specific validator candidate.\nsummary: Bonds more for a specific validator candidate.\nschedule_nominator_bond_less(candidate: AccountId, less: BalanceOf)\ninterface: api.tx.bfcStaking.scheduleNominatorBondLess\ninterface: api.tx.bfcStaking.scheduleNominatorBondLess\nsummary: Requests bond less for a specific validator candidate.\nsummary: Requests bond less for a specific validator candidate.\nexecute_nomination_request(candidate: AccountId)\ninterface: api.tx.bfcStaking.executeNominationRequest\ninterface: api.tx.bfcStaking.executeNominationRequest\nsummary: Executes pending request to change an existing nomination.\nsummary: Executes pending request to change an existing nomination.\ncancel_nomination_request(candidate: AccountId)\ninterface: api.tx.bfcStaking.cancelNominationRequest\ninterface: api.tx.bfcStaking.cancelNominationRequest\nsummary: Cancels request to change an existing nomination.\nsummary: Cancels request to change an existing nomination.\nStorage Values\nSession(): SessionIndex\ninterface: api.query.bfcStaking.session\ninterface: api.query.bfcStaking.session\nsummary: Current session index of current round.\nsummary: Current session index of current round.\nRound(): RoundInfo<T::BlockNumber>\ninterface: api.query.bfcStaking.round\ninterface: api.query.bfcStaking.round\nsummary: Current round index and specific information.\nsummary: Current round index and specific information.\nStorageCacheLifetime(): u32\ninterface: api.query.bfcStaking.storageCacheLifetime\ninterface: api.query.bfcStaking.storageCacheLifetime\nsummary: The maximum storage lifetime for storage data to be cached.\nsummary: The maximum storage lifetime for storage data to be cached.\nDefaultFullValidatorCommission(): Perbill\ninterface: api.query.bfcStaking.defaultFullValidatorCommission\ninterface: api.query.bfcStaking.defaultFullValidatorCommission\nsummary: Default commission rate for full validators.\nsummary: Default commission rate for full validators.\nDefaultBasicValidatorCommission(): Perbill\ninterface: api.query.bfcStaking.defaultBasicValidatorCommission\ninterface: api.query.bfcStaking.defaultBasicValidatorCommission\nsummary: Default commission rate for basic validators.\nsummary: Default commission rate for basic validators.\nMaxFullValidatorCommission(): Perbill\ninterface: api.query.bfcStaking.maxFullValidatorCommission\ninterface: api.query.bfcStaking.maxFullValidatorCommission\nsummary: Maximum commission rate for full validators.\nsummary: Maximum commission rate for full validators.\nMaxBasicValidatorCommission(): Perbill\ninterface: api.query.bfcStaking.maxBasicValidatorCommission\ninterface: api.query.bfcStaking.maxBasicValidatorCommission\nsummary: Maximum commission rate for basic validators.\nsummary: Maximum commission rate for basic validators.\nMaxTotalSelected(): u32\ninterface: api.query.bfcStaking.maxTotalSelected\ninterface: api.query.bfcStaking.maxTotalSelected\nsummary: Maximum node candidates selected every round.\nsummary: Maximum node candidates selected every round.\nMaxFullSelected(): u32\ninterface: api.query.bfcStaking.maxFullSelected\ninterface: api.query.bfcStaking.maxFullSelected\nsummary: Maximum full node candidates selected every round.\nsummary: Maximum full node candidates selected every round.\nMaxBasicSelected(): u32\ninterface: api.query.bfcStaking.maxBasicSelected\ninterface: api.query.bfcStaking.maxBasicSelected\nsummary: Maximum basic node candidates selected every round.\nsummary: Maximum basic node candidates selected every round.\nMinTotalSelected(): u32\ninterface: api.query.bfcStaking.minTotalSelected\ninterface: api.query.bfcStaking.minTotalSelected\nsummary: Minimum candidates selected every round.\nsummary: Minimum candidates selected every round.\nProductivityPerBlock(): Perbill\ninterface: api.query.bfcStaking.productivityPerBlock\ninterface: api.query.bfcStaking.productivityPerBlock\nsummary: Productivity rate per block in the current round.\nsummary: Productivity rate per block in the current round.\nNominatorState(AccountId): Option<Nominator<AccountId, BalanceOf>>\ninterface: api.query.bfcStaking.nominatorState\ninterface: api.query.bfcStaking.nominatorState\nsummary: Gets nominator state associated with an account if the account is nominating else None.\nsummary: Gets nominator state associated with an account if the account is nominating else None.\nCandidateInfo(AccountId): Option<CandidateMetadata<AccountId, BalanceOf, BlockNumberOf>>\ninterface: api.query.bfcStaking.candidateInfo\ninterface: api.query.bfcStaking.candidateInfo\nsummary: Gets validator candidate info associated with an account if the account is candidate else None.\nsummary: Gets validator candidate info associated with an account if the account is candidate else None.\nBondedStash(AccountId): Option<AccountId>\ninterface: api.query.bfcStaking.bondedStash\ninterface: api.query.bfcStaking.bondedStash\nsummary: Map from all locked \"stash\" accounts to the controller account.\nsummary: Map from all locked \"stash\" accounts to the controller account.\nTopNominations(AccountId): Option<Nominations<AccountId, BalanceOf>>\ninterface: api.query.bfcStaking.topNominations\ninterface: api.query.bfcStaking.topNominations\nsummary: Top nominations for validator candidate.\nsummary: Top nominations for validator candidate.\nBottomNominations(AccountId): Option<Nominations<AccountId, BalanceOf>>\ninterface: api.query.bfcStaking.bottomNominations\ninterface: api.query.bfcStaking.bottomNominations\nsummary: Bottom nominations for validator candidate.\nsummary: Bottom nominations for validator candidate.\nSelectedCandidates(): Vec<AccountId>\ninterface: api.query.bfcStaking.selectedCandidates\ninterface: api.query.bfcStaking.selectedCandidates\nsummary: Active validator set (full and basic) selected for the current round.\nsummary: Active validator set (full and basic) selected for the current round.\nSelectedFullCandidates(): Vec<AccountId>\ninterface: api.query.bfcStaking.selectedFullCandidates\ninterface: api.query.bfcStaking.selectedFullCandidates\nsummary: Active full validator set selected for the current round.\nsummary: Active full validator set selected for the current round.\nSelectedBasicCandidates(): Vec<AccountId>\ninterface: api.query.bfcStaking.selectedBasicCandidates\ninterface: api.query.bfcStaking.selectedBasicCandidates\nsummary: Active basic validator set selected for the current round.\nsummary: Active basic validator set selected for the current round.\nCachedSelectedCandidates(): Vec<(RoundIndex, Vec<AccountId>)>\ninterface: api.query.bfcStaking.cachedSelectedCandidates\ninterface: api.query.bfcStaking.cachedSelectedCandidates\nsummary: Cached active validator set selected from previous rounds.\nsummary: Cached active validator set selected from previous rounds.\nMajority(): u32\ninterface: api.query.bfcStaking.majority\ninterface: api.query.bfcStaking.majority\nsummary: Majority of the current active validator set.\nsummary: Majority of the current active validator set.\nCachedMajority(): Vec<(RoundIndex, u32)>\ninterface: api.query.bfcStaking.cachedMajority\ninterface: api.query.bfcStaking.cachedMajority\nsummary: Cached majority based on the active validator set selected from previous rounds.\nsummary: Cached majority based on the active validator set selected from previous rounds.\nTotal(): BalanceOf\ninterface: api.query.bfcStaking.total\ninterface: api.query.bfcStaking.total\nsummary: Total capital locked by this staking pallet.\nsummary: Total capital locked by this staking pallet.\nCandidatePool(): Vec<Bond<AccountId, BalanceOf>>\ninterface: api.query.bfcStaking.candidatePool\ninterface: api.query.bfcStaking.candidatePool\nsummary: The pool of validator candidates, each with their total voting power.\nsummary: The pool of validator candidates, each with their total voting power.\nAtStake(RoundIndex): ValidatorSnapshot<AccountId, BalanceOf>\ninterface: api.query.bfcStaking.atStake\ninterface: api.query.bfcStaking.atStake\nsummary: Snapshot of validator nomination stake at the start of the round.\nsummary: Snapshot of validator nomination stake at the start of the round.\nTotalAtStake(RoundIndex): Option<TotalSnapshot<BalanceOf>>\ninterface: api.query.bfcStaking.totalAtStake\ninterface: api.query.bfcStaking.totalAtStake\nsummary: Snapshot of the network state at the start of the round.\nsummary: Snapshot of the network state at the start of the round.\nDelayedPayouts(RoundIndex): Option<DelayedPayout<BalanceOf>>\ninterface: api.query.bfcStaking.delayedPayouts\ninterface: api.query.bfcStaking.delayedPayouts\nsummary: Delayed reward payouts.\nsummary: Delayed reward payouts.\nDelayedControllerSets(RoundIndex): Vec<DelayedControllerSet<AccountId>>\ninterface: api.query.bfcStaking.delayedControllerSets\ninterface: api.query.bfcStaking.delayedControllerSets\nsummary: Delayed new controller account set requests.\nsummary: Delayed new controller account set requests.\nStaked(RoundIndex): BalanceOf\ninterface: api.query.bfcStaking.staked\ninterface: api.query.bfcStaking.staked\nsummary: Total counted stake for selected candidates in the round.\nsummary: Total counted stake for selected candidates in the round.\nInflationConfig(): InflationInfo<BalanceOf>\ninterface: api.query.bfcStaking.inflationConfig\ninterface: api.query.bfcStaking.inflationConfig\nsummary: Inflation configuration.\nsummary: Inflation configuration.\nPoints(RoundIndex): RewardPoint\ninterface: api.query.bfcStaking.points\ninterface: api.query.bfcStaking.points\nsummary: Total points awarded to validators for block production in the round.\nsummary: Total points awarded to validators for block production in the round.\nAwardedPts(AccountId): RewardPoint\ninterface: api.query.bfcStaking.awardedPts\ninterface: api.query.bfcStaking.awardedPts\nsummary: Points for each validator per round.\nsummary: Points for each validator per round.\nAwardedTokens(): BalanceOf\ninterface: api.query.bfcStaking.awardedTokens\ninterface: api.query.bfcStaking.awardedTokens\nsummary: Tokens awarded to validators and nominators since genesis.\nsummary: Tokens awarded to validators and nominators since genesis.\nConstants\nDefaultBlocksPerSession: u32\ninterface: api.consts.bfcStaking.defaultBlocksPerSession\ninterface: api.consts.bfcStaking.defaultBlocksPerSession\nsummary: Default number of blocks per session at genesis.\nsummary: Default number of blocks per session at genesis.\nDefaultBlocksPerRound: u32\ninterface: api.consts.bfcStaking.defaultBlocksPerRound\ninterface: api.consts.bfcStaking.defaultBlocksPerRound\nsummary: Default number of blocks per round at genesis.\nsummary: Default number of blocks per round at genesis.\nMinBlocksPerRound: u32\ninterface: api.consts.bfcStaking.minBlocksPerRound\ninterface: api.consts.bfcStaking.minBlocksPerRound\nsummary: Default minimum number of blocks per round at genesis.\nsummary: Default minimum number of blocks per round at genesis.\nStorageCacheLifetimeInRounds: u32\ninterface: api.consts.bfcStaking.storageCacheLifetimeInRounds\ninterface: api.consts.bfcStaking.storageCacheLifetimeInRounds\nsummary: Maximum lifetime in rounds for certain storage data to be cached.\nsummary: Maximum lifetime in rounds for certain storage data to be cached.\nLeaveCandidatesDelay: RoundIndex\ninterface: api.consts.bfcStaking.leaveCandidatesDelay\ninterface: api.consts.bfcStaking.leaveCandidatesDelay\nsummary: Number of rounds that candidates remain bonded before exit request is executable.\nsummary: Number of rounds that candidates remain bonded before exit request is executable.\nCandidateBondLessDelay: RoundIndex\ninterface: api.consts.bfcStaking.candidateBondLessDelay\ninterface: api.consts.bfcStaking.candidateBondLessDelay\nsummary: Number of rounds candidate requests to decrease self-bond must wait to be executable.\nsummary: Number of rounds candidate requests to decrease self-bond must wait to be executable.\nLeaveNominatorsDelay: RoundIndex\ninterface: api.consts.bfcStaking.leaveNominatorsDelay\ninterface: api.consts.bfcStaking.leaveNominatorsDelay\nsummary: Number of rounds that nominators remain bonded before exit request is executable.\nsummary: Number of rounds that nominators remain bonded before exit request is executable.\nRevokeNominationDelay: RoundIndex\ninterface: api.consts.bfcStaking.revokeNominationDelay\ninterface: api.consts.bfcStaking.revokeNominationDelay\nsummary: Number of rounds that nominations remain bonded before revocation request is executable.\nsummary: Number of rounds that nominations remain bonded before revocation request is executable.\nNominationBondLessDelay: RoundIndex\ninterface: api.consts.bfcStaking.nominationBondLessDelay\ninterface: api.consts.bfcStaking.nominationBondLessDelay\nsummary: Number of rounds that nomination less requests must wait before executable.\nsummary: Number of rounds that nomination less requests must wait before executable.\nRewardPaymentDelay: RoundIndex\ninterface: api.consts.bfcStaking.rewardPaymentDelay\ninterface: api.consts.bfcStaking.rewardPaymentDelay\nsummary: Number of rounds after which block authors are rewarded.\nsummary: Number of rounds after which block authors are rewarded.\nDefaultMaxSelectedFullCandidates: u32\ninterface: api.consts.bfcStaking.defaultMaxSelectedFullCandidates\ninterface: api.consts.bfcStaking.defaultMaxSelectedFullCandidates\nsummary: Default maximum number of selected full node candidates every round.\nsummary: Default maximum number of selected full node candidates every round.\nDefaultMaxSelectedBasicCandidates: u32\ninterface: api.consts.bfcStaking.defaultMaxSelectedBasicCandidates\ninterface: api.consts.bfcStaking.defaultMaxSelectedBasicCandidates\nsummary: Default maximum number of selected basic node candidates every round.\nsummary: Default maximum number of selected basic node candidates every round.\nDefaultMinSelectedCandidates: u32\ninterface: api.consts.bfcStaking.defaultMinSelectedCandidates\ninterface: api.consts.bfcStaking.defaultMinSelectedCandidates\nsummary: Default minimum number of selected candidates (full and basic) every round.\nsummary: Default minimum number of selected candidates (full and basic) every round.\nMaxTopNominationsPerCandidate: u32\ninterface: api.consts.bfcStaking.maxTopNominationsPerCandidate\ninterface: api.consts.bfcStaking.maxTopNominationsPerCandidate\nsummary: Maximum top nominations counted per candidate.\nsummary: Maximum top nominations counted per candidate.\nMaxBottomNominationsPerCandidate: u32\ninterface: api.consts.bfcStaking.maxBottomNominationsPerCandidate\ninterface: api.consts.bfcStaking.maxBottomNominationsPerCandidate\nsummary: Maximum bottom nominations counted per candidate.\nsummary: Maximum bottom nominations counted per candidate.\nMaxNominationsPerNominator: u32\ninterface: api.consts.bfcStaking.maxNominationsPerNominator\ninterface: api.consts.bfcStaking.maxNominationsPerNominator\nsummary: Maximum nominations per nominator.\nsummary: Maximum nominations per nominator.\nDefaultFullValidatorCommission: Perbill\ninterface: api.consts.bfcStaking.defaultFullValidatorCommission\ninterface: api.consts.bfcStaking.defaultFullValidatorCommission\nsummary: Default commission rate for a full validator.\nsummary: Default commission rate for a full validator.\nDefaultBasicValidatorCommission: Perbill\ninterface: api.consts.bfcStaking.defaultBasicValidatorCommission\ninterface: api.consts.bfcStaking.defaultBasicValidatorCommission\nsummary: Default commission rate for a basic validator.\nsummary: Default commission rate for a basic validator.\nMaxFullValidatorCommission: Perbill\ninterface: api.consts.bfcStaking.maxFullValidatorCommission\ninterface: api.consts.bfcStaking.maxFullValidatorCommission\nsummary: Maximum commission rate available for a full validator.\nsummary: Maximum commission rate available for a full validator.\nMaxBasicValidatorCommission: Perbill\ninterface: api.consts.bfcStaking.maxBasicValidatorCommission\ninterface: api.consts.bfcStaking.maxBasicValidatorCommission\nsummary: Maximum commission rate available for a basic validator.\nsummary: Maximum commission rate available for a basic validator.\nMinFullValidatorStk: BalanceOf\ninterface: api.consts.bfcStaking.minFullValidatorStk\ninterface: api.consts.bfcStaking.minFullValidatorStk\nsummary: Minimum stake required for any full node candidate to be in SelectedCandidates for the round.\nsummary: Minimum stake required for any full node candidate to be in SelectedCandidates for the round.\nMinBasicValidatorStk: BalanceOf\ninterface: api.consts.bfcStaking.minBasicValidatorStk\ninterface: api.consts.bfcStaking.minBasicValidatorStk\nsummary: Minimum stake required for any basic node candidate to be in SelectedCandidates for the round.\nsummary: Minimum stake required for any basic node candidate to be in SelectedCandidates for the round.\nMinFullCandidateStk: BalanceOf\ninterface: api.consts.bfcStaking.minFullCandidateStk\ninterface: api.consts.bfcStaking.minFullCandidateStk\nsummary: Minimum stake required for any account to be a full validator candidate.\nsummary: Minimum stake required for any account to be a full validator candidate.\nMinBasicCandidateStk: BalanceOf\ninterface: api.consts.bfcStaking.minBasicCandidateStk\ninterface: api.consts.bfcStaking.minBasicCandidateStk\nsummary: Minimum stake required for any account to be a basic validator candidate.\nsummary: Minimum stake required for any account to be a basic validator candidate.\nMinNominatorStk: BalanceOf\ninterface: api.consts.bfcStaking.minNominatorStk\ninterface: api.consts.bfcStaking.minNominatorStk\nsummary: Minimum stake for any registered on-chain account to be a nominator.\nsummary: Minimum stake for any registered on-chain account to be a nominator.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/pallet-interfaces/bfcstaking"
  },
  {
    "title": "BfcUtility",
    "content": "DEVELOPER DOCUMENTATIONS\nPALLET INTERFACES\nBfcUtility\nDescription\nThis pallet allows users to submit proposals to the community.\nExtrinsics\ncommunity_proposal(proposal: Vec<u8>)\ninterface: api.tx.bfcUtility.communityProposal\ninterface: api.tx.bfcUtility.communityProposal\nsummary: General community proposal without changes on codes.\nsummary: General community proposal without changes on codes.\nStorage Values\nAcceptedProposals(): Vec<Proposal>\ninterface: api.query.bfcUtility.acceptedProposals\ninterface: api.query.bfcUtility.acceptedProposals\nsummary: Storage for accepted proposals. Proposal passed by governance will be stored here.\nsummary: Storage for accepted proposals. Proposal passed by governance will be stored here.\nProposalIndex(): PropIndex\ninterface: api.query.bfcUtility.proposalIndex\ninterface: api.query.bfcUtility.proposalIndex\nsummary: Storage for proposal index. Whenever proposal is accepted, index will be increased.\nsummary: Storage for proposal index. Whenever proposal is accepted, index will be increased.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/pallet-interfaces/bfcutility"
  },
  {
    "title": "BfcOffences",
    "content": "DEVELOPER DOCUMENTATIONS\nPALLET INTERFACES\nBfcOffences\nDescription\nThe Bifrost Node tracks offences of validators and penalizes them to maintain network stability. The related implementation is defined in the pallet_bfc_offences module which is a central module implemented to handle offences reported through multiple modules and is responsible for counting offences and processing validator slashing.\nExtrinsics\nset_offence_expiration(new: SessionIndex)\ninterface: api.tx.bfcOffences.setOffenceExpiration\ninterface: api.tx.bfcOffences.setOffenceExpiration\nsummary: Sets a new offence expiration for all validators. It must be specified in sessions. The origin should be the root.\nsummary: Sets a new offence expiration for all validators. It must be specified in sessions. The origin should be the root.\nset_max_offence_count(new: OffenceCount)\ninterface: api.tx.bfcOffences.setMaxOffenceCount\ninterface: api.tx.bfcOffences.setMaxOffenceCount\nsummary: Sets a new maximum offence count for all validators. The origin should be the root.\nsummary: Sets a new maximum offence count for all validators. The origin should be the root.\nset_offence_activation(is_active: bool)\ninterface: api.tx.bfcOffences.setOffenceActivation\ninterface: api.tx.bfcOffences.setOffenceActivation\nsummary: Sets the activation of validator offence management. The origin should be the root.\nsummary: Sets the activation of validator offence management. The origin should be the root.\nset_slash_activation(is_active: bool)\ninterface: api.tx.bfcOffences.setOffenceActivation\ninterface: api.tx.bfcOffences.setOffenceActivation\nsummary: Sets the activation of validator slashing. The origin should be the root.\nsummary: Sets the activation of validator slashing. The origin should be the root.\nStorage Values\nValidatorOffences(AccountId): Option<ValidatorOffenceInfo<BalanceOf>>\ninterface: api.query.bfcOffences.validatorOffences\ninterface: api.query.bfcOffences.validatorOffences\nsummary: The current offence state of a specific validator.\nsummary: The current offence state of a specific validator.\nOffenceExpirationInSessions(): SessionIndex\ninterface: api.query.bfcOffences.offenceExpirationInSessions\ninterface: api.query.bfcOffences.offenceExpirationInSessions\nsummary: The current offence expiration in sessions.\nsummary: The current offence expiration in sessions.\nMaximumOffenceCount(): OffenceCount\ninterface: api.query.bfcOffences.maximumOffenceCount\ninterface: api.query.bfcOffences.maximumOffenceCount\nsummary: The current maximum offence count for all validators.\nsummary: The current maximum offence count for all validators.\nIsOffenceActive(): bool\ninterface: api.query.bfcOffences.isOffenceActive\ninterface: api.query.bfcOffences.isOffenceActive\nsummary: The current activation of validator offence management.\nsummary: The current activation of validator offence management.\nIsSlashActive(): bool\ninterface: api.query.bfcOffences.isSlashActive\ninterface: api.query.bfcOffences.isSlashActive\nsummary: The current activation of validator slashing.\nsummary: The current activation of validator slashing.\nConstants\nDefaultOffenceExpirationInSessions: SessionIndex\ninterface: api.consts.bfcOffences.defaultOffenceExpirationInSessions\ninterface: api.consts.bfcOffences.defaultOffenceExpirationInSessions\nsummary: The default offence expiration in sessions.\nsummary: The default offence expiration in sessions.\nDefaultMaximumOffenceCount: OffenceCount\ninterface: api.consts.bfcOffences.defaultMaximumOffenceCount\ninterface: api.consts.bfcOffences.defaultMaximumOffenceCount\nsummary: The default maximum offence count for all validators.\nsummary: The default maximum offence count for all validators.\nIsOffenceActive: bool\ninterface: api.consts.bfcOffences.isOffenceActive\ninterface: api.consts.bfcOffences.isOffenceActive\nsummary: The activation of validator offence management.\nsummary: The activation of validator offence management.\nIsSlashActive: bool\ninterface: api.consts.bfcOffences.isSlashActive\ninterface: api.consts.bfcOffences.isSlashActive\nsummary: The activation of validator slashing.\nsummary: The activation of validator slashing.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/pallet-interfaces/bfcoffences"
  },
  {
    "title": "RelayManager",
    "content": "DEVELOPER DOCUMENTATIONS\nPALLET INTERFACES\nRelayManager\nDescription\nFull node operators on the Bifrost Network must additionally operate the relayer program. Therefore, carefully managing and tracking the state of all relayers is crucial to maintaining the stability of the network. The core implementation for relayer management is defined in pallet_relay_manager.\nExtrinsics\nset_storage_cache_lifetime(new: u32)\ninterface: api.tx.relayManager.setStorageCacheLifetime\ninterface: api.tx.relayManager.setStorageCacheLifetime\nsummary: Sets the StorageCacheLifetime round length. The origin should be the root.\nsummary: Sets the StorageCacheLifetime round length. The origin should be the root.\nset_heartbeat_offence_activation(is_active: bool)\ninterface: api.tx.relayManager.setHeartbeatOffenceActivation\ninterface: api.tx.relayManager.setHeartbeatOffenceActivation\nsummary: Sets the activation of relayer heartbeat management. The origin should be the root.\nsummary: Sets the activation of relayer heartbeat management. The origin should be the root.\nset_heartbeat_slash_fraction(new: Perbill)\ninterface: api.tx.relayManager.setHeartbeatSlashFraction\ninterface: api.tx.relayManager.setHeartbeatSlashFraction\nsummary: Sets a new slash fraction for heartbeat offences. The origin should be the root.\nsummary: Sets a new slash fraction for heartbeat offences. The origin should be the root.\nset_relayer(new: AccountId)\ninterface: api.tx.relayManager.setRelayer\ninterface: api.tx.relayManager.setRelayer\nsummary: (Re-)sets the bonded relayer account. The origin must be the bonded controller account. The state reflection will be immediately applied.\nsummary: (Re-)sets the bonded relayer account. The origin must be the bonded controller account. The state reflection will be immediately applied.\nheartbeat()\ninterface: api.tx.relayManager.heartbeat\ninterface: api.tx.relayManager.heartbeat\nsummary: Sends a new heartbeat to manage relayer liveness for the current session. The origin must be the registered relayer account, and only the selected relayers can request.\nsummary: Sends a new heartbeat to manage relayer liveness for the current session. The origin must be the registered relayer account, and only the selected relayers can request.\nStorage Values\nStorageCacheLifetime(): u32\ninterface: api.query.relayManager.storageCacheLifetime\ninterface: api.query.relayManager.storageCacheLifetime\nsummary: The maximum storage lifetime for storage data to be cached.\nsummary: The maximum storage lifetime for storage data to be cached.\nRound(): RoundIndex\ninterface: api.query.relayManager.round\ninterface: api.query.relayManager.round\nsummary: The current round index.\nsummary: The current round index.\nBondedController(AccountId): Option<AccountId>\ninterface: api.query.relayManager.bondedController\ninterface: api.query.relayManager.bondedController\nsummary: Mapped controller accounts to the relayer account.\nsummary: Mapped controller accounts to the relayer account.\nRelayerPool(): Vec<Relayer<AccountId>>\ninterface: api.query.relayManager.relayerPool\ninterface: api.query.relayManager.relayerPool\nsummary: The pool of relayers of the current round (including selected and non-selected relayers).\nsummary: The pool of relayers of the current round (including selected and non-selected relayers).\nRelayerState(): Option<RelayerMetadata<AccountId>>\ninterface: api.query.relayManager.relayerState\ninterface: api.query.relayManager.relayerState\nsummary: The current state of a specific relayer.\nsummary: The current state of a specific relayer.\nSelectedRelayers(): Vec<AccountId>\ninterface: api.query.relayManager.selectedRelayers\ninterface: api.query.relayManager.selectedRelayers\nsummary: The active relayer set selected for the current round.\nsummary: The active relayer set selected for the current round.\nInitialSelectedRelayers(): Vec<AccountId>\ninterface: api.query.relayManager.initialSelectedRelayers\ninterface: api.query.relayManager.initialSelectedRelayers\nsummary: The active relayer set selected at the beginning of the current round.\nsummary: The active relayer set selected at the beginning of the current round.\nCachedSelectedRelayers(): Vec<(RoundIndex, Vec<AccountId>)>\ninterface: api.query.relayManager.cachedSelectedRelayers\ninterface: api.query.relayManager.cachedSelectedRelayers\nsummary: The cached active relayer set selected from previous rounds.\nsummary: The cached active relayer set selected from previous rounds.\nCachedInitialSelectedRelayers(): Vec<(RoundIndex, Vec<AccountId>)>\ninterface: api.query.relayManager.cachedInitialSelectedRelayers\ninterface: api.query.relayManager.cachedInitialSelectedRelayers\nsummary: The cached active relayer set selected from the beginning of each previous round.\nsummary: The cached active relayer set selected from the beginning of each previous round.\nMajority(): u32\ninterface: api.query.relayManager.majority\ninterface: api.query.relayManager.majority\nsummary: The majority of the current active relayer set.\nsummary: The majority of the current active relayer set.\nInitialMajority(): u32\ninterface: api.query.relayManager.initialMajority\ninterface: api.query.relayManager.initialMajority\nsummary: The majority of the current active relayer set at the beginning of the current round.\nsummary: The majority of the current active relayer set at the beginning of the current round.\nCachedMajority(): Vec<(RoundIndex, u32)>\ninterface: api.query.relayManager.cachedMajority\ninterface: api.query.relayManager.cachedMajority\nsummary: The cached majority based on the active relayer set selected from previous rounds.\nsummary: The cached majority based on the active relayer set selected from previous rounds.\nCachedInitialMajority(): Vec<(RoundIndex, u32)>\ninterface: api.query.relayManager.cachedInitialMajority\ninterface: api.query.relayManager.cachedInitialMajority\nsummary: The cached majority based on the active relayer set selected from the beginning of each previous rounds.\nsummary: The cached majority based on the active relayer set selected from the beginning of each previous rounds.\nReceivedHeartbeats(AccountId): bool\ninterface: api.query.relayManager.receivedHeartbeats\ninterface: api.query.relayManager.receivedHeartbeats\nsummary: The received heartbeats of a specific relayer in the current session.\nsummary: The received heartbeats of a specific relayer in the current session.\nIsHeartbeatOffenceActive(): bool\ninterface: api.query.relayManager.isHeartbeatOffenceActive\ninterface: api.query.relayManager.isHeartbeatOffenceActive\nsummary: The activation of relayer heartbeat offence management.\nsummary: The activation of relayer heartbeat offence management.\nHeartbeatSlashFraction(): Perbill\ninterface: api.query.relayManager.heartbeatSlashFraction\ninterface: api.query.relayManager.heartbeatSlashFraction\nsummary: The slash fraction for heartbeat offences.\nsummary: The slash fraction for heartbeat offences.\nConstants\nStorageCacheLifetimeInRounds: u32\ninterface: api.consts.relayManager.storageCacheLifetimeInRounds\ninterface: api.consts.relayManager.storageCacheLifetimeInRounds\nsummary: The maximum lifetime in rounds for storage data to be cached.\nsummary: The maximum lifetime in rounds for storage data to be cached.\nIsHeartbeatOffenceActive: bool\ninterface: api.consts.relayManager.isHeartbeatOffenceActive\ninterface: api.consts.relayManager.isHeartbeatOffenceActive\nsummary: The activation of relayer heartbeat offence management.\nsummary: The activation of relayer heartbeat offence management.\nDefaultHeartbeatSlashFraction: Perbill\ninterface: api.consts.relayManager.defaultHeartbeatSlashFraction\ninterface: api.consts.relayManager.defaultHeartbeatSlashFraction\nsummary: The default slash fraction for heartbeat offences.\nsummary: The default slash fraction for heartbeat offences.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/pallet-interfaces/relaymanager"
  },
  {
    "title": "Client API",
    "content": "DEVELOPER DOCUMENTATIONS\nClient API\nThe following sections contain the supported API endpoints of the Bifrost Network and the Bifrost Explorer.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api"
  },
  {
    "title": "JSON-RPC API",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nThe following sections contain known RPC methods available on the Bifrost Network which allow you to interact with the actual node, query, and submit.\nTestnet (ChainId: 49088)\nhttps://public-01.testnet.bifrostnetwork.com/rpc\nhttps://public-02.testnet.bifrostnetwork.com/rpc\nhttps://bifrost-testnet.g.allthatnode.com/archive/evm\n*https://bifrost-testnet.g.allthatnode.com/full/evm\nwss://public-01.testnet.bifrostnetwork.com/wss\nwss://public-02.testnet.bifrostnetwork.com/wss\nwss://bifrost-testnet.g.allthatnode.com/archive/evm\n*wss://bifrost-testnet.g.allthatnode.com/full/evm\n\"*\" denotes a full node RPC.\nMainnet (ChainId: 3068)\nhttps://public-01.mainnet.bifrostnetwork.com/rpc\nhttps://public-02.mainnet.bifrostnetwork.com/rpc\nhttps://bifrost-mainnet.g.allthatnode.com/archive/evm\n*https://bifrost-mainnet.g.allthatnode.com/full/evm\nwss://public-01.mainnet.bifrostnetwork.com/wss\nwss://public-02.mainnet.bifrostnetwork.com/wss\nwss://bifrost-mainnet.g.allthatnode.com/archive/evm\n*wss://bifrost-mainnet.g.allthatnode.com/full/evm\nLast updated 8 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api"
  },
  {
    "title": "author",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nauthor\nhasKey(publicKey: Bytes, keyType: Text): bool\ninterface: api.rpc.author.hasKey\ninterface: api.rpc.author.hasKey\njsonrpc: author_hasKey\njsonrpc: author_hasKey\nsummary: Returns true if the keystore has private keys for the given public key and key type.\nsummary: Returns true if the keystore has private keys for the given public key and key type.\nhasSessionKeys(sessionKeys: Bytes): bool\ninterface: api.rpc.author.hasSessionKeys\ninterface: api.rpc.author.hasSessionKeys\njsonrpc: author_hasSessionKeys\njsonrpc: author_hasSessionKeys\nsummary: Returns true if the keystore has private keys for the given session public keys.\nsummary: Returns true if the keystore has private keys for the given session public keys.\ninsertKey(keyType: Text, suri: Text, publicKey: Bytes): Bytes\ninterface: api.rpc.author.insertKey\ninterface: api.rpc.author.insertKey\njsonrpc: author_insertKey\njsonrpc: author_insertKey\nsummary: Inserts a key into the keystore.\nsummary: Inserts a key into the keystore.\npendingExtrinsics(): Vec<Extrinsic>\ninterface: api.rpc.author.pendingExtrinsics\ninterface: api.rpc.author.pendingExtrinsics\njsonrpc: author_pendingExtrinsics\njsonrpc: author_pendingExtrinsics\nsummary: Returns all pending extrinsics, potentially grouped by sender\nsummary: Returns all pending extrinsics, potentially grouped by sender\nremoveExtrinsic(bytesOrHash: Vec<ExtrinsicOrHash>): Vec<Hash>\ninterface: api.rpc.author.removeExtrinsic\ninterface: api.rpc.author.removeExtrinsic\njsonrpc: author_removeExtrinsic\njsonrpc: author_removeExtrinsic\nsummary: Removes given extrinsic from the pool and temporarily ban it to prevent reimporting\nsummary: Removes given extrinsic from the pool and temporarily ban it to prevent reimporting\nrotateKeys(): Bytes\ninterface: api.rpc.author.rotateKeys\ninterface: api.rpc.author.rotateKeys\njsonrpc: author_rotateKeys\njsonrpc: author_rotateKeys\nsummary: Generates new session keys and returns the corresponding public keys\nsummary: Generates new session keys and returns the corresponding public keys\nsubmitExtrinsic(extrinsic: Extrinsic): Hash\ninterface: api.rpc.author.submitExtrinsic\ninterface: api.rpc.author.submitExtrinsic\njsonrpc: author_submitExtrinsic\njsonrpc: author_submitExtrinsic\nsummary: Submits a fully formatted extrinsic for block inclusion\nsummary: Submits a fully formatted extrinsic for block inclusion\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/author"
  },
  {
    "title": "chain",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nchain\ngetBlock(hash?: BlockHash): SignedBlock\ninterface: api.rpc.chain.getBlock\ninterface: api.rpc.chain.getBlock\njsonrpc: chain_getBlock\njsonrpc: chain_getBlock\nsummary: Gets the header and body of the target chain block\nsummary: Gets the header and body of the target chain block\ngetBlockHash(blockNumber?: BlockNumber): BlockHash\ninterface: api.rpc.chain.getBlockHash\ninterface: api.rpc.chain.getBlockHash\njsonrpc: chain_getBlockHash (alias=chain_getHead)\njsonrpc: chain_getBlockHash (alias=chain_getHead)\nsummary: Gets the block hash for a specific block\nsummary: Gets the block hash for a specific block\ngetFinalizedHead(): BlockHash\ninterface: api.rpc.chain.getFinalizedHead\ninterface: api.rpc.chain.getFinalizedHead\njsonrpc: chain_getFinalizedHead (alias=chain_getFinalisedHead)\njsonrpc: chain_getFinalizedHead (alias=chain_getFinalisedHead)\nsummary: Gets hash of the last finalized block in the canon chain\nsummary: Gets hash of the last finalized block in the canon chain\ngetHeader(hash?: BlockHash): Header\ninterface: api.rpc.chain.getHeader\ninterface: api.rpc.chain.getHeader\njsonrpc: chain_getHeader\njsonrpc: chain_getHeader\nsummary: Retrieves the header for a specific block\nsummary: Retrieves the header for a specific block\nsubscribeAllHeads(): Header\ninterface: api.rpc.chain.subscribeAllHeads\ninterface: api.rpc.chain.subscribeAllHeads\njsonrpc: chain_subscribeAllHeads\njsonrpc: chain_subscribeAllHeads\nsummary: Retrieves the newest header via subscription\nsummary: Retrieves the newest header via subscription\nsubscribeFinalizedHeads(): Header\ninterface: api.rpc.chain.subscribeFinalizedHeads\ninterface: api.rpc.chain.subscribeFinalizedHeads\njsonrpc: chain_subscribeFinalizedHeads (alias=chain_subscribeFinalisedHeads)\njsonrpc: chain_subscribeFinalizedHeads (alias=chain_subscribeFinalisedHeads)\nsummary: Retrieves the best finalized header via subscription.\nsummary: Retrieves the best finalized header via subscription.\nsubscribeNewHeads(): Header\ninterface: api.rpc.chain.subscribeNewHeads\ninterface: api.rpc.chain.subscribeNewHeads\njsonrpc: chain_subscribeNewHeads (alias=chain_subscribeNewHead)\njsonrpc: chain_subscribeNewHeads (alias=chain_subscribeNewHead)\nsummary: Retrieves the best header via subscription.\nsummary: Retrieves the best header via subscription.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/chain"
  },
  {
    "title": "childstate",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nchildstate\ngetKeys(childKey: PrefixedStorageKey, prefix: StorageKey, at?: Hash): Vec<StorageKey>\ninterface: api.rpc.childstate.getKeys\ninterface: api.rpc.childstate.getKeys\njsonrpc: childstate_getKeys\njsonrpc: childstate_getKeys\nsummary: Returns the keys with prefix from a child storage, leave empty to get all the keys\nsummary: Returns the keys with prefix from a child storage, leave empty to get all the keys\ngetKeysPaged(childKey: PrefixedStorageKey, prefix: StorageKey, count: u32, startKey?: StorageKey, at?: Hash): Vec<StorageKey>\ninterface: api.rpc.childstate.getKeysPaged\ninterface: api.rpc.childstate.getKeysPaged\njsonrpc: childstate_getKeysPaged\njsonrpc: childstate_getKeysPaged\nsummary: Returns the keys with prefix from a child storage with pagination support\nsummary: Returns the keys with prefix from a child storage with pagination support\ngetStorage(childKey: PrefixedStorageKey, key: StorageKey, at?: Hash): Option<StorageData>\ninterface: api.rpc.childstate.getStorage\ninterface: api.rpc.childstate.getStorage\njsonrpc: childstate_getStorage\njsonrpc: childstate_getStorage\nsummary: Returns a child storage entry at a specific block state\nsummary: Returns a child storage entry at a specific block state\ngetStorageEntries(childKey: PrefixedStorageKey, keys: Vec<StorageKey>, at?: Hash): Vec<Option<StorageData>>\ninterface: api.rpc.childstate.getStorageEntries\ninterface: api.rpc.childstate.getStorageEntries\njsonrpc: childstate_getStorageEntries\njsonrpc: childstate_getStorageEntries\nsummary: Returns child storage entries for multiple keys at a specific block state\nsummary: Returns child storage entries for multiple keys at a specific block state\ngetStorageHash(childKey: PrefixedStorageKey, key: StorageKey, at?: Hash): Option<Hash>\ninterface: api.rpc.childstate.getStorageHash\ninterface: api.rpc.childstate.getStorageHash\njsonrpc: childstate_getStorageHash\njsonrpc: childstate_getStorageHash\nsummary: Returns the hash of a child storage entry at a block state\nsummary: Returns the hash of a child storage entry at a block state\ngetStorageSize(childKey: PrefixedStorageKey, key: StorageKey, at?: Hash): Option<u64>\ninterface: api.rpc.childstate.getStorageSize\ninterface: api.rpc.childstate.getStorageSize\njsonrpc: childstate_getStorageSize\njsonrpc: childstate_getStorageSize\nsummary: Returns the size of a child storage entry at a block state\nsummary: Returns the size of a child storage entry at a block state\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/childstate"
  },
  {
    "title": "debug",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\ndebug\ntraceBlockByHash(id: BlockHash, params?: TraceParams): Vec<TransactionTrace>\njsonrpc: debug_traceBlockByHash\njsonrpc: debug_traceBlockByHash\nsummary: traceBlockByHash accepts a block hash and will replay the block that is already present in the database. For the second parameter, see theTraceParams reference.\nsummary: traceBlockByHash accepts a block hash and will replay the block that is already present in the database. For the second parameter, see theTraceParams reference.\ntraceBlockByNumber(id: BlockNumber, params?: TraceParams): Vec<TransactionTrace>\njsonrpc: debug_traceBlockByNumber\njsonrpc: debug_traceBlockByNumber\nsummary: traceBlockByNumber accepts a block number and will replay the block that is already present in the database. For the second parameter, see theTraceParams reference.\nsummary: traceBlockByNumber accepts a block number and will replay the block that is already present in the database. For the second parameter, see theTraceParams reference.\ntraceTransaction(transaction_hash: hash, params?: TraceParams): TransactionTrace\njsonrpc: debug_traceTransaction\njsonrpc: debug_traceTransaction\nsummary: The traceTransactiondebugging method will attempt to run the transaction in the exact same manner as it was executed on the network. It will replay any transaction that may have been executed prior to the current one before it finally attempts to execute the transaction that corresponds to the given hash. For the second parameter, see the TraceParams reference.\nsummary: The traceTransactiondebugging method will attempt to run the transaction in the exact same manner as it was executed on the network. It will replay any transaction that may have been executed prior to the current one before it finally attempts to execute the transaction that corresponds to the given hash. For the second parameter, see the TraceParams reference.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/debug"
  },
  {
    "title": "eth",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\neth\naccounts(): Vec<H160>\ninterface: api.rpc.eth.accounts\ninterface: api.rpc.eth.accounts\njsonrpc: eth_accounts\njsonrpc: eth_accounts\nsummary: Returns a list of addresses owned by client.\nsummary: Returns a list of addresses owned by client.\nblockNumber(): U256\ninterface: api.rpc.eth.blockNumber\ninterface: api.rpc.eth.blockNumber\njsonrpc: eth_blockNumber\njsonrpc: eth_blockNumber\nsummary: Returns the current \"latest\" block number.\nsummary: Returns the current \"latest\" block number.\ncall(transaction: transactionObject, block?: BlockNumber): HexString\ninterface: api.rpc.eth.call\ninterface: api.rpc.eth.call\njsonrpc: eth_call\njsonrpc: eth_call\nsummary: Executes a new message call immediately without creating a transaction on the block chain.\nsummary: Executes a new message call immediately without creating a transaction on the block chain.\nchainId(): HexString\ninterface: api.rpc.eth.chainId\ninterface: api.rpc.eth.chainId\njsonrpc: eth_chainId\njsonrpc: eth_chainId\nsummary: Returns the currently configured chain id.\nsummary: Returns the currently configured chain id.\ncoinbase(): H160\ninterface: api.rpc.eth.coinbase\ninterface: api.rpc.eth.coinbase\njsonrpc: eth_coinbase\njsonrpc: eth_coinbase\nsummary: Returns block author.\nsummary: Returns block author.\nestimateGas(transaction: transactionObject, block?: BlockNumber): HexString\ninterface: api.rpc.eth.estimateGas\ninterface: api.rpc.eth.estimateGas\njsonrpc: eth_estimateGas\njsonrpc: eth_estimateGas\nsummary: Estimates gas needed for execution of given transaction.\nsummary: Estimates gas needed for execution of given transaction.\nfeeHistory(blockCount: U256, newest_block: BlockNumber, reward_percentiles?: Vec<f64>): FeeHistory\ninterface: api.rpc.eth.feeHistory\ninterface: api.rpc.eth.feeHistory\njsonrpc: eth_feeHistory\njsonrpc: eth_feeHistory\nsummary: Introduced in EIP-1159 for getting information on the appropriate priority fee to use.\nsummary: Introduced in EIP-1159 for getting information on the appropriate priority fee to use.\ngasPrice(): HexString\ninterface: api.rpc.eth.gasPrice\ninterface: api.rpc.eth.gasPrice\njsonrpc: eth_gasPrice\njsonrpc: eth_gasPrice\nsummary: Returns the current gas price in wei.\nsummary: Returns the current gas price in wei.\ngetBalance(address: H160, block?: BlockNumber): HexString\ninterface: api.rpc.eth.getBalance\ninterface: api.rpc.eth.getBalance\njsonrpc: eth_getBalance\njsonrpc: eth_getBalance\nsummary: Returns the balance of the account of given address.\nsummary: Returns the balance of the account of given address.\ngetBlockByHash(hash: H256, full?: bool): BlockObject\ninterface: api.rpc.eth.getBlockByHash\ninterface: api.rpc.eth.getBlockByHash\njsonrpc: eth_getBlockByHash\njsonrpc: eth_getBlockByHash\nsummary: Returns information about a block by hash.\nsummary: Returns information about a block by hash.\ngetBlockByNumber(BlockNumber: BlockNumber, full?: bool): BlockObject\ninterface: api.rpc.eth.getBlockByNumber\ninterface: api.rpc.eth.getBlockByNumber\njsonrpc: eth_getBlockByNumber\njsonrpc: eth_getBlockByNumber\nsummary: Returns information about a block by hash.\nsummary: Returns information about a block by hash.\ngetBlockTransactionCountByHash(hash: H256): U256\ninterface: api.rpc.eth.getBlockTransactionCountByHash\ninterface: api.rpc.eth.getBlockTransactionCountByHash\njsonrpc: eth_getBlockTransactionCountByHash\njsonrpc: eth_getBlockTransactionCountByHash\nsummary: Returns the number of transactions in the block with the given block hash.\nsummary: Returns the number of transactions in the block with the given block hash.\ngetBlockTransactionCountByNumber(BlockNumber: BlockNumber): U256\ninterface: api.rpc.eth.getBlockTransactionCountByNumber\ninterface: api.rpc.eth.getBlockTransactionCountByNumber\njsonrpc: eth_getBlockTransactionCountByNumber\njsonrpc: eth_getBlockTransactionCountByNumber\nsummary: Returns the number of transactions in the block with the given block number.\nsummary: Returns the number of transactions in the block with the given block number.\ngetCode(address: H160, number?: BlockNumber): Bytes\ninterface: api.rpc.eth.getCode\ninterface: api.rpc.eth.getCode\njsonrpc: eth_getCode\njsonrpc: eth_getCode\nsummary: Returns the compiled smart contract code, if any, at a given address.\nsummary: Returns the compiled smart contract code, if any, at a given address.\ngetFilterChanges(index: Index): FilterChanges\ninterface: api.rpc.eth.getFilterChanges\ninterface: api.rpc.eth.getFilterChanges\njsonrpc: eth_getFilterChanges\njsonrpc: eth_getFilterChanges\nsummary: Polling method for a filter, which returns an array of logs that occurred since the last poll. A filter must be created by calling either eth_newFilter or eth_newBlockFilter\nsummary: Polling method for a filter, which returns an array of logs that occurred since the last poll. A filter must be created by calling either eth_newFilter or eth_newBlockFilter\ngetFilterLogs(index: Index): Vec<Log>\ninterface: api.rpc.eth.getFilterLogs\ninterface: api.rpc.eth.getFilterLogs\njsonrpc: eth_getFilterLogs\njsonrpc: eth_getFilterLogs\nsummary: Returns an array of all logs matching filter with given id.\nsummary: Returns an array of all logs matching filter with given id.\ngetLogs(filter: Filter): Vec<Log>\ninterface: api.rpc.eth.getLogs\ninterface: api.rpc.eth.getLogs\njsonrpc: eth_getLogs\njsonrpc: eth_getLogs\nsummary: Returns an array of all logs matching a given filter object.\nsummary: Returns an array of all logs matching a given filter object.\ngetStorageAt(address: H160, index: U256, number?: BlockNumber): H256\ninterface: api.rpc.eth.getStorageAt\ninterface: api.rpc.eth.getStorageAt\njsonrpc: eth_getStorageAt\njsonrpc: eth_getStorageAt\nsummary: Returns the value from a storage position at a given address.\nsummary: Returns the value from a storage position at a given address.\ngetTransactionByBlockHashAndIndex(hash: H256, index: Index): Transaction\ninterface: api.rpc.eth.getTransactionByBlockHash\ninterface: api.rpc.eth.getTransactionByBlockHash\njsonrpc: eth_getTransactionByBlockHashAndIndex\njsonrpc: eth_getTransactionByBlockHashAndIndex\nsummary: Returns information about a transaction by block hash and transaction index position.\nsummary: Returns information about a transaction by block hash and transaction index position.\ngetTransactionByBlockNumberAndIndex(number: BlockNumber, index: Index): Transaction\ninterface: api.rpc.eth.getTransactionByBlockNumberAndIndex\ninterface: api.rpc.eth.getTransactionByBlockNumberAndIndex\njsonrpc: eth_getTransactionByBlockNumberAndIndex\njsonrpc: eth_getTransactionByBlockNumberAndIndex\nsummary: Returns information about a transaction by block number and transaction index position.\nsummary: Returns information about a transaction by block number and transaction index position.\ngetTransactionByHash(hash: H256): Transaction\ninterface: api.rpc.eth.getTransactionByHash\ninterface: api.rpc.eth.getTransactionByHash\njsonrpc: eth_getTransactionByHash\njsonrpc: eth_getTransactionByHash\nsummary: Returns information about a transaction for a given hash.\nsummary: Returns information about a transaction for a given hash.\ngetTransactionCount(address: H160, number?: BlockNumber): U256\ninterface: api.rpc.eth.getTransactionCount\ninterface: api.rpc.eth.getTransactionCount\njsonrpc: eth_getTransactionCount\njsonrpc: eth_getTransactionCount\nsummary: Returns the number of transactions sent from an address.\nsummary: Returns the number of transactions sent from an address.\ngetTransactionReceipt(hash: H256): Receipt\ninterface: api.rpc.eth.getTransactionReceipt\ninterface: api.rpc.eth.getTransactionReceipt\njsonrpc: eth_getTransactionReceipt\njsonrpc: eth_getTransactionReceipt\nsummary: Returns the receipt of a transaction by transaction hash.\nsummary: Returns the receipt of a transaction by transaction hash.\nmaxPriorityFeePerGas(): U256\ninterface: api.rpc.eth.maxPriorityFeePerGas\ninterface: api.rpc.eth.maxPriorityFeePerGas\njsonrpc: eth_maxPriorityFeePerGas\njsonrpc: eth_maxPriorityFeePerGas\nsummary: Introduced in EIP-1159, a Geth-specific and simplified priority fee oracle.\nsummary: Introduced in EIP-1159, a Geth-specific and simplified priority fee oracle.\nnewBlockFilter(): U256\ninterface: api.rpc.eth.newBlockFilter\ninterface: api.rpc.eth.newBlockFilter\njsonrpc: eth_newBlockFilter\njsonrpc: eth_newBlockFilter\nsummary: Creates a filter in the node, to notify when a new block arrives. To check if the state has changed, call eth_getFilterChanges.\nsummary: Creates a filter in the node, to notify when a new block arrives. To check if the state has changed, call eth_getFilterChanges.\nnewFilter(filter: Filter): U256\ninterface: api.rpc.eth.newFilter\ninterface: api.rpc.eth.newFilter\njsonrpc: eth_newFilter\njsonrpc: eth_newFilter\nsummary: Creates a filter object, based on filter options, to notify when the state changes (logs). To check if the state has changed, call eth_getFilterChanges\nsummary: Creates a filter object, based on filter options, to notify when the state changes (logs). To check if the state has changed, call eth_getFilterChanges\nprotocolVersion(): u64\ninterface: api.rpc.eth.protocolVersion\ninterface: api.rpc.eth.protocolVersion\njsonrpc: eth_protocolVersion\njsonrpc: eth_protocolVersion\nsummary: Returns the current Ethereum protocol version.\nsummary: Returns the current Ethereum protocol version.\nsendRawTransaction(bytes: Bytes): H256\ninterface: api.rpc.eth.sendRawTransaction\ninterface: api.rpc.eth.sendRawTransaction\njsonrpc: eth_sendRawTransaction\njsonrpc: eth_sendRawTransaction\nsummary: Submits a pre-signed transaction for broadcast to the network.\nsummary: Submits a pre-signed transaction for broadcast to the network.\nsendTransaction(request: TransactionRequest): H256\ninterface: api.rpc.eth.sendTransaction\ninterface: api.rpc.eth.sendTransaction\njsonrpc: eth_sendTransaction\njsonrpc: eth_sendTransaction\nsummary: Sends transaction; will block waiting for the signer to return the transaction hash.\nsummary: Sends transaction; will block waiting for the signer to return the transaction hash.\nsyncing(): SyncStatus\ninterface: api.rpc.eth.syncing\ninterface: api.rpc.eth.syncing\njsonrpc: eth_syncing\njsonrpc: eth_syncing\nsummary: Returns an object with data about the sync status or false.\nsummary: Returns an object with data about the sync status or false.\nuninstallFilter(index: Index): bool\ninterface: api.rpc.eth.uninstallFilter\ninterface: api.rpc.eth.uninstallFilter\njsonrpc: eth_uninstallFilter\njsonrpc: eth_uninstallFilter\nsummary: Uninstalls a filter with given ID. Should always be called when watching is no longer needed. Additionally filters time out when not requested with eth_getFilterChanges for a period of time.\nsummary: Uninstalls a filter with given ID. Should always be called when watching is no longer needed. Additionally filters time out when not requested with eth_getFilterChanges for a period of time.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/eth"
  },
  {
    "title": "grandpa",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\ngrandpa\nproveFinality(blockNumber: BlockNumber): Option<EncodedFinalityProofs>\ninterface: api.rpc.grandpa.proveFinality\ninterface: api.rpc.grandpa.proveFinality\njsonrpc: grandpa_proveFinality\njsonrpc: grandpa_proveFinality\nsummary: Proves finality for the given block number, returning the Justification for the last block in the set.\nsummary: Proves finality for the given block number, returning the Justification for the last block in the set.\nroundState(): ReportedRoundStates\ninterface: api.rpc.grandpa.roundState\ninterface: api.rpc.grandpa.roundState\njsonrpc: grandpa_roundState\njsonrpc: grandpa_roundState\nsummary: Returns the state of the current best round state as well as the ongoing background rounds.\nsummary: Returns the state of the current best round state as well as the ongoing background rounds.\nsubscribeJustifications(): JustificationNotification\ninterface: api.rpc.grandpa.subscribeJustifications\ninterface: api.rpc.grandpa.subscribeJustifications\njsonrpc: grandpa_subscribeJustifications\njsonrpc: grandpa_subscribeJustifications\nsummary: Subscribes to grandpa justifications.\nsummary: Subscribes to grandpa justifications.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/grandpa"
  },
  {
    "title": "net",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nnet\nlistening(): bool\ninterface: api.rpc.net.listening\ninterface: api.rpc.net.listening\njsonrpc: net_listening\njsonrpc: net_listening\nsummary: Returns true if client is actively listening for network connections. Otherwise false.\nsummary: Returns true if client is actively listening for network connections. Otherwise false.\npeerCount(): Text\ninterface: api.rpc.net.peerCount\ninterface: api.rpc.net.peerCount\njsonrpc: net_peerCount\njsonrpc: net_peerCount\nsummary: Returns number of peers connected to node.\nsummary: Returns number of peers connected to node.\nversion(): Text\ninterface: api.rpc.net.version\ninterface: api.rpc.net.version\njsonrpc: net_version\njsonrpc: net_version\nsummary: Returns protocol version.\nsummary: Returns protocol version.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/net"
  },
  {
    "title": "offchain",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\noffchain\nlocalStorageGet(kind: StorageKind, key: Bytes): Option<Bytes>\ninterface: api.rpc.offchain.localStorageGet\ninterface: api.rpc.offchain.localStorageGet\njsonrpc: offchain_localStorageGet\njsonrpc: offchain_localStorageGet\nsummary: Gets off-chain local storage under the given key and prefix.\nsummary: Gets off-chain local storage under the given key and prefix.\nlocalStorageSet(kind: StorageKind, key: Bytes, value: Bytes): Null\ninterface: api.rpc.offchain.localStorageSet\ninterface: api.rpc.offchain.localStorageSet\njsonrpc: offchain_localStorageSet\njsonrpc: offchain_localStorageSet\nsummary: Sets off-chain local storage under the given key and prefix.\nsummary: Sets off-chain local storage under the given key and prefix.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/offchain"
  },
  {
    "title": "payment",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\npayment\nqueryFeeDetails(extrinsic: Bytes, at?: BlockHash): FeeDetails\ninterface: api.rpc.payment.queryFeeDetails\ninterface: api.rpc.payment.queryFeeDetails\njsonrpc: payment_queryFeeDetails\njsonrpc: payment_queryFeeDetails\nsummary: Queries the detailed fee of a given encoded extrinsic.\nsummary: Queries the detailed fee of a given encoded extrinsic.\ndeprecated: Use api.call.transactionPaymentApi.queryFeeDetails instead.\ndeprecated: Use api.call.transactionPaymentApi.queryFeeDetails instead.\nqueryInfo(extrinsic: Bytes, at?: BlockHash): RuntimeDispatchInfoV1\ninterface: api.rpc.payment.queryInfo\ninterface: api.rpc.payment.queryInfo\njsonrpc: payment_queryInfo\njsonrpc: payment_queryInfo\nsummary: Retrieves the fee information for an encoded extrinsic.\nsummary: Retrieves the fee information for an encoded extrinsic.\ndeprecated: Use api.call.transactionPaymentApi.queryInfo instead.\ndeprecated: Use api.call.transactionPaymentApi.queryInfo instead.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/payment"
  },
  {
    "title": "rpc",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nrpc\nmethods(): RpcMethods\ninterface: api.rpc.rpc.methods\ninterface: api.rpc.rpc.methods\njsonrpc: rpc_methods\njsonrpc: rpc_methods\nsummary: Retrieves the list of RPC methods that are exposed by the node.\nsummary: Retrieves the list of RPC methods that are exposed by the node.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/rpc"
  },
  {
    "title": "state",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nstate\ncall(method: Text, data: Bytes, at?: BlockHash): Bytes\ninterface: api.rpc.state.call\ninterface: api.rpc.state.call\njsonrpc: state_call (alias=state_callAt)\njsonrpc: state_call (alias=state_callAt)\nsummary: Calls a contract (pallet) at a block's state.\nsummary: Calls a contract (pallet) at a block's state.\ngetChildReadProof(childStorageKey: PrefixedStorageKey, keys: Vec<StorageKey>, at?: BlockHash): ReadProof\ninterface: api.rpc.state.getChildReadProof\ninterface: api.rpc.state.getChildReadProof\njsonrpc: state_getChildReadProof\njsonrpc: state_getChildReadProof\nsummary: Returns proof of storage for child key entries at a specific block state.\nsummary: Returns proof of storage for child key entries at a specific block state.\ngetKeys(key: StorageKey, at?: BlockHash): Vec<StorageKey>\ninterface: api.rpc.state.getKeys\ninterface: api.rpc.state.getKeys\njsonrpc: state_getKeys\njsonrpc: state_getKeys\nsummary: Retrieves the keys with a certain prefix.\nsummary: Retrieves the keys with a certain prefix.\ndeprecated: Use api.rpc.state.getKeysPaged to retrieve keys.\ndeprecated: Use api.rpc.state.getKeysPaged to retrieve keys.\ngetKeysPaged(key: StorageKey, count: u32, startKey?: StorageKey, at?: BlockHash): Vec<StorageKey>\ninterface: api.rpc.state.getKeysPaged\ninterface: api.rpc.state.getKeysPaged\njsonrpc: state_getKeysPaged (alias=state_getKeysPagedAt)\njsonrpc: state_getKeysPaged (alias=state_getKeysPagedAt)\nsummary: Returns the keys with prefix with pagination support.\nsummary: Returns the keys with prefix with pagination support.\ngetMetadata(at?: BlockHash): Metadata\ninterface: api.rpc.state.getMetadata\ninterface: api.rpc.state.getMetadata\njsonrpc: state_getMetadata\njsonrpc: state_getMetadata\nsummary: Returns the runtime metadata.\nsummary: Returns the runtime metadata.\ngetPairs(prefix: StorageKey, at?: BlockHash): Vec<KeyValue>\ninterface: api.rpc.state.getPairs\ninterface: api.rpc.state.getPairs\njsonrpc: state_getPairs\njsonrpc: state_getPairs\nsummary: Returns the keys with prefix, leaves empty to get all the keys (deprecated: Use getKeysPaged).\nsummary: Returns the keys with prefix, leaves empty to get all the keys (deprecated: Use getKeysPaged).\ndeprecated: Use api.rpc.state.getKeysPaged to retrieve keys.\ndeprecated: Use api.rpc.state.getKeysPaged to retrieve keys.\ngetReadProof(keys: Vec<StorageKey>, at?: BlockHash): ReadProof\ninterface: api.rpc.state.getReadProof\ninterface: api.rpc.state.getReadProof\njsonrpc: state_getReadProof\njsonrpc: state_getReadProof\nsummary: Returns proof of storage entries at a specific block state.\nsummary: Returns proof of storage entries at a specific block state.\ngetRuntimeVersion(at?: BlockHash): RuntimeVersion\ninterface: api.rpc.state.getRuntimeVersion\ninterface: api.rpc.state.getRuntimeVersion\njsonrpc: state_getRuntimeVersion (alias=chain_getRuntimeVersion)\njsonrpc: state_getRuntimeVersion (alias=chain_getRuntimeVersion)\nsummary: Gets the runtime version.\nsummary: Gets the runtime version.\ngetStorage(key: StorageKey, at?: BlockHash): StorageData\ninterface: api.rpc.state.getStorage\ninterface: api.rpc.state.getStorage\njsonrpc: state_getStorage (alias=state_getStorageAt)\njsonrpc: state_getStorage (alias=state_getStorageAt)\nsummary: Retrieves the storage for a key.\nsummary: Retrieves the storage for a key.\ngetStorageHash(key: StorageKey, at?: BlockHash): Hash\ninterface: api.rpc.state.getStorageHash\ninterface: api.rpc.state.getStorageHash\njsonrpc: state_getStorageHash (alias=state_getStorageHashAt)\njsonrpc: state_getStorageHash (alias=state_getStorageHashAt)\nsummary: Retrieves the storage hash.\nsummary: Retrieves the storage hash.\ngetStorageSize(key: StorageKey, at?: BlockHash): u64\ninterface: api.rpc.state.getStorageSize\ninterface: api.rpc.state.getStorageSize\njsonrpc: state_getStorageSize (alias=state_getStorageSizeAt)\njsonrpc: state_getStorageSize (alias=state_getStorageSizeAt)\nsummary: Retrieves the storage size.\nsummary: Retrieves the storage size.\nqueryStorage(keys: Vec<StorageKey>, fromBlock: Hash, toBlock?: BlockHash): Vec<StorageChangeSet>\ninterface: api.rpc.state.queryStorage\ninterface: api.rpc.state.queryStorage\njsonrpc: state_queryStorage\njsonrpc: state_queryStorage\nsummary: Queries historical storage entries (by key) starting from a start block.\nsummary: Queries historical storage entries (by key) starting from a start block.\nqueryStorageAt(keys: Vec<StorageKey>, at?: BlockHash): Vec<StorageChangeSet>\ninterface: api.rpc.state.queryStorageAt\ninterface: api.rpc.state.queryStorageAt\njsonrpc: state_queryStorageAt\njsonrpc: state_queryStorageAt\nsummary: Queries storage entries (by key) starting at block hash given as the second parameter.\nsummary: Queries storage entries (by key) starting at block hash given as the second parameter.\nsubscribeRuntimeVersion(): RuntimeVersion\ninterface: api.rpc.state.subscribeRuntimeVersion\ninterface: api.rpc.state.subscribeRuntimeVersion\njsonrpc: state_subscribeRuntimeVersion\njsonrpc: state_subscribeRuntimeVersion\nsummary: Retrieves the runtime version via subscription.\nsummary: Retrieves the runtime version via subscription.\nsubscribeStorage(keys?: Vec<StorageKey>): StorageChangeSet\ninterface: api.rpc.state.subscribeStorage\ninterface: api.rpc.state.subscribeStorage\njsonrpc: state_subscribeStorage\njsonrpc: state_subscribeStorage\nsummary: Subscribes to storage changes for the provided keys.\nsummary: Subscribes to storage changes for the provided keys.\ntraceBlock(block: Hash, targets: Option<Text>, storageKeys: Option<Text>, methods: Option<Text>): TraceBlockResponse\ninterface: api.rpc.state.traceBlock\ninterface: api.rpc.state.traceBlock\njsonrpc: state_traceBlock\njsonrpc: state_traceBlock\nsummary: Provides a way to trace the re-execution of a single block.\nsummary: Provides a way to trace the re-execution of a single block.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/state"
  },
  {
    "title": "system",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nsystem\naccountNextIndex(accountId: AccountId): Index\ninterface: api.rpc.system.accountNextIndex\ninterface: api.rpc.system.accountNextIndex\njsonrpc: system_accountNextIndex\njsonrpc: system_accountNextIndex\nsummary: Retrieves the next accountIndex as available on the node.\nsummary: Retrieves the next accountIndex as available on the node.\naddLogFilter(directives: Text): Null\ninterface: api.rpc.system.addLogFilter\ninterface: api.rpc.system.addLogFilter\njsonrpc: system_addLogFilter\njsonrpc: system_addLogFilter\nsummary: Adds the supplied directives to the current log filter.\nsummary: Adds the supplied directives to the current log filter.\naddReservedPeer(peer: Text): Text\ninterface: api.rpc.system.addReservedPeer\ninterface: api.rpc.system.addReservedPeer\njsonrpc: system_addReservedPeer\njsonrpc: system_addReservedPeer\nsummary: Adds a reserved peer.\nsummary: Adds a reserved peer.\nchain(): Text\ninterface: api.rpc.system.chain\ninterface: api.rpc.system.chain\njsonrpc: system_chain\njsonrpc: system_chain\nsummary: Retrieves the chain.\nsummary: Retrieves the chain.\nchainType(): ChainType\ninterface: api.rpc.system.chainType\ninterface: api.rpc.system.chainType\njsonrpc: system_chainType\njsonrpc: system_chainType\nsummary: Retrieves the chain type.\nsummary: Retrieves the chain type.\ndryRun(extrinsic: Bytes, at?: BlockHash): ApplyExtrinsicResult\ninterface: api.rpc.system.dryRun\ninterface: api.rpc.system.dryRun\njsonrpc: system_dryRun (alias=system_dryRunAt)\njsonrpc: system_dryRun (alias=system_dryRunAt)\nsummary: Dry runs an extrinsic at a given block.\nsummary: Dry runs an extrinsic at a given block.\nhealth(): Health\ninterface: api.rpc.system.health\ninterface: api.rpc.system.health\njsonrpc: system_health\njsonrpc: system_health\nsummary: Returns the health status of the node.\nsummary: Returns the health status of the node.\nlocalListenAddresses(): Vec<Text>\ninterface: api.rpc.system.localListenAddresses\ninterface: api.rpc.system.localListenAddresses\njsonrpc: system_localListenAddresses\njsonrpc: system_localListenAddresses\nsummary: The addresses include a trailing /p2p/ with the local PeerId, and are thus suitable to be passed to addReservedPeer or as a bootnode address for example.\nsummary: The addresses include a trailing /p2p/ with the local PeerId, and are thus suitable to be passed to addReservedPeer or as a bootnode address for example.\nlocalPeerId(): Text\ninterface: api.rpc.system.localPeerId\ninterface: api.rpc.system.localPeerId\njsonrpc: system_localPeerId\njsonrpc: system_localPeerId\nsummary: Returns the base58-encoded PeerId of the node.\nsummary: Returns the base58-encoded PeerId of the node.\nname(): Text\ninterface: api.rpc.system.name\ninterface: api.rpc.system.name\njsonrpc: system_name\njsonrpc: system_name\nsummary: Retrieves the node name.\nsummary: Retrieves the node name.\nnodeRoles(): Vec<NodeRole>\ninterface: api.rpc.system.nodeRoles\ninterface: api.rpc.system.nodeRoles\njsonrpc: system_nodeRoles\njsonrpc: system_nodeRoles\nsummary: Returns the roles the node is running as.\nsummary: Returns the roles the node is running as.\npeers(): Vec<PeerInfo>\ninterface: api.rpc.system.peers\ninterface: api.rpc.system.peers\njsonrpc: system_peers\njsonrpc: system_peers\nsummary: Returns the currently connected peers.\nsummary: Returns the currently connected peers.\nproperties(): ChainProperties\ninterface: api.rpc.system.properties\ninterface: api.rpc.system.properties\njsonrpc: system_properties\njsonrpc: system_properties\nsummary: Gets a custom set of properties as a JSON object, defined in the chain specification.\nsummary: Gets a custom set of properties as a JSON object, defined in the chain specification.\nremoveReservedPeer(peerId: Text): Text\ninterface: api.rpc.system.removeReservedPeer\ninterface: api.rpc.system.removeReservedPeer\njsonrpc: system_removeReservedPeer\njsonrpc: system_removeReservedPeer\nsummary: Removes a reserved peer.\nsummary: Removes a reserved peer.\nreservedPeers(): Vec<Text>\ninterface: api.rpc.system.reservedPeers\ninterface: api.rpc.system.reservedPeers\njsonrpc: system_reservedPeers\njsonrpc: system_reservedPeers\nsummary: Returns the list of reserved peers.\nsummary: Returns the list of reserved peers.\nresetLogFilter(): Null\ninterface: api.rpc.system.resetLogFilter\ninterface: api.rpc.system.resetLogFilter\njsonrpc: system_resetLogFilter\njsonrpc: system_resetLogFilter\nsummary: Resets the log filter to Substrate defaults.\nsummary: Resets the log filter to Substrate defaults.\nsyncState(): SyncState\ninterface: api.rpc.system.syncState\ninterface: api.rpc.system.syncState\njsonrpc: system_syncState\njsonrpc: system_syncState\nsummary: Returns the state of the syncing of the node.\nsummary: Returns the state of the syncing of the node.\nversion(): Text\ninterface: api.rpc.system.version\ninterface: api.rpc.system.version\njsonrpc: system_version\njsonrpc: system_version\nsummary: Retrieves the version of the node.\nsummary: Retrieves the version of the node.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/system"
  },
  {
    "title": "trace",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\ntrace\nfilter(filter: FilterRequest): Vec<TransactionTrace>\ninterface: api.rpc.trace.filter\ninterface: api.rpc.trace.filter\njsonrpc: trace_filter\njsonrpc: trace_filter\nsummary: It allows you to get the traces of multiple transactions in a single request based on the filters you provide.\nsummary: It allows you to get the traces of multiple transactions in a single request based on the filters you provide.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/trace"
  },
  {
    "title": "txpool",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\ntxpool\ncontent(): TxPoolResult<PoolTransactionMap<PoolTransaction>>\ninterface: api.rpc.txpool.content\ninterface: api.rpc.txpool.content\njsonrpc: txpool_content\njsonrpc: txpool_content\nsummary: Lists the exact details of all the transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\nsummary: Lists the exact details of all the transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\ninspect(): TxPoolResult<PoolTransactionMap<PoolSummary>>\ninterface: api.rpc.txpool.inspect\ninterface: api.rpc.txpool.inspect\njsonrpc: txpool_inspect\njsonrpc: txpool_inspect\nsummary: Lists a textual summary of all the transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\nsummary: Lists a textual summary of all the transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\nstatus(): TxPoolResult<U256>\ninterface: api.rpc.txpool.status\ninterface: api.rpc.txpool.status\njsonrpc: txpool_status\njsonrpc: txpool_status\nsummary: Lists the number of transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\nsummary: Lists the number of transactions currently pending for inclusion in the next block(s), as well as the ones that are being scheduled for future execution only.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/txpool"
  },
  {
    "title": "web3",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nJSON-RPC API\nweb3\nclientVersion(): String\ninterface: api.rpc.web3.clientVersion\ninterface: api.rpc.web3.clientVersion\njsonrpc: web3_clientVersion\njsonrpc: web3_clientVersion\nsummary: Returns current client version.\nsummary: Returns current client version.\nsha3(): H256\ninterface: api.rpc.web3.sha3\ninterface: api.rpc.web3.sha3\njsonrpc: web3_sha3\njsonrpc: web3_sha3\nsummary: Returns sha3 of the given data.\nsummary: Returns sha3 of the given data.\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/json-rpc-api/web3"
  },
  {
    "title": "Explorer API",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nExplorer API\nThe Bifrost Network Explorer\nThe Bifrost Explorer provides a web page and a wide range of APIs for DApp developers for convenience.\nMainnet\nhttps://explorer.mainnet.thebifrost.io\nTestnet\nhttps://explorer.testnet.thebifrost.io\nYou can find all API specifications on the Explorer API Documentation page.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/explorer-api"
  },
  {
    "title": "Runtime API",
    "content": "DEVELOPER DOCUMENTATIONS\nCLIENT API\nRuntime API\nExternal node components handle most of the logic such as peer discovery, transaction pooling, block and transaction propagations, consensus mechanisms, and RPC requests. In some cases, external components require some data that is provided by the Runtime. Thus, the Runtime API allows the Runtime and external components to communicate easily with each other.\nThe API definitions below are the Runtime APIs supported on the Bifrost Network.\nAccountNonceApi\naccountNonce(accountId: AccountId): Index\ninterface: api.call.accountNonceApi.accountNonce\ninterface: api.call.accountNonceApi.accountNonce\nruntime: AccountNonceApi_account_nonce\nruntime: AccountNonceApi_account_nonce\nsummary: The API to query account nonce (aka transaction index).\nsummary: The API to query account nonce (aka transaction index).\nAuraApi\nauthorities(): Vec<AuthorityId>\ninterface: api.call.auraApi.authorities\ninterface: api.call.auraApi.authorities\nruntime: AuraApi_authorities\nruntime: AuraApi_authorities\nsummary: Returns the current set of authorities.\nsummary: Returns the current set of authorities.\nslotDuration(): SlotDuration\ninterface: api.call.auraApi.slotDuration\ninterface: api.call.auraApi.slotDuration\nruntime: AuraApi_slot_duration\nruntime: AuraApi_slot_duration\nsummary: Returns the slot duration for Aura.\nsummary: Returns the slot duration for Aura.\nBlockBuilder\napplyExtrinsic(extrinsic: Extrinsic): ApplyExtrinsicResult\ninterface: api.call.blockBuilder.applyExtrinsic\ninterface: api.call.blockBuilder.applyExtrinsic\nruntime: BlockBuilder_apply_extrinsic\nruntime: BlockBuilder_apply_extrinsic\nsummary: Applies the given extrinsic.\nsummary: Applies the given extrinsic.\ncheckInherents(block: Block, data: InherentData): CheckInherentsResult\ninterface: api.call.blockBuilder.checkInherents\ninterface: api.call.blockBuilder.checkInherents\nruntime: BlockBuilder_check_inherents\nruntime: BlockBuilder_check_inherents\nsummary: Checks that the inherents are valid.\nsummary: Checks that the inherents are valid.\nfinalizeBlock(): Header\ninterface: api.call.blockBuilder.finalizeBlock\ninterface: api.call.blockBuilder.finalizeBlock\nruntime: BlockBuilder_finalize_block\nruntime: BlockBuilder_finalize_block\nsummary: Finishes the current block.\nsummary: Finishes the current block.\ninherentExtrinsics(inherent: InherentData): Vec<Extrinsic>\ninterface: api.call.blockBuilder.inherentExtrinsics\ninterface: api.call.blockBuilder.inherentExtrinsics\nruntime: BlockBuilder_inherent_extrinsics\nruntime: BlockBuilder_inherent_extrinsics\nsummary: Generates inherent extrinsics.\nsummary: Generates inherent extrinsics.\nConvertTransactionRuntimeApi\nconvertTransaction(transaction: TransactionV2): Extrinsic\ninterface: api.call.convertTransactionRuntimeApi.convertTransaction\ninterface: api.call.convertTransactionRuntimeApi.convertTransaction\nruntime: ConvertTransactionRuntimeApi_convert_transaction\nruntime: ConvertTransactionRuntimeApi_convert_transaction\nsummary: Converts an Ethereum-style transaction to Extrinsic\nsummary: Converts an Ethereum-style transaction to Extrinsic\nCore\nexecuteBlock(block: Block): Null\ninterface: api.call.core.executeBlock\ninterface: api.call.core.executeBlock\nruntime: Core_execute_block\nruntime: Core_execute_block\nsummary: Executes the given block.\nsummary: Executes the given block.\ninitializeBlock(header: Header): Null\ninterface: api.call.core.initializeBlock\ninterface: api.call.core.initializeBlock\nruntime: Core_initialize_block\nruntime: Core_initialize_block\nsummary: Initializes a block with the given header.\nsummary: Initializes a block with the given header.\nversion(): RuntimeVersion\ninterface: api.call.core.version\ninterface: api.call.core.version\nruntime: Core_version\nruntime: Core_version\nsummary: Returns the version of the runtime.\nsummary: Returns the version of the runtime.\nDebugRuntimeApi\ntraceBlock(extrinsics: Vec<Extrinsic>, knownTransactions: Vec<H256>): Result<(), DispatchError>\ninterface: api.call.debugRuntimeApi.traceBlock\ninterface: api.call.debugRuntimeApi.traceBlock\nruntime: DebugRuntimeApi_trace_block\nruntime: DebugRuntimeApi_trace_block\nsummary: Traces all block extrinsics.\nsummary: Traces all block extrinsics.\ntraceTransaction(extrinsics: Vec<Extrinsic>, transaction: EthTransaction): Result<(), DispatchError>\ninterface: api.call.debugRuntimeApi.traceTransaction\ninterface: api.call.debugRuntimeApi.traceTransaction\nruntime: DebugRuntimeApi_trace_transaction\nruntime: DebugRuntimeApi_trace_transaction\nsummary: Traces transaction extrinsics.\nsummary: Traces transaction extrinsics.\nEthereumRuntimeRPCApi\naccountBasic(address: H160): EvmAccount\ninterface: api.call.ethereumRuntimeRPCApi.accountBasic\ninterface: api.call.ethereumRuntimeRPCApi.accountBasic\nruntime: EthereumRuntimeRPCApi_account_basic\nruntime: EthereumRuntimeRPCApi_account_basic\nsummary: Returns pallet_evm::Accounts basic information by address.\nsummary: Returns pallet_evm::Accounts basic information by address.\naccountCodeAt(address: H160): Bytes\ninterface: api.call.ethereumRuntimeRPCApi.accountCodeAt\ninterface: api.call.ethereumRuntimeRPCApi.accountCodeAt\nruntime: EthereumRuntimeRPCApi_account_code_at\nruntime: EthereumRuntimeRPCApi_account_code_at\nsummary: Returns pallet_evm::AccountCodes for a given account address.\nsummary: Returns pallet_evm::AccountCodes for a given account address.\nauthor(): H160\ninterface: api.call.ethereumRuntimeRPCApi.author\ninterface: api.call.ethereumRuntimeRPCApi.author\nruntime: EthereumRuntimeRPCApi_author\nruntime: EthereumRuntimeRPCApi_author\nsummary: Returns the converted FindAuthor::find_author authority id.\nsummary: Returns the converted FindAuthor::find_author authority id.\ncall(from: H160, to: H160, data: Vec<u8>, value: U256, gasLimit: U256, maxFeePerGas: Option<U256>, maxPriorityFeePerGas: Option<U256>, nonce: Option<U256>, estimate: bool, accessList: Option<Vec<(H160, Vec<H256>)>>): Result<EvmCallInfo, DispatchError>\ninterface: api.call.ethereumRuntimeRPCApi.call\ninterface: api.call.ethereumRuntimeRPCApi.call\nruntime: EthereumRuntimeRPCApi_call\nruntime: EthereumRuntimeRPCApi_call\nsummary: Returns a pallet_ethereum::call response.\nsummary: Returns a pallet_ethereum::call response.\nchainId(): u64\ninterface: api.call.ethereumRuntimeRPCApi.chainId\ninterface: api.call.ethereumRuntimeRPCApi.chainId\nruntime: EthereumRuntimeRPCApi_chain_id\nruntime: EthereumRuntimeRPCApi_chain_id\nsummary: Returns runtime defined pallet_evm::ChainId.\nsummary: Returns runtime defined pallet_evm::ChainId.\ncreate(from: H160, data: Vec<u8>, value: U256, gasLimit: U256, maxFeePerGas: Option<U256>, maxPriorityFeePerGas: Option<U256>, nonce: Option<U256>, estimate: bool, accessList: Option<Vec<(H160, Vec<H256>)>>): Result<EvmCreateInfo, DispatchError>\ninterface: api.call.ethereumRuntimeRPCApi.create\ninterface: api.call.ethereumRuntimeRPCApi.create\nruntime: EthereumRuntimeRPCApi_create\nruntime: EthereumRuntimeRPCApi_create\nsummary: Returns a pallet_ethereum::call response.\nsummary: Returns a pallet_ethereum::call response.\ncurrentAll(): (Option<BlockV2>, Option<Vec<EthReceiptV3>>, Option<Vec<EthTransactionStatus>>)\ninterface: api.call.ethereumRuntimeRPCApi.currentAll\ninterface: api.call.ethereumRuntimeRPCApi.currentAll\nruntime: EthereumRuntimeRPCApi_current_all\nruntime: EthereumRuntimeRPCApi_current_all\nsummary: Returns all the current data for a block in a single runtime call.\nsummary: Returns all the current data for a block in a single runtime call.\ncurrentBlock(): BlockV2\ninterface: api.call.ethereumRuntimeRPCApi.currentBlock\ninterface: api.call.ethereumRuntimeRPCApi.currentBlock\nruntime: EthereumRuntimeRPCApi_current_block\nruntime: EthereumRuntimeRPCApi_current_block\nsummary: Returns the current block.\nsummary: Returns the current block.\ncurrentReceipts(): Option<Vec<EthReceiptV3>>\ninterface: api.call.ethereumRuntimeRPCApi.currentReceipts\ninterface: api.call.ethereumRuntimeRPCApi.currentReceipts\nruntime: EthereumRuntimeRPCApi_current_receipts\nruntime: EthereumRuntimeRPCApi_current_receipts\nsummary: Returns the current receipt.\nsummary: Returns the current receipt.\ncurrentTransactionStatuses(): Option<Vec<EthTransactionStatus>>\ninterface: api.call.ethereumRuntimeRPCApi.currentTransactionStatuses\ninterface: api.call.ethereumRuntimeRPCApi.currentTransactionStatuses\nruntime: EthereumRuntimeRPCApi_current_transaction_statuses\nruntime: EthereumRuntimeRPCApi_current_transaction_statuses\nsummary: Returns the current transaction status.\nsummary: Returns the current transaction status.\nelasticity(): Option<Permill>\ninterface: api.call.ethereumRuntimeRPCApi.elasticity\ninterface: api.call.ethereumRuntimeRPCApi.elasticity\nruntime: EthereumRuntimeRPCApi_elasticity\nruntime: EthereumRuntimeRPCApi_elasticity\nsummary: Returns the elasticity multiplier.\nsummary: Returns the elasticity multiplier.\nextrinsicFilter(xts: Vec<Extrinsic>): Vec<TransactionV2>\ninterface: api.call.ethereumRuntimeRPCApi.extrinsicFilter\ninterface: api.call.ethereumRuntimeRPCApi.extrinsicFilter\nruntime: EthereumRuntimeRPCApi_extrinsic_filter\nruntime: EthereumRuntimeRPCApi_extrinsic_filter\nsummary: Receives a Vec<OpaqueExtrinsic> and filters all the ethereum transactions.\nsummary: Receives a Vec<OpaqueExtrinsic> and filters all the ethereum transactions.\ngasPrice(): u256\ninterface: api.call.ethereumRuntimeRPCApi.gasPrice\ninterface: api.call.ethereumRuntimeRPCApi.gasPrice\nruntime: EthereumRuntimeRPCApi_gas_price\nruntime: EthereumRuntimeRPCApi_gas_price\nsummary: Returns FixedGasPrice::min_gas_price\nsummary: Returns FixedGasPrice::min_gas_price\nstorageAt(address: H160, index: u256): H256\ninterface: api.call.ethereumRuntimeRPCApi.storageAt\ninterface: api.call.ethereumRuntimeRPCApi.storageAt\nruntime: EthereumRuntimeRPCApi_storage_at\nruntime: EthereumRuntimeRPCApi_storage_at\nsummary: Returns pallet_evm::AccountStorages for a given account address and index. \nsummary: Returns pallet_evm::AccountStorages for a given account address and index. \nGrandpaApi\ncurrentSetId(): SetId\ninterface: api.call.grandpaApi.currentSetId\ninterface: api.call.grandpaApi.currentSetId\nruntime: GrandpaApi_current_set_id\nruntime: GrandpaApi_current_set_id\nsummary: Gets current GRANDPA authority set id.\nsummary: Gets current GRANDPA authority set id.\ngenerateKeyOwnershipProof(setId: SetId, authorityId: AuthorityId): Option<OpaqueKeyOwnershipProof>\ninterface: api.call.grandpaApi.generateKeyOwnershipProof\ninterface: api.call.grandpaApi.generateKeyOwnershipProof\nruntime: GrandpaApi_generate_key_ownership_proof\nruntime: GrandpaApi_generate_key_ownership_proof\nsummary: Generates a proof of key ownership for the given authority in the given set.\nsummary: Generates a proof of key ownership for the given authority in the given set.\ngrandpaAuthorities(): AuthorityList\ninterface: api.call.grandpaApi.grandpaAuthorities\ninterface: api.call.grandpaApi.grandpaAuthorities\nruntime: GrandpaApi_grandpa_authorities\nruntime: GrandpaApi_grandpa_authorities\nsummary: Gets the current GRANDPA authorities and weights. This should not change except when changes are scheduled and the corresponding delay has passed.\nsummary: Gets the current GRANDPA authorities and weights. This should not change except when changes are scheduled and the corresponding delay has passed.\nsubmitReportEquivocationUnsignedExtrinsic(equivocationProof: GrandpaEquivocationProof, keyOwnerProof: OpaqueKeyOwnershipProof): Option<Null>\ninterface: api.call.grandpaApi.submitReportEquivocationUnsignedExtrinsic\ninterface: api.call.grandpaApi.submitReportEquivocationUnsignedExtrinsic\nruntime: GrandpaApi_submit_report_equivocation_unsigned_extrinsic\nruntime: GrandpaApi_submit_report_equivocation_unsigned_extrinsic\nsummary: Submits an unsigned extrinsic to report an equivocation.\nsummary: Submits an unsigned extrinsic to report an equivocation.\nMetadata\nmetadata(): OpaqueMetadata\ninterface: api.call.metadata.metadata\ninterface: api.call.metadata.metadata\nruntime: Metadata_metadata\nruntime: Metadata_metadata\nsummary: Returns the metadata of a runtime.\nsummary: Returns the metadata of a runtime.\nOffchainWorkerApi\noffchainWorker(header: Header): Null\ninterface: api.call.offchainWorkerApi.offchainWorker\ninterface: api.call.offchainWorkerApi.offchainWorker\nruntime: OffchainWorkerApi_offchain_worker\nruntime: OffchainWorkerApi_offchain_worker\nsummary: Starts the off-chain task for the given block header.\nsummary: Starts the off-chain task for the given block header.\nSessionKeys\ndecodeSessionKeys(encoded: Bytes): Option<Vec<(Bytes, KeyTypeId)>>\ninterface: api.call.sessionKeys.decodeSessionKeys\ninterface: api.call.sessionKeys.decodeSessionKeys\nruntime: SessionKeys_decode_session_keys\nruntime: SessionKeys_decode_session_keys\nsummary: Decodes the given public session keys.\nsummary: Decodes the given public session keys.\ngenerateSessionKeys(seed: Option<Bytes>): Bytes\ninterface: api.call.sessionKeys.generateSessionKeys\ninterface: api.call.sessionKeys.generateSessionKeys\nruntime: SessionKeys_generate_session_keys\nruntime: SessionKeys_generate_session_keys\nsummary: Generates a set of session keys with optionally using the given seed.\nsummary: Generates a set of session keys with optionally using the given seed.\nTaggedTransactionQueue\nvalidateTransaction(source: TransactionSource, tx: Extrinsic, blockHash: BlockHash): TransactionValidity\ninterface: api.call.taggedTransactionQueue.validateTransaction\ninterface: api.call.taggedTransactionQueue.validateTransaction\nruntime: TaggedTransactionQueue_validate_transaction\nruntime: TaggedTransactionQueue_validate_transaction\nsummary: Validates the transaction.\nsummary: Validates the transaction.\nTransactionPaymentApi\nqueryFeeDetails(uxt: Extrinsic, len: u32): FeeDetails\ninterface: api.call.transactionPaymentApi.queryFeeDetails\ninterface: api.call.transactionPaymentApi.queryFeeDetails\nruntime: TransactionPaymentApi_query_fee_details\nruntime: TransactionPaymentApi_query_fee_details\nsummary: The transaction fee details.\nsummary: The transaction fee details.\nqueryInfo(uxt: Extrinsic, len: u32): RuntimeDispatchInfo\ninterface: api.call.transactionPaymentApi.queryInfo\ninterface: api.call.transactionPaymentApi.queryInfo\nruntime: TransactionPaymentApi_query_info\nruntime: TransactionPaymentApi_query_info\nsummary: The transaction info.\nsummary: The transaction info.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/client-api/runtime-api"
  },
  {
    "title": "Cross-Chain Transaction and Oracle API",
    "content": "DEVELOPER DOCUMENTATIONS\nCross-Chain Transaction and Oracle API\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/cross-chain-transaction-and-oracle-api"
  },
  {
    "title": "Price Oracle Contract API",
    "content": "DEVELOPER DOCUMENTATIONS\nCROSS-CHAIN TRANSACTION AND ORACLE API\nPrice Oracle Contract API\nDescription\nOne of the key advantages of the Bifrost Network is its native price oracle, which offers a wide range of digital asset prices sourced from centralized exchanges (CEXs) and decentralized exchanges (DEXs) on other networks. We have made the price oracle for CCCP-supported assets publicly available to all developers on the Bifrost Network. We hope many DApp developers will enjoy these benefits through our network.\nTo minimize the learning curve, our oracle service includes an abstraction layer that provides an interface compatible with Chainlink's. This design choice not only reduces the time needed for developers to adapt but also enables seamless integration for those already familiar with Chainlink's environment. \nIn the following sections, we will explain how to utilize Bifrost's price oracle.\nPrice Feed Methods\ndecimals()\nReturns USD price decimals for a specific asset (e.g., the USD price of ETH).\nReturn values\nuint8\nThe decimals (now only USD support)  for a specific asset\ndescription()\nReturn the type of a specific oracle feeder (e.g., ETH/USD)\nReturn values\nstring\nThe type of a specific oracle feeder \nversion()\nReturn the version of a specific oracle feed contract.\nReturn values\nuint256\nThe version of a specific oracle feed contract. \ngetRoundData(_roundId)\nReturn the price information from the previous round along with the timestamp of that update.\nParameters\n_roundId\nuint8\nThe round ID of desired price information. \nReturn values\nroundId\nuint80\nThe round ID.\nanswer\nint256\nThe price information for this round.\nstartedAt\nuint256\nThe timestamp of when the round started.\nupdatedAt\nuint256\nThe timestamp of when the round was updated.\nansweredInRound\nuint80\nThe answers could take multiple rounds to be computed.\nlatestRoundData()\nReturn the latest price information along with the timestamp of the most recent update.\nReturn values\nroundId\nuint80\nThe round ID.\nanswer\nint256\nThe price information for this round.\nstartedAt\nuint256\nThe timestamp of when the round started.\nupdatedAt\nuint256\nThe timestamp of when the round was updated.\nansweredInRound\nuint80\nThe answers could take multiple rounds to be computed.\nPrice Feed Contract Interface\nPrice Feed Contract Address\nETH/USD\nmainnet: 0x0427d2908E45FAfD65F56a6A6E2095461e70A3d6\ntestnet: 0x786cA38641bD2eE6f4c9397056F9CF9d9C893eEA\nUSDC/USD\nmainnet: 0x2FFc2e7C4c280eb82A13972cCA30719F9365746F\ntestnet: 0x9Fa06A8f3454b902b4ecdaBB6eBC8F56CC536609\nBNB/USD\nmainnet: 0x1Eda422B45b279c8C280B510cbf4BDFB671985c0\ntestnet: 0x590A94102B03b10d4aDF8bfc83aCC556dc9745E5\nMATIC/USD\nmainnet: 0x59C75485126Ac9a90609E7Fe5D6c513396ED503d\ntestnet: 0x534Fa69E2616444B5DFB940f3a893D8183fEDcD7\nBIFI/USD\nmainnet: 0xc97D3b8d03ec813b760C8A471F3c8393e4F91506\ntestnet: 0x42acD3003fA8b870999573071427C64A90146991\nBFC/USD\nmainnet: 0x77397a130c169702Ff007682630eCAa5caB23791\ntestnet: 0xEF746B668880f83F06245245017B31523e485Df8\nUSDT/USD\nmainnet: 0xd8653315Dc63128AA8428C6Ae12E50b5E77156AC\ntestnet: 0xfdcC92216E7236E6f0A2033B1d63D3505369945b\nDAI/USD\nmainnet: 0xF2385A5DDa77fF9731F661aA44f6b4398A97A1cd\ntestnet: 0x4842D3a8c29fABfB971AeD8675262c16b71ef2Dd\nWBTC/USD\nmainnet: 0xc1596ece7e801125D507f0815e7070Aa97D3645e\ntestnet: 0x1aF3595Ba40EAb3481f19245E5a0F09018e85Aa4\nBTCB/USD\nmainnet: 0x40c8BB8036351EF29b41ea8AFEbA76ac2d8A96bF\ntestnet: 0x0B2C85312E35829e714Fef01efAD6d2718e3c227\nExample: ETH/USD price oracle (testnet)\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/cross-chain-transaction-and-oracle-api/price-oracle-contract-api"
  },
  {
    "title": "Socket Contract API",
    "content": "DEVELOPER DOCUMENTATIONS\nCROSS-CHAIN TRANSACTION AND ORACLE API\nSocket Contract API\nThe vault contract is an entry point for a user request. When a user requests Bridge or BridgeAndCall with their cryptocurrency, the vault contract securely locks it until the opposite-directional bridge request occurs.\nThe socket contract receives and verifies event messages from users or relayers. If the requested message is determined as valid, the socket contract executes request-indicated actions (e.g. mint, lending, leveraged investment) and checks whether or not these actions are executed correctly.\nInterfaces of Vault contract\nInterfaces of Socket contract\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/cross-chain-transaction-and-oracle-api/socket-contract-api"
  },
  {
    "title": "Testnet Faucet",
    "content": "DEVELOPER DOCUMENTATIONS\nTestnet Faucet\nThis page introduces how to claim BFC in order to test functions or carry out missions on the Bifrost Testnet. Through the faucet, you can claim BFC on the testnet which has no value.\nJoining Discord\nThe Bifrost Testnet Faucet will be operated by a Discord bot. Please visit our Bifrost CITY server.\nCommands\nOn the faucet, three types of commands are supported. Enter a command in the faucet channel of the Bifrost CITY server, and the command will be executed.\nPlease read below to learn how each command works.\n/faucet_help\nCommand /faucet_help shows the list of commands and explanations for each command.\n/faucet [address]\nWith command /faucet [address], you can receive testnet BFC in the entered address. BFC can be used when testing internal services of the Bifrost Testnet, or cross-chain actions (Bifrost Testnet → External networks)\nOnce a request is sent, the bot starts to transfer BFC to the entered address. If the process is successfully done, you will be notified and given the Bifrost explorer link. You can use command /faucet [address] every 24 hours per Discord account.\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/developer-documentations/testnet-faucet"
  },
  {
    "title": "Governance",
    "content": "Governance\nThis page outlines the governance mechanism of the Bifrost Network during the Incentivized Testnet.\nIntroduction \nBifrost aims to reflect the voice of the community and enhance the protocol through governance. Based on our shared vision, the Bifrost governance mechanism encompasses all token holders. All types of governance must go through the decisions of holders who can vote or create proposals. In addition, our governance forum allows everyone, even those without tokens, to freely discuss and share ideas about the protocol.\nGlossary\nReferendum: The proposal with the highest amount of support from each launch period is selected to be a referendum. During the voting period, BFC holders can submit “aye” or “nay” votes by depositing their shares, and approval is determined by the total voting weight at the end of the voting period. \nReferendum: The proposal with the highest amount of support from each launch period is selected to be a referendum. During the voting period, BFC holders can submit “aye” or “nay” votes by depositing their shares, and approval is determined by the total voting weight at the end of the voting period. \nLaunch period: A period of time with blocks of a certain length. At the end of the launch period, the proposal with the most endorsement is selected for a referendum. \nLaunch period: A period of time with blocks of a certain length. At the end of the launch period, the proposal with the most endorsement is selected for a referendum. \nVoting period: A period of time during which voters may vote on a referendum. At the end of the voting period, votes are aggregated to determine whether or not a referendum is approved. \nVoting period: A period of time during which voters may vote on a referendum. At the end of the voting period, votes are aggregated to determine whether or not a referendum is approved. \nEnactment period: A period of time it takes for a referendum to be reflected in the network. From a technical perspective, a referendum is placed In Queue, waits for a certain amount of time specified by the enactment period, and is finally applied by pallet_scheduler. \nEnactment period: A period of time it takes for a referendum to be reflected in the network. From a technical perspective, a referendum is placed In Queue, waits for a certain amount of time specified by the enactment period, and is finally applied by pallet_scheduler. \nLock period: A period of time starting from the end of the enactment period of a referendum during which the voters’ shares are locked. \nLock period: A period of time starting from the end of the enactment period of a referendum during which the voters’ shares are locked. \nDelegation: As it may be difficult for BFC holders to participate in every voting, delegation exists as an option to yield one’s voting rights by using their stakes as collateral and increasing the voting weight of a certain trusted voter. In such a case, when the delegated voter casts their vote, it is submitted with an additional delegated weight. As with normal voting, a conviction can be applied to delegation to increase the vote weight by increasing the lock period. However, delegators cannot vote unless they remove their delegation.\nDelegation: As it may be difficult for BFC holders to participate in every voting, delegation exists as an option to yield one’s voting rights by using their stakes as collateral and increasing the voting weight of a certain trusted voter. In such a case, when the delegated voter casts their vote, it is submitted with an additional delegated weight. As with normal voting, a conviction can be applied to delegation to increase the vote weight by increasing the lock period. However, delegators cannot vote unless they remove their delegation.\nMechanics\nThe idea behind governance is to allow holders to make changes to the Bifrost Network through voting. Every proposal has to go through a referendum.\nMembers of the General Council are expected to have a deep understanding of the Bifrost Network and be aligned with its long-term goals. Initially, General Council will be appointed by the Bifrost Foundation, and over time will move towards the election-based system in which BFC holders will be voting members in and out.\nProposal\nCreating a proposal\nIn order to submit proposals, participants must first create a proposal. During the process, participants suggest changes to the pallet (smart contract) and the extrinsic (function). Once participants make all the changes, they have to save the generated hash. \nThe saved hash is used to submit a proposal. When submitting a proposal, holders can set the minimum amount of BFC to endorse the proposal. Keep in mind that the minimum amount of BFC will be locked until the proposal is selected as a referendum and undergoes voting. This is a measure to prevent voters from selling their votes after endorsement. The required number of coins may vary depending on the type of the proposal or the minimum number set by the proposal creator. \nIf a proposal fails to become a referendum, it has to go through another launch period. The process is repeated until the proposal is selected as a referendum. At the end of every launch period, the proposal with the most endorsement will be selected for a referendum.\nEndorsing a proposal\nVoters can endorse a proposal by clicking the “Endorse” button. The endorsement may fail if a voter does not have enough coins in their address or does not own enough coins set by the proposal creator.\nReferenda\nGiven that at least one proposal is endorsed by the majority by the end of a launch period, a new referendum is held after every voting period. During the voting period, holders may vote either “aye” or “nay”. If a referendum passes, it goes through the enactment period and is queued for dispatch. \nThe number of coins determines the voting power in the referendum and holders can vote on behalf of other voters through delegation. When voting on the referendum either with “aye” or “nay”, voters can use the “Increase voting power” button to increase their conviction. \nVoters can increase their voting power by increasing their lock period. With this feature, voters can increase their voting power by up to six times. The increased lock period will be succeeded by the voting period. For example, if a voter decides to increase their voting power by two, their lock period following the voting period will be doubled.\n0.1 (no lock period)\n0.1\n1 (no lock period)\n1\n2\n28\n3\n56\n4\n112\n5\n224\n6\n448\nBalance\nTo unlock coins used for endorsement and voting which are immediately locked, users need to access the “Profile” page. On the “Profile” page, users can check their balance as well as their governance participation history. \nTo unlock their votes, voters need to click the “Unlock” button under Delegation Status. By clicking this button, voters request the remove_vote function to the Bifrost governance system. After the lock period, voters can claim their coins used for voting. Even if remove_vote is not requested, unlock will begin automatically after the end of the referendum voting period. However, if remove_vote is not requested, the balance will not be transferred to claimable BFC.\nVoting System\nIn order to alleviate the problem of poor turnout, the Bifrost governance mechanism adopts the Polkadot-based Adaptive Quorum Biasing (AQB) protocol instead of the existing quorum-based voting system. This is because the latter requires the participation of a certain number of voters and manifests a number of problems including the following: \nLow participation rates due to strict and fixed quorum settings. \nLow participation rates due to strict and fixed quorum settings. \nDifficulty in setting a specific quorum that is both appropriate and agreeable to all participants.\nDifficulty in setting a specific quorum that is both appropriate and agreeable to all participants.\nConversely, the following are key characteristics of a voting system that is not quorum based: \nParticipants are rewarded. \nParticipants are rewarded. \nHowever, nonparticipants are penalized. \nHowever, nonparticipants are penalized. \nHowever, this system can lead to malicious actions and disproportionate turnout.\nVoting Mechanics \nTerminology\nApprove: number of aye votes (conviction included) \nApprove: number of aye votes (conviction included) \nAgainst: number of nay votes (conviction included) \nAgainst: number of nay votes (conviction included) \nTurnout: total number of votes (conviction not included) \nTurnout: total number of votes (conviction not included) \nElectorate: total number of coins issued in the network \nThe total number of coins issued in the network refers to the number of BFC in the Bifrost Network.\nElectorate: total number of coins issued in the network \nThe total number of coins issued in the network refers to the number of BFC in the Bifrost Network.\nThe total number of coins issued in the network refers to the number of BFC in the Bifrost Network.\nPositive Turnout Bias (PTB) \n                                            turnout\nagainst\n<\nelectorate\napprove\n \nA referendum will be approved when the majority of voters vote “aye” and there is a low turnout. However, with a high turnout, there should be fewer “aye” votes. \nA referendum will be approved when the majority of voters vote “aye” and there is a low turnout. However, with a high turnout, there should be fewer “aye” votes. \nThe general public will vote on a PTB basis (Public Proposal). \nThe general public will vote on a PTB basis (Public Proposal). \nNegative Turnout Bias (NTB)\n                                             electorate\nagainst\n<\nturnout\napprove\nA referendum will be rejected when the majority of voters vote “nay” and there is a low turnout. However, with a high turnout, there should be fewer “nay” votes. \nA referendum will be rejected when the majority of voters vote “nay” and there is a low turnout. However, with a high turnout, there should be fewer “nay” votes. \nAll proposals submitted by the council members’ (External Proposal) are based on the NTB model.\nAll proposals submitted by the council members’ (External Proposal) are based on the NTB model.\nExample \napprove\n6000 (1000 * 6) = lock balance * conviction\nagainst\n10 (100 * 0.1) = lock balance * conviction\nturnout\n1100 (1000 + 100) = approve + against\nelectorate\n1M\nresult\n0.3 < 6 (aye wins)\n                                                 1100\n10\n<\n1000000\n6000\n                                                     33.166\n10\n<\n 1000\n6000\nGovernance Flow\nHolders have to create a “Proposal Hash”, a hash containing the changes. \nHolders have to create a “Proposal Hash”, a hash containing the changes. \nOnce the “Proposal Hash” is created, the hash creator can either choose to submit a proposal by themself or ask other holders to submit a proposal using the hash. The proposer must deposit or lock up a certain amount of coins into the governance to register a proposal. If the submission is successful, the proposal is publicly registered. \nOnce the “Proposal Hash” is created, the hash creator can either choose to submit a proposal by themself or ask other holders to submit a proposal using the hash. The proposer must deposit or lock up a certain amount of coins into the governance to register a proposal. If the submission is successful, the proposal is publicly registered. \nAt the end of every Launch Period, the proposal with the most endorsement will become a referendum and voters will vote either “aye” or “nay” during the voting period. \nAt the end of every Launch Period, the proposal with the most endorsement will become a referendum and voters will vote either “aye” or “nay” during the voting period. \nAt the end of the voting period, the Bifrost governance system will aggregate casted votes to determine whether a referendum or referenda will be approved. \nAt the end of the voting period, the Bifrost governance system will aggregate casted votes to determine whether a referendum or referenda will be approved. \nIf a referendum or referenda are approved, the Bifrost network will reflect the changes after the enactment period.\nIf a referendum or referenda are approved, the Bifrost network will reflect the changes after the enactment period.\nCouncil\nCouncil members are in charge of managing the Bifrost Governance. Their role is to cancel malicious referenda, select the technical committee and manage the treasury. \nIn case the council members are unable to participate in every activity, a prime member to represent them is separately selected. The council member who receives the highest number of votes during the council round is selected as a prime member. Members who do not cast votes on council proposals automatically follow the vote of the prime member\nTechnical Committee\nThe technical committee is a committee selected by the council members and is also responsible for managing the Bifrost Governance and preventing unilateral actions of council members. Members of the technical committee have the authority to cancel malicious proposals and proposals created by the council members and to fast-track proposals when necessary.\nMembers of the technical committee have veto powers to prevent any potential abuses by council members. If even one member exerts veto power, the proposal is nullified and enlisted on the blacklist for a certain period of time. This prevents the submission of relevant proposals. In addition, like council members, members of the technical committee cannot exercise certain authority indefinitely and must possess BFC tokens.\nTreasury\nThe treasury stores and burns BFC which have been slashed when proposals and referenda are canceled. They also store the slashed BFC of network node operators. The treasury is managed by the council members. The council members will do their best to carefully manage the treasury so as not to lose the trust of community members. Keep in mind that council members are also BFC holders who will not take any actions that negatively affect the Bifrost Network.\nFAQ\nI am not familiar with codes. Is there any way I can create proposals without coding knowledge?\n\nYou can create proposals without blockchain or coding knowledge. Select “bfcUtility” under “communityProposal”. Then, insert the URL that explains your proposal under proposal \"Bytes\". We encourage you to use the Bifrost Governance Forum URL.\nI am not familiar with codes. Is there any way I can create proposals without coding knowledge?\n\nYou can create proposals without blockchain or coding knowledge. Select “bfcUtility” under “communityProposal”. Then, insert the URL that explains your proposal under proposal \"Bytes\". We encourage you to use the Bifrost Governance Forum URL.\nHow can I submit a proposal on the behalf of other voters?\n\nOur governance mechanism allows one to submit proposals on the behalf of other voters or network participants. To submit a proposal on the behalf of other voters, you must know the “Preimage Hash” and all the changes on the “Pallet” and the “Extrinsic”. Click “Submit a Proposal” and insert “Preimage Hash” created by another holder and imply all the changes of the “Pallet” and the “Extrinsic”.\nHow can I submit a proposal on the behalf of other voters?\n\nOur governance mechanism allows one to submit proposals on the behalf of other voters or network participants. To submit a proposal on the behalf of other voters, you must know the “Preimage Hash” and all the changes on the “Pallet” and the “Extrinsic”. Click “Submit a Proposal” and insert “Preimage Hash” created by another holder and imply all the changes of the “Pallet” and the “Extrinsic”.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/governance"
  },
  {
    "title": "Security",
    "content": "Security\nTo ensure the security of all stakeholders of the network, Bifrost implements several lines of defense. Socket contracts and relayers play a major role.\nAll relayers must sign the message with their private key in every message handling. The Bifrost Network should accept messages of valid relayers by verifying the message signature.\nEvery socket contract verifies the signed message to check whether or not the message is from valid relayers.\nEvery socket contract verifies the signed message to check whether or not the message is from valid relayers.\nRelayers and socket contracts perform sanity checks for every Cross-Chain Communication (CCC) message at each stage.\nIf an Ethereum transaction related to the CCC job is not executed for a long time, the network identifies the transaction and then runs a corresponding action, such as transaction rollback.\nIf an Ethereum transaction related to the CCC job is not executed for a long time, the network identifies the transaction and then runs a corresponding action, such as transaction rollback.\nThe network is able to identify the message which falls under abnormal situations (e.g. transaction revert and transaction pending for a long time).\nThe network is able to identify the message which falls under abnormal situations (e.g. transaction revert and transaction pending for a long time).\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/security"
  },
  {
    "title": "Tokens & Assets",
    "content": "Tokens & Assets\nAbout Bifrost Network's tokens and assets. \nLast updated 9 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/tokens-and-assets"
  },
  {
    "title": "Unified Token",
    "content": "TOKENS & ASSETS\nUnified Token\nWhat is Unified token?\nOne of the standout features of the Bifrost Network is its commitment to a developer-friendly environment, epitomized by the implementation of the Unified Token (ERC-20 based). This innovative approach consolidates tokens from disparate chains, such as Ethereum’s DAI and BNB Chain’s DAI, under a single token contract. By doing so, it streamlines liquidity management for DApp developers by minimizing the complexities associated with fragmented bridge tokens. For instance, when DAI tokens from Ethereum and BNB Chain are transferred to the Bifrost Network, they are seamlessly integrated into a single Unified DAI token, thereby simplifying asset management and enhancing developer efficiency.\nContract address\nThese are the unified token contracts within our network.\nMainnet\nUnified BFC\n0xae172d8c5e428d4b7c70f9e593b207f9dac9bf3e\nUnified BiFi\n0x047938c3ad13c1eb821c8e310b2b6f889b6d0003\nUnified ETH\n0x6c9944674c1d2cf6c4c4999fc7290ba105dcd70e\nUnified BNB\n0xb800eaf843f962dfe5e145a8c9d07a3e70b11d7f\nUnified MATIC\n0x21ad243b81eff53482f6f6e7c76539f2cfc0b734\nUnified USDC\n0x640952e7984f2ecedead8fd97aa618ab1210a21c\nUnified USDT\n0x3ea8654d5755e673599473ab37d92788b5ba12ae\nUnified DAI\n0xcdb9579db96eb5c8298df889d915d0ff668aff2a\nUnified BTCB\n0xd267f821f1b8344b5a63626c8c824697194a173e\nUnified WBTC\n0x7b8fac5f29e101baab33c5f9c39d4f85ba2cc7c1\nUnified SAT\n0x17102ac78a02a98fc78b0c29b7b0506f035a99e5\nUnified WITCH\n0xb1f3a83597bce2ad842c29bd750ae17afc474137\nUnified P2D\n0xaa2e0911ac56c6f8a9c4f0006a8c907d5d180a6a\nUnified EGG\n0x9dd4d64e41ea7fc90acec15b08552172ce94556a\nTestnet\nUnified BFC\n0xb0ff18cb2d0f3f51a9c54af862ed98f3caa027a1\nUnified BiFi\n0x8010a873d59719e895e20f15f9906b5a1f399c3a\nUnified ETH\n0xc83eed1bf5464ed5383bc3342b918e08f6815950\nUnified BNB\n0xcd8bf79fa84d551f2465c0a646cabc295d43be5c\nUnified MATIC\n0xad115f901a1af99dc83d055c89641031fd1a50dc\nUnified USDC\n0x28661511cda7119b2185c647f23106a637cc074f\nUnified USDT\n0x815e850cddb2bb8c8afb61266525daffb9add7dc\nUnified DAI\n0x2353859d0c5cd0cb4da701d2aca9f1222ad71110\nUnified BTCB\n0xa4bde980daabdf9861f87ea89d4854a5ff062755\nUnified WBTC\n0xb710c446e2e4e162d734580bd6f13725c345e1f7\nUnified SAT\n0x3325b631cd1b972628f021c3bb776e21290bab21\nUnified WITCH\n0x97c46701a8599df99abb306ce8980b5f57d833fb\nUnified P2D\n0xda007bea12013ee90d5dec4111dba5bd98314f93\nUnified EGG\n0xc53ce1aa929e9e8b7f9587bbee2ab0fb530fe676\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/tokens-and-assets/unified-token"
  },
  {
    "title": "Inflation Model",
    "content": "TOKENS & ASSETS\nInflation Model\nBFC inflation model lies in motivating participants of the Bifrost Network and expanding the network. Holding BFC without utilizing them comes with an opportunity cost under the current inflation model, leading to BFC dilution over time.\nEconomic research or from an economic perspective, emphasizes the importance of having an optimal inflation rate to incentivize network participants to foster growth. Lowering the inflation rate may hinder the growth, while increasing the inflation rate could disrupt the model of the token. Since inflation rate is dynamically adjusted by the codes, considering the status of the network, our inflation remains subject to change through governance, rather than permanently fixed.\nBFC functions as the native currency of Bifrost and is characterized by its inflationary nature. The inflation rate within the Bifrost network is contingent upon the quantity of tokens staked. As the number of staked tokens varies, the allocation of inflationary rewards to validators and nominators is dynamically adjusted to optimize participation incentives for staking.\nThe inflation rate doesn’t target the token supply; instead, it targets the staked tokens.\nThe dynamic inflation rate can be divided into three segments: minimum, ideal, and maximum. Currently, these segments are set at 7%, 10%, and 13%, respectively. The inflation model incentivizes network participants by selecting one of the three inflation rates based on the current amount of staked tokens.\nThe rate selection follows the rules below:\nMinimum rate: current staked tokens ≥ expected maximum staked tokens\nMinimum rate: current staked tokens ≥ expected maximum staked tokens\nIdeal rate: expected minimum staked tokens < current staked tokens < expected maximum staked tokens\nIdeal rate: expected minimum staked tokens < current staked tokens < expected maximum staked tokens\nMaximum rate: current staked tokens ≤ expected minimum staked tokens\nMaximum rate: current staked tokens ≤ expected minimum staked tokens\nThe minimum rate is applied when the staked tokens exceed expectations, thereby disincentivizing network participants with reduced staking rewards. Conversely, the maximum rate is applied when the staked tokens fall below expectations, thereby incentivizing participants with increased rewards to reach the ideal range.\nEstablishing an ideal inflation rate and expectations is crucial for motivating network participants and supporting network growth. Reducing the inflation rate may hinder growth, while increasing it could destabilize the token's inflation model. Therefore, the token inflation rate is not fixed indefinitely; it can be adjusted in the future through on-chain governance, depending on the Bifrost ecosystem and tokenomics.\nThe objective is to align the staked tokens with the ideal staked tokens, ensuring there is sufficient backing of BFC to prevent potential security compromises while maintaining the liquidity of the native token.\nLast updated 9 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/tokens-and-assets/inflation-model"
  },
  {
    "title": "Biport",
    "content": "ADD NETWORK\nBiport\nHow to Add the Bifrost Network on Biport\nUsing Biport\nThere is no need for Biport users to manually add the Bifrost Network! \nThere are 3 different types of BFC on Biport: \nEthereum-based (ERC-20) BFC\nEthereum-based (ERC-20) BFC\nBIFROST Mainnet token\nBIFROST Mainnet token\nTestnet BFC token\nTestnet BFC token\nScroll down until you see MATIC, and BFC Bifrost Mainnet token is on the 6th row. It is right above Klaytn Cypress (KLAY).\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/add-network/biport"
  },
  {
    "title": "MetaMask",
    "content": "ADD NETWORK\nMetaMask\nHow to Add the BIFROST Network on MetaMask\n💡 RPC Information\nNetwork Name: Bifrost Network\nNetwork Name: Bifrost Network\nRPC URL: https://public-01.mainnet.bifrostnetwork.com/rpc\nRPC URL: https://public-01.mainnet.bifrostnetwork.com/rpc\nChain ID: 3068\nChain ID: 3068\nCurrency symbol: BFC\nCurrency symbol: BFC\nBlock explorer URL (Optional): https://explorer.mainnet.bifrostnetwork.com/\nBlock explorer URL (Optional): https://explorer.mainnet.bifrostnetwork.com/\nOnce you complete the following steps, you will see BFC in your wallet. If you experience any difficulty, please contact us through Discord.\nHow to Manually Add the Bifrost Network\nClick “My accounts” on the top right corner of the page. Then click “Settings”.\nClick “My accounts” on the top right corner of the page. Then click “Settings”.\nUnder “Settings”, scroll down to click “Networks”.\nUnder “Settings”, scroll down to click “Networks”.\nClick “Add network”.\nClick “Add network”.\nOnce you are directed to a new page, click “Add a network manually”.\nOnce you are directed to a new page, click “Add a network manually”.\nType in the correct “Network name”, “New RPC URL”, “Chain ID”, “Currency symbol”, and “Block explorer URL”.\nType in the correct “Network name”, “New RPC URL”, “Chain ID”, “Currency symbol”, and “Block explorer URL”.\n💡 RPC Information\nNetwork Name: Bifrost Network\nNetwork Name: Bifrost Network\nRPC URL: https://public-01.mainnet.bifrostnetwork.com/rpc\nRPC URL: https://public-01.mainnet.bifrostnetwork.com/rpc\nChain ID: 3068\nChain ID: 3068\nCurrency symbol: BFC\nCurrency symbol: BFC\nBlock explorer URL (Optional): https://explorer.mainnet.bifrostnetwork.com/\nBlock explorer URL (Optional): https://explorer.mainnet.bifrostnetwork.com/\nSuccess! The Bifrost Network has been added to MetaMask!\nSuccess! The Bifrost Network has been added to MetaMask!\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/add-network/metamask"
  },
  {
    "title": "Bridge Guide",
    "content": "BRIDGE\nBridge Guide\nThe BIFROST Bridge\nWhat is a bridge?\nA bridge is a service that allows the transfer of information and assets existing on different blockchain networks. An example of when and how a bridge would be used is as follows. If a user has USDC on Ethereum and wants to use this asset on the BIFROST Network, the user would use a bridge to transfer USDC from Ethereum to BIFROST. All blockchain networks, such as Ethereum and Polygon, have their own set of rules and consensus mechanisms. Bridges are a solution to connect these two economically and technologically different networks in order to broaden cryptocurrency usage and enhance interoperability.\nWhy do we need a bridge?\nAs mentioned previously, all blockchains have independent environments, each with its rules and consensus mechanisms. As such, each chain on its own cannot communicate with another, and tokens minted on one network cannot move to another network freely. A bridge is used to overcome this problem of interoperability and allows assets to move freely across chains. In addition to the above, the BIFROST Bridge acts as a core infrastructure in forming a multichain ecosystem by providing the benefits listed below.\nSupport for major networks, such as BIFROST, BNB Chain, Polygon, and Ethereum\nSupport for major networks, such as BIFROST, BNB Chain, Polygon, and Ethereum\nA low service fee of 0.005%\nA low service fee of 0.005%\nFast execution speed, with a maximum of 15 minutes\nFast execution speed, with a maximum of 15 minutes\nHigh compatibility with BIFROST Network Staking, BiFi, BiFi X, Owly, Biport, CrossChainSwap, Bifswap, and other BIFROST DApps\nHigh compatibility with BIFROST Network Staking, BiFi, BiFi X, Owly, Biport, CrossChainSwap, Bifswap, and other BIFROST DApps\nSolving the problem of liquidity fragmentation\nSolving the problem of liquidity fragmentation\nSupported networks and tokens\nHere is the list of networks and assets currently supported by the BIFROST Bridge. This list will grow as more networks and tokens are added.\nBFC\nBNB\nMATIC\nBFC\nETH\nETH\nBiFi\nUSDC\nBiFi\nUSDC\nDAI\nETH\nETH\nUSDT\nUSDC\nUSDC\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bridge/bridge-guide"
  },
  {
    "title": "Depositing to the Bifrost Network",
    "content": "BRIDGE\nBRIDGE GUIDE\nDepositing to the Bifrost Network\nDepositing to the BIFROST Network\nMaking a deposit with the Bifrost Network\nThe Deposit feature allows you to bring assets from other networks to the Bifrost Network. This guide will walk you through how to bridge an Ethereum network-based BFC to a Bifrost Network-based BFC.\nStep 1) Connect your wallet\nAccess the Bifrost Bridge page (https://www.bifrostnetwork.com/bridge)\nAccess the Bifrost Bridge page (https://www.bifrostnetwork.com/bridge)\nClick the wallet icon in the top right corner to connect your wallet.\nClick the wallet icon in the top right corner to connect your wallet.\nStep 2) Select a network and token\nSelect which network are you doing a deposit from.\nSelect which network are you doing a deposit from.\nSelect a token. Different networks support different types of tokens. You can see the supported networks and tokens page.\nSelect a token. Different networks support different types of tokens. You can see the supported networks and tokens page.\nEnter the amount of tokens to deposit. If the amount condition is not met, the bridge may not be able to run. If the execute button is not enabled, you will need to take a look at the minimum/maximum amount. Please check the minimum amount to deposit and the maximum amount to deposit to be able to proceed. (The maximum deposit amount may vary depending on liquidity conditions).\nEnter the amount of tokens to deposit. If the amount condition is not met, the bridge may not be able to run. If the execute button is not enabled, you will need to take a look at the minimum/maximum amount. Please check the minimum amount to deposit and the maximum amount to deposit to be able to proceed. (The maximum deposit amount may vary depending on liquidity conditions).\nStep 3) Launch the bridge\nClick the Approve button to agree to grant access for the token to be sent.\nClick the Approve button to agree to grant access for the token to be sent.\nClick the “Deposit” button to run the bridge.\nClick the “Deposit” button to run the bridge.\nWhen the connected wallet opens, check the estimated gas cost and confirm.\nWhen the connected wallet opens, check the estimated gas cost and confirm.\nComplete the bridge transaction. The time to bridge can fluctuate depending on network congestion.\nComplete the bridge transaction. The time to bridge can fluctuate depending on network congestion.\nStep 4) Check the bridge transaction execution history.\nAt the top of the page where you launched the bridge, under the “Use” tab, click “Explorer” (https://explorer.mainnet.bifrostnetwork.com/).\nAt the top of the page where you launched the bridge, under the “Use” tab, click “Explorer” (https://explorer.mainnet.bifrostnetwork.com/).\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bridge/bridge-guide/depositing-to-the-bifrost-network"
  },
  {
    "title": "Withdrawing to another network",
    "content": "BRIDGE\nBRIDGE GUIDE\nWithdrawing to another network\nWithdrawing to another network\nWithdrawing to other networks\nThe “Withdraw” feature allows you to move assets on the Bifrost Network to another network. This guide will walk you through how to bridge a Bifrost Network-based BFC to an Ethereum Network-based BFC.\nIf you are sending BFC to a centralised exchange (CEX), please make sure that the exchange supports the Bifrost Network. For example, if you send A Network-based tokens directly to an exchange that does not support A Network, you will lose your tokens, and neither the Foundation nor the exchange will be responsible for lost tokens.\nStep 1) Connect your wallet and set up your network\nAccess the Bifrost Bridge page (https://www.bifrostnetwork.com/bridge)\nAccess the Bifrost Bridge page (https://www.bifrostnetwork.com/bridge)\nClick the top-right wallet icon to connect your wallet.\nClick the top-right wallet icon to connect your wallet.\nIf the wallet you connect does not see the Bifrost Network, follow these steps: Settings - Networks - Search for and select Bifrost Network in the network search bar to connect.\nIf it is not found, enter the following information on the Add network page and save it:\nNetwork Name: Bifrost Network\nRPC URL: https://public-01.mainnet.bifrostnetwork.com/rpc\nChain ID: 3068\nCurrency symbol: BFC\nBlock explorer URL (Optional): https://explorer.mainnet.bifrostnetwork.com/\nStep 2) Select a network and token\nOn the Withdraw tab, select the network you want to withdraw to.\nOn the Withdraw tab, select the network you want to withdraw to.\nSelect a token.\nSelect a token.\nEnter the amount of tokens to withdraw. If the amount condition is not met, the bridge may not be able to run. If the execute button is not enabled, you will need to take a look at the minimum/maximum quantity. Please check the minimum amount to withdraw and the maximum amount to withdraw to be able to proceed. (The maximum withdrawal amount may fluctuate depending on liquidity conditions).\nEnter the amount of tokens to withdraw. If the amount condition is not met, the bridge may not be able to run. If the execute button is not enabled, you will need to take a look at the minimum/maximum quantity. Please check the minimum amount to withdraw and the maximum amount to withdraw to be able to proceed. (The maximum withdrawal amount may fluctuate depending on liquidity conditions).\nStep 3) Launch the bridge\nClick the Approve button to agree to grant access to the token to be sent.\nClick the Approve button to agree to grant access to the token to be sent.\nClick the “Withdraw” button to run the bridge.\nClick the “Withdraw” button to run the bridge.\nWhen the connected wallet opens, check the estimated gas cost and confirm.\nWhen the connected wallet opens, check the estimated gas cost and confirm.\nComplete the bridge transaction. The time to bridge can fluctuate depending on network congestion.\nComplete the bridge transaction. The time to bridge can fluctuate depending on network congestion.\nStep 4) Check the bridge transaction execution history.\nAt the top of the page where you launched the bridge, under the “Use” tab, click “Explorer” (https://explorer.mainnet.bifrostnetwork.com/).\nAt the top of the page where you launched the bridge, under the “Use” tab, click “Explorer” (https://explorer.mainnet.bifrostnetwork.com/).\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bridge/bridge-guide/withdrawing-to-another-network"
  },
  {
    "title": "Glossary",
    "content": "BRIDGE\nGlossary\nGlossary\nMinimum amount to deposit\nThe minimum amount of assets to execute bridging to the Bifrost Network\nMaximum amount to deposit\nThe current maximum amount of bridgeable assets\nMinimum amount to withdraw\nThe minimum amount of assets to execute bridging out of the Bifrost Network\nMaximum amount to withdraw\nThe current maximum amount of bridgeable assets.\nService fee\nThe fee that will be paid for the bridge transaction. The Bifrost Bridge currently charges a minimum of 0.005% to a maximum of 0.05% as a service fee. This fee varies depending on the network conditions and is subject to change.\nTime to transfer\nThe time it takes for an asset to be bridged over. The amount of time for bridging depends on network conditions.\nLast updated 7 months ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/bridge/glossary"
  },
  {
    "title": "Staking Guide",
    "content": "STAKING\nStaking Guide\nStake BFC\nUnstake BFC\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/staking-guide"
  },
  {
    "title": "Stake BFC",
    "content": "STAKING\nSTAKING GUIDE\nStake BFC\nStake BFC on the B\bifrost Network Page\nGo to the Bifrost staking page (https://www.bifrostnetwork.com/stake).\nGo to the Bifrost staking page (https://www.bifrostnetwork.com/stake).\nIf you click on the “Stake to a Validator” button it will take you to the “My Staking Status” section.\nIf you click on the “Stake to a Validator” button it will take you to the “My Staking Status” section.\nIn “My Staking Status” section, click “Connect wallet” to connect your wallet.\nIn “My Staking Status” section, click “Connect wallet” to connect your wallet.\nBy scrolling down you can check the “All Validators” section information.\nBy scrolling down you can check the “All Validators” section information.\nSelect a validator, enter the amount of BFC you want to stake and click the “Continue” button.\nSelect a validator, enter the amount of BFC you want to stake and click the “Continue” button.\nConfirm in your wallet to complete your staking.\nConfirm in your wallet to complete your staking.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/staking-guide/stake-bfc"
  },
  {
    "title": "Unstake BFC",
    "content": "STAKING\nSTAKING GUIDE\nUnstake BFC\nLearn How to Unstake BFC\nGo to the Bifrost staking page (https://www.bifrostnetwork.com/stake).\nGo to the Bifrost staking page (https://www.bifrostnetwork.com/stake).\nConnect your wallet, select the assets that you want to unstake in the “All Validators” section, enter the amount of tokens, and click “Continue”.\nConnect your wallet, select the assets that you want to unstake in the “All Validators” section, enter the amount of tokens, and click “Continue”.\nOnce you confirm in your wallet, the following pop-up message will be displayed. Click “Confirm” to complete unstaking.\nOnce you confirm in your wallet, the following pop-up message will be displayed. Click “Confirm” to complete unstaking.\nYou can check your unstaking request history in the “My Staking Status” section.\nYou can check your unstaking request history in the “My Staking Status” section.\nYou can receive rewards only after the unstaking period has elapsed. You can check this period of time in the “My Staking Status” section. Once your cancellation process has been completed, you may request a withdrawal at any time. (The duration of the cancellation may vary depending on the moment of your request)\nYou can receive rewards only after the unstaking period has elapsed. You can check this period of time in the “My Staking Status” section. Once your cancellation process has been completed, you may request a withdrawal at any time. (The duration of the cancellation may vary depending on the moment of your request)\nIf you have any questions about BFC staking, please reach out to us through Discord.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/staking-guide/unstake-bfc"
  },
  {
    "title": "Glossary",
    "content": "STAKING\nGlossary\nLast updated 2 years ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/glossary"
  },
  {
    "title": "All Validators",
    "content": "STAKING\nGLOSSARY\nAll Validators\nSearch by Name/Address: You can search by entering the name of the validator or the address of the controller.\nSearch by Name/Address: You can search by entering the name of the validator or the address of the controller.\nTypes: The search can be distinguished between “Full node” or “Basic node” types.\nTypes: The search can be distinguished between “Full node” or “Basic node” types.\nName: Displays the name of the validator.\nName: Displays the name of the validator.\nAddress: Displays the controller address of the validator.\nAddress: Displays the controller address of the validator.\nStaked: Displays the BFC stake of this validator. This represents the amount of self-bonding the validator has deposited into the network and the total amount of BFC nominated to them.\nStaked: Displays the BFC stake of this validator. This represents the amount of self-bonding the validator has deposited into the network and the total amount of BFC nominated to them.\nProductivity: Its an indicator of whether a validator is reliably generating blocks during that round correctly. For example if productivity is shown as 100%, it means that the validator node is generating blocks with 100% efficiency and no failures.\nProductivity: Its an indicator of whether a validator is reliably generating blocks during that round correctly. For example if productivity is shown as 100%, it means that the validator node is generating blocks with 100% efficiency and no failures.\nCommission: Commission refers to the fee that a validator charges to nominators who stake to them in exchange for delegation. Commission rates vary by validator.\nCommission: Commission refers to the fee that a validator charges to nominators who stake to them in exchange for delegation. Commission rates vary by validator.\nEYR: Estimated annualised yield.\nEYR: Estimated annualised yield.\nStaking: Click the “Staking” button to stake to the corresponding validator. If you are currently staking, an unstaking button will appear instead.\nStaking: Click the “Staking” button to stake to the corresponding validator. If you are currently staking, an unstaking button will appear instead.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/glossary/all-validators"
  },
  {
    "title": "My Staking Status",
    "content": "STAKING\nGLOSSARY\nMy Staking Status\nStaked balance: Displays the balance of tokens being staked.\nStaked balance: Displays the balance of tokens being staked.\nEstimated Yearly Return: Displays the estimated annual return.\nEstimated Yearly Return: Displays the estimated annual return.\nAverage APY: Displays the average annual percentage yield.\nAverage APY: Displays the average annual percentage yield.\nRemaining Unstaking Period: Displays the remaining period before unstaking is complete.\nRemaining Unstaking Period: Displays the remaining period before unstaking is complete.\nLast updated 1 year ago",
    "url": "https://docs.bifrostnetwork.com/bifrost-network/staking/glossary/my-staking-status"
  },
  {
    "title": "스테이킹 가이드",
    "content": "스테이킹\n스테이킹 가이드\nLast updated 1 year ago",
    "url": "https://docs.thebifrost.io/undefined-1/undefined/undefined"
  }
]
